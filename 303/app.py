import gradio as gr
import torch
from transformers import AutoModelForImageTextToText, AutoProcessor
from PIL import Image
import requests
import os
from io import BytesIO

# ==================== é…ç½® ====================
MODEL_PATH = "checkpoints/translategemma-27b-it"
EXAMPLE_IMAGE_DIR = "example_images"
EXAMPLE_IMAGE_URL = "https://c7.alamy.com/comp/2YAX36N/traffic-signs-in-czech-republic-pedestrian-zone-2YAX36N.jpg"
EXAMPLE_IMAGE_PATH = os.path.join(EXAMPLE_IMAGE_DIR, "example_traffic_sign.jpg")

# ==================== ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡ ====================
def download_example_image():
    """ä¸‹è½½å®˜æ–¹ç¤ºä¾‹å›¾ç‰‡"""
    if not os.path.exists(EXAMPLE_IMAGE_DIR):
        os.makedirs(EXAMPLE_IMAGE_DIR)
    
    if not os.path.exists(EXAMPLE_IMAGE_PATH):
        print(f"æ­£åœ¨ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡: {EXAMPLE_IMAGE_URL}")
        try:
            response = requests.get(EXAMPLE_IMAGE_URL, timeout=30)
            response.raise_for_status()
            with open(EXAMPLE_IMAGE_PATH, 'wb') as f:
                f.write(response.content)
            print(f"ç¤ºä¾‹å›¾ç‰‡å·²ä¿å­˜åˆ°: {EXAMPLE_IMAGE_PATH}")
        except Exception as e:
            print(f"ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡å¤±è´¥: {e}")
            return None
    return EXAMPLE_IMAGE_PATH

# ==================== åŠ è½½æ¨¡å‹ ====================
print("=" * 50)
print("æ­£åœ¨åŠ è½½ TranslateGemma æ¨¡å‹...")
print(f"æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
print("=" * 50)

processor = AutoProcessor.from_pretrained(MODEL_PATH, use_fast=True)
model = AutoModelForImageTextToText.from_pretrained(
    MODEL_PATH, 
    device_map="auto",
    dtype=torch.bfloat16
)
print("æ¨¡å‹åŠ è½½å®Œæˆï¼")

# ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡
example_image_path = download_example_image()

# ==================== ç¿»è¯‘å‡½æ•° ====================
def translate_text(text, source_lang, target_lang):
    """æ–‡æœ¬ç¿»è¯‘"""
    if not text.strip():
        return "è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬"
    
    # è®¾ç½®è¯­è¨€ä»£ç 
    lang_map = {
        "ä¸­æ–‡": "zh",
        "è‹±æ–‡": "en"
    }
    source_code = lang_map.get(source_lang, "zh")
    target_code = lang_map.get(target_lang, "en")
    
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "source_lang_code": source_code,
                    "target_lang_code": target_code,
                    "text": text,
                }
            ],
        }
    ]
    
    try:
        inputs = processor.apply_chat_template(
            messages, tokenize=True, add_generation_prompt=True, 
            return_dict=True, return_tensors="pt"
        ).to(model.device, dtype=torch.bfloat16)
        input_len = len(inputs['input_ids'][0])
        
        with torch.inference_mode():
            generation = model.generate(**inputs, max_new_tokens=512, do_sample=False)
        
        generation = generation[0][input_len:]
        decoded = processor.decode(generation, skip_special_tokens=True)
        return decoded
    except Exception as e:
        return f"ç¿»è¯‘å‡ºé”™: {str(e)}"

def translate_image(image, source_lang, target_lang):
    """å›¾ç‰‡æ–‡å­—æå–ä¸ç¿»è¯‘"""
    if image is None:
        return "è¯·ä¸Šä¼ å›¾ç‰‡"
    
    # è®¾ç½®è¯­è¨€ä»£ç 
    lang_map = {
        "ä¸­æ–‡": "zh",
        "è‹±æ–‡": "en",
        "æ·å…‹è¯­": "cs",
        "å¾·è¯­": "de",
        "æ³•è¯­": "fr",
        "æ—¥è¯­": "ja",
        "éŸ©è¯­": "ko",
        "è¥¿ç­ç‰™è¯­": "es"
    }
    source_code = lang_map.get(source_lang, "en")
    target_code = lang_map.get(target_lang, "zh")
    
    # ä¿å­˜å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_image_path = "temp_upload_image.jpg"
    if isinstance(image, str):
        temp_image_path = image
    else:
        image.save(temp_image_path)
    
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "source_lang_code": source_code,
                    "target_lang_code": target_code,
                    "url": temp_image_path,
                },
            ],
        }
    ]
    
    try:
        inputs = processor.apply_chat_template(
            messages, tokenize=True, add_generation_prompt=True, 
            return_dict=True, return_tensors="pt"
        ).to(model.device, dtype=torch.bfloat16)
        input_len = len(inputs['input_ids'][0])
        
        with torch.inference_mode():
            generation = model.generate(**inputs, max_new_tokens=512, do_sample=False)
        
        generation = generation[0][input_len:]
        decoded = processor.decode(generation, skip_special_tokens=True)
        return decoded
    except Exception as e:
        return f"ç¿»è¯‘å‡ºé”™: {str(e)}"

# ==================== ç¤ºä¾‹æ–‡æœ¬ ====================
text_examples_zh_to_en = [
    ["äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ã€‚", "ä¸­æ–‡", "è‹±æ–‡"],
    ["ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œæˆ‘ä»¬ä¸€èµ·å»å…¬å›­æ•£æ­¥å§ã€‚", "ä¸­æ–‡", "è‹±æ–‡"],
    ["è¿™æ¬¾äº§å“é‡‡ç”¨äº†æœ€æ–°çš„æŠ€æœ¯ï¼Œæ€§èƒ½éå¸¸å‡ºè‰²ã€‚", "ä¸­æ–‡", "è‹±æ–‡"],
    ["å­¦ä¹ ä¸€é—¨æ–°è¯­è¨€éœ€è¦æ—¶é—´å’Œè€å¿ƒã€‚", "ä¸­æ–‡", "è‹±æ–‡"],
    ["ä¸­å›½æ˜¯ä¸€ä¸ªæ‹¥æœ‰æ‚ ä¹…å†å²å’Œç¿çƒ‚æ–‡åŒ–çš„å›½å®¶ã€‚", "ä¸­æ–‡", "è‹±æ–‡"],
]

text_examples_en_to_zh = [
    ["Artificial intelligence is transforming the way we live.", "è‹±æ–‡", "ä¸­æ–‡"],
    ["The weather is beautiful today, let's take a walk in the park.", "è‹±æ–‡", "ä¸­æ–‡"],
    ["This product uses the latest technology and has excellent performance.", "è‹±æ–‡", "ä¸­æ–‡"],
    ["Learning a new language takes time and patience.", "è‹±æ–‡", "ä¸­æ–‡"],
    ["Machine learning models are becoming increasingly powerful.", "è‹±æ–‡", "ä¸­æ–‡"],
]

# ==================== Gradio ç•Œé¢ ====================
# è‡ªå®šä¹‰ CSS
custom_css = """
.youtube-banner {
    background: linear-gradient(135deg, #ff0000 0%, #cc0000 100%);
    padding: 15px 20px;
    border-radius: 10px;
    margin-bottom: 20px;
    text-align: center;
}
.youtube-banner a {
    color: white !important;
    text-decoration: none;
    font-size: 18px;
    font-weight: bold;
}
.youtube-banner a:hover {
    text-decoration: underline;
}
"""

with gr.Blocks(title="TranslateGemma ä¸­è‹±äº’è¯‘") as demo:
    # YouTube é¢‘é“ä¿¡æ¯
    gr.HTML("""
    <div class="youtube-banner">
        <a href="https://www.youtube.com/@rongyikanshijie-ai" target="_blank">
            ğŸ“º æ¬¢è¿è®¢é˜…æˆ‘çš„ YouTube é¢‘é“: AI æŠ€æœ¯åˆ†äº«é¢‘é“
        </a>
    </div>
    """)
    
    gr.Markdown("""
    # ğŸŒ TranslateGemma ä¸­è‹±äº’è¯‘ç³»ç»Ÿ
    
    åŸºäº Google TranslateGemma-27B æ¨¡å‹ï¼Œæ”¯æŒä¸­è‹±æ–‡æ–‡æœ¬äº’è¯‘å’Œå›¾ç‰‡æ–‡å­—æå–ç¿»è¯‘ã€‚
    
    **æ¨¡å‹ç‰¹ç‚¹ï¼š**
    - æ”¯æŒ 55 ç§è¯­è¨€ç¿»è¯‘
    - æ”¯æŒå›¾ç‰‡æ–‡å­—æå–ä¸ç¿»è¯‘
    - è½»é‡çº§ã€é«˜æ€§èƒ½
    """)
    
    with gr.Tabs():
        # ==================== æ–‡æœ¬ç¿»è¯‘ Tab ====================
        with gr.TabItem("ğŸ“ æ–‡æœ¬ç¿»è¯‘"):
            gr.Markdown("### è¾“å…¥æ–‡æœ¬è¿›è¡Œä¸­è‹±äº’è¯‘")
            
            with gr.Row():
                with gr.Column():
                    text_input = gr.Textbox(
                        label="è¾“å…¥æ–‡æœ¬",
                        placeholder="è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬...",
                        lines=5
                    )
                    with gr.Row():
                        source_lang_text = gr.Dropdown(
                            choices=["ä¸­æ–‡", "è‹±æ–‡"],
                            value="ä¸­æ–‡",
                            label="æºè¯­è¨€"
                        )
                        target_lang_text = gr.Dropdown(
                            choices=["ä¸­æ–‡", "è‹±æ–‡"],
                            value="è‹±æ–‡",
                            label="ç›®æ ‡è¯­è¨€"
                        )
                    translate_text_btn = gr.Button("ğŸš€ å¼€å§‹ç¿»è¯‘", variant="primary")
                
                with gr.Column():
                    text_output = gr.Textbox(
                        label="ç¿»è¯‘ç»“æœ",
                        lines=5,
                        interactive=False
                    )
            
            gr.Markdown("### ğŸ“š ä¸­æ–‡ â†’ è‹±æ–‡ ç¤ºä¾‹")
            gr.Examples(
                examples=text_examples_zh_to_en,
                inputs=[text_input, source_lang_text, target_lang_text],
                label=""
            )
            
            gr.Markdown("### ğŸ“š è‹±æ–‡ â†’ ä¸­æ–‡ ç¤ºä¾‹")
            gr.Examples(
                examples=text_examples_en_to_zh,
                inputs=[text_input, source_lang_text, target_lang_text],
                label=""
            )
            
            translate_text_btn.click(
                fn=translate_text,
                inputs=[text_input, source_lang_text, target_lang_text],
                outputs=text_output
            )
        
        # ==================== å›¾ç‰‡ç¿»è¯‘ Tab ====================
        with gr.TabItem("ğŸ–¼ï¸ å›¾ç‰‡æ–‡å­—æå–ä¸ç¿»è¯‘"):
            gr.Markdown("### ä¸Šä¼ å›¾ç‰‡ï¼Œæå–å¹¶ç¿»è¯‘å›¾ç‰‡ä¸­çš„æ–‡å­—")
            
            with gr.Row():
                with gr.Column():
                    image_input = gr.Image(
                        label="ä¸Šä¼ å›¾ç‰‡",
                        type="pil"
                    )
                    with gr.Row():
                        source_lang_image = gr.Dropdown(
                            choices=["ä¸­æ–‡", "è‹±æ–‡", "æ·å…‹è¯­", "å¾·è¯­", "æ³•è¯­", "æ—¥è¯­", "éŸ©è¯­", "è¥¿ç­ç‰™è¯­"],
                            value="è‹±æ–‡",
                            label="å›¾ç‰‡æ–‡å­—è¯­è¨€"
                        )
                        target_lang_image = gr.Dropdown(
                            choices=["ä¸­æ–‡", "è‹±æ–‡", "æ·å…‹è¯­", "å¾·è¯­", "æ³•è¯­", "æ—¥è¯­", "éŸ©è¯­", "è¥¿ç­ç‰™è¯­"],
                            value="ä¸­æ–‡",
                            label="ç¿»è¯‘ç›®æ ‡è¯­è¨€"
                        )
                    translate_image_btn = gr.Button("ğŸš€ æå–å¹¶ç¿»è¯‘", variant="primary")
                
                with gr.Column():
                    image_output = gr.Textbox(
                        label="ç¿»è¯‘ç»“æœ",
                        lines=8,
                        interactive=False
                    )
            
            # å›¾ç‰‡ç¤ºä¾‹
            if example_image_path and os.path.exists(example_image_path):
                gr.Markdown("### ğŸ“· ç¤ºä¾‹å›¾ç‰‡ï¼ˆæ·å…‹è¯­äº¤é€šæ ‡å¿—ï¼‰")
                gr.Examples(
                    examples=[[example_image_path, "æ·å…‹è¯­", "ä¸­æ–‡"]],
                    inputs=[image_input, source_lang_image, target_lang_image],
                    label=""
                )
            
            translate_image_btn.click(
                fn=translate_image,
                inputs=[image_input, source_lang_image, target_lang_image],
                outputs=image_output
            )
    
    gr.Markdown("""
    ---
    **è¯´æ˜ï¼š**
    - æœ¬ç³»ç»ŸåŸºäº Google TranslateGemma-27B-IT æ¨¡å‹
    - å½“å‰ä»…æ”¯æŒä¸­è‹±æ–‡äº’è¯‘
    - å›¾ç‰‡ç¿»è¯‘ä¼šè‡ªåŠ¨æå–å›¾ç‰‡ä¸­çš„æ–‡å­—å¹¶ç¿»è¯‘
    """)

# ==================== å¯åŠ¨åº”ç”¨ ====================
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, css=custom_css, theme=gr.themes.Soft())
