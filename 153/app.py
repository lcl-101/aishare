import gradio as gr
import torch
from transformers import VoxtralForConditionalGeneration, AutoProcessor
import tempfile
import os
import requests
import urllib.parse

# å…¨å±€é…ç½®
device = "cuda"
repo_id = "checkpoints/Voxtral-Small-24B-2507"

# ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶çš„URL
SAMPLE_AUDIOS = {
    "obama.mp3": "https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/obama.mp3",
    "bcn_weather.mp3": "https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/bcn_weather.mp3",
    "winning_call.mp3": "https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/winning_call.mp3",
    "mary_had_lamb.mp3": "https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/mary_had_lamb.mp3"
}

def download_sample_audio(url, filename):
    """ä¸‹è½½ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶åˆ°æœ¬åœ°"""
    os.makedirs("samples", exist_ok=True)
    filepath = os.path.join("samples", filename)
    
    if not os.path.exists(filepath):
        try:
            response = requests.get(url)
            response.raise_for_status()
            with open(filepath, 'wb') as f:
                f.write(response.content)
            print(f"Downloaded {filename} to {filepath}")
        except Exception as e:
            print(f"Error downloading {filename}: {e}")
            return None
    
    return filepath

def download_all_samples():
    """ä¸‹è½½æ‰€æœ‰ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶"""
    downloaded_files = {}
    for filename, url in SAMPLE_AUDIOS.items():
        filepath = download_sample_audio(url, filename)
        if filepath:
            downloaded_files[filename] = filepath
    return downloaded_files

# å¯åŠ¨æ—¶ä¸‹è½½æ‰€æœ‰ç¤ºä¾‹æ–‡ä»¶
print("Downloading sample audio files...")
sample_files = download_all_samples()
print("Sample files ready!")

# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
print("Loading Voxtral model...")
processor = AutoProcessor.from_pretrained(repo_id)
model = VoxtralForConditionalGeneration.from_pretrained(repo_id, torch_dtype=torch.bfloat16, device_map=device)
print("Model loaded successfully!")

def demo2_function(audio1_file, audio2_file, audio3_file, follow_up_question):
    """Demo2: å¯¹è¯å¼éŸ³é¢‘åˆ†æ - å¤šè½®å¯¹è¯"""
    if not audio1_file or not audio2_file or not audio3_file:
        return "è¯·ä¸Šä¼ ä¸‰ä¸ªéŸ³é¢‘æ–‡ä»¶"
    
    conversation = [
        {
            "role": "user",
            "content": [
                {
                    "type": "audio",
                    "path": audio1_file,
                },
                {
                    "type": "audio",
                    "path": audio2_file,
                },
                {"type": "text", "text": "è¯·ç®€è¦æè¿°æ‚¨å¬åˆ°çš„å†…å®¹ã€‚"},
            ],
        },
        {
            "role": "assistant",
            "content": "éŸ³é¢‘å¼€å§‹æ—¶ï¼Œæ¼”è®²è€…åœ¨èŠåŠ å“¥å‘è¡¨å‘Šåˆ«æ¼”è¯´ï¼Œå›é¡¾äº†ä»–ä½œä¸ºæ€»ç»Ÿçš„å…«å¹´æ—¶å…‰ï¼Œå¹¶å‘ç¾å›½äººæ°‘è¡¨è¾¾è°¢æ„ã€‚ç„¶åéŸ³é¢‘è½¬å‘å¤©æ°”æŠ¥å‘Šï¼Œè¯´æ˜å·´å¡ç½—é‚£å‰ä¸€å¤©çš„æ¸©åº¦æ˜¯35åº¦ï¼Œä½†ç¬¬äºŒå¤©æ¸©åº¦ä¼šé™åˆ°é›¶ä¸‹20åº¦ã€‚",
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "audio",
                    "path": audio3_file,
                },
                {"type": "text", "text": follow_up_question or "å¥½çš„ï¼Œç°åœ¨è¯·æ¯”è¾ƒè¿™ä¸ªæ–°éŸ³é¢‘ä¸ä¹‹å‰çš„éŸ³é¢‘æœ‰ä»€ä¹ˆä¸åŒã€‚"},
            ],
        },
    ]
    
    inputs = processor.apply_chat_template(conversation)
    inputs = inputs.to(device, dtype=torch.bfloat16)
    
    outputs = model.generate(**inputs, max_new_tokens=500)
    decoded_outputs = processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)
    
    return decoded_outputs[0]

def demo3_function(text_question):
    """Demo3: çº¯æ–‡æœ¬ç”Ÿæˆ"""
    if not text_question:
        return "è¯·è¾“å…¥é—®é¢˜"
    
    conversation = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": text_question,
                },
            ],
        }
    ]
    
    inputs = processor.apply_chat_template(conversation)
    inputs = inputs.to(device, dtype=torch.bfloat16)
    
    outputs = model.generate(**inputs, max_new_tokens=500)
    decoded_outputs = processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)
    
    return decoded_outputs[0]

def demo4_function(audio_file):
    """Demo4: å•éŸ³é¢‘åˆ†æ"""
    if not audio_file:
        return "è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
    
    conversation = [
        {
            "role": "user",
            "content": [
                {
                    "type": "audio",
                    "path": audio_file,
                },
            ],
        }
    ]
    
    inputs = processor.apply_chat_template(conversation)
    inputs = inputs.to(device, dtype=torch.bfloat16)
    
    outputs = model.generate(**inputs, max_new_tokens=500)
    decoded_outputs = processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)
    
    return decoded_outputs[0]

def demo5_function(audio1_file, audio2_file, audio3_file, question1, question2):
    """Demo5: æ‰¹é‡å¤„ç†å¤šä¸ªå¯¹è¯"""
    if not audio1_file or not audio2_file or not audio3_file:
        return "è¯·ä¸Šä¼ ä¸‰ä¸ªéŸ³é¢‘æ–‡ä»¶"
    
    conversations = [
        [
            {
                "role": "user",
                "content": [
                    {
                        "type": "audio",
                        "path": audio1_file,
                    },
                    {
                        "type": "audio",
                        "path": audio2_file,
                    },
                    {
                        "type": "text",
                        "text": question1 or "æ¼”è®²ä¸­è°åœ¨è¯´è¯ï¼Œè®¨è®ºçš„æ˜¯å“ªä¸ªåŸå¸‚çš„å¤©æ°”ï¼Ÿ",
                    },
                ],
            }
        ],
        [
            {
                "role": "user",
                "content": [
                    {
                        "type": "audio",
                        "path": audio3_file,
                    },
                    {"type": "text", "text": question2 or "æ‚¨èƒ½å‘Šè¯‰æˆ‘è¿™ä¸ªéŸ³é¢‘çš„å†…å®¹å—ï¼Ÿ"},
                ],
            }
        ],
    ]
    
    inputs = processor.apply_chat_template(conversations)
    inputs = inputs.to(device, dtype=torch.bfloat16)
    
    outputs = model.generate(**inputs, max_new_tokens=500)
    decoded_outputs = processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)
    
    results = []
    for i, output in enumerate(decoded_outputs):
        results.append(f"å¯¹è¯ {i+1} çš„å›ç­”:\n{output}")
    
    return "\n\n" + "="*80 + "\n\n".join(results)

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="Voxtral å¤šæ¨¡æ€AIåŠ©æ‰‹", theme=gr.themes.Soft()) as app:
    gr.Markdown("# ğŸµ Voxtral å¤šæ¨¡æ€AIåŠ©æ‰‹")
    gr.Markdown("è¿™æ˜¯ä¸€ä¸ªé›†æˆäº†å¤šç§åŠŸèƒ½çš„è¯­éŸ³å’Œæ–‡æœ¬AIåŠ©æ‰‹ï¼ŒåŸºäºVoxtralæ¨¡å‹æ„å»ºã€‚")
    
    with gr.Tabs():
        # Demo 4 Tab - å•éŸ³é¢‘åˆ†æ (ç¬¬ä¸€ä¸ª)
        with gr.TabItem("å•éŸ³é¢‘åˆ†æ"):
            gr.Markdown("### ğŸ§ å•ä¸ªéŸ³é¢‘æ–‡ä»¶åˆ†æ")
            gr.Markdown("ä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ŒAIå°†è‡ªåŠ¨åˆ†æå¹¶æè¿°å…¶å†…å®¹ã€‚")
            
            with gr.Row():
                with gr.Column():
                    demo4_audio = gr.Audio(label="éŸ³é¢‘æ–‡ä»¶", type="filepath")
                    demo4_btn = gr.Button("ğŸµ åˆ†æéŸ³é¢‘", variant="primary")
                
                with gr.Column():
                    demo4_output = gr.Textbox(label="AIåˆ†æç»“æœ", lines=15, max_lines=30, show_copy_button=True)
            
            # æ·»åŠ ç¤ºä¾‹
            gr.Examples(
                examples=[
                    [sample_files.get("winning_call.mp3")],
                    [sample_files.get("obama.mp3")],
                    [sample_files.get("bcn_weather.mp3")],
                    [sample_files.get("mary_had_lamb.mp3")]
                ],
                inputs=[demo4_audio],
                label="ğŸ“ ç¤ºä¾‹éŸ³é¢‘ï¼ˆç‚¹å‡»åŠ è½½ï¼‰"
            )
            
            demo4_btn.click(
                demo4_function,
                inputs=demo4_audio,
                outputs=demo4_output
            )
        
        # Demo 3 Tab - æ–‡æœ¬é—®ç­” (ç¬¬äºŒä¸ª)
        with gr.TabItem("æ–‡æœ¬é—®ç­”"):
            gr.Markdown("### ğŸ“ çº¯æ–‡æœ¬AIé—®ç­”")
            gr.Markdown("ç›´æ¥å‘AIæé—®ï¼Œè·å¾—è¯¦ç»†çš„æ–‡æœ¬å›ç­”ã€‚")
            
            with gr.Row():
                with gr.Column():
                    demo3_question = gr.Textbox(
                        label="é—®é¢˜",
                        placeholder="ä¾‹å¦‚ï¼šä¸ºä»€ä¹ˆAIæ¨¡å‹åº”è¯¥å¼€æºï¼Ÿ",
                        value="ä¸ºä»€ä¹ˆAIæ¨¡å‹åº”è¯¥å¼€æºï¼Ÿ",
                        lines=3
                    )
                    demo3_btn = gr.Button("ğŸ¤– æé—®", variant="primary")
                
                with gr.Column():
                    demo3_output = gr.Textbox(label="AIå›ç­”", lines=15, max_lines=30, show_copy_button=True)
            
            # æ·»åŠ ç¤ºä¾‹
            gr.Examples(
                examples=[
                    ["ä¸ºä»€ä¹ˆAIæ¨¡å‹åº”è¯¥å¼€æºï¼Ÿ"],
                    ["å¤šæ¨¡æ€AIç³»ç»Ÿæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ"],
                    ["è¯·è§£é‡ŠAIå®‰å…¨å’Œå¯¹é½çš„é‡è¦æ€§ã€‚"]
                ],
                inputs=[demo3_question],
                label="ğŸ“ ç¤ºä¾‹é—®é¢˜ï¼ˆç‚¹å‡»åŠ è½½ï¼‰"
            )
            
            demo3_btn.click(
                demo3_function,
                inputs=demo3_question,
                outputs=demo3_output
            )
        
        # Demo 2 Tab - å¯¹è¯å¼åˆ†æ (ç¬¬ä¸‰ä¸ª)
        with gr.TabItem("å¯¹è¯å¼åˆ†æ"):
            gr.Markdown("### ğŸ’¬ å¤šè½®å¯¹è¯éŸ³é¢‘åˆ†æ")
            gr.Markdown("ä¸Šä¼ ä¸‰ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œè¿›è¡Œå¤šè½®å¯¹è¯å¼çš„éŸ³é¢‘å†…å®¹åˆ†æã€‚")
            
            with gr.Row():
                with gr.Column():
                    demo2_audio1 = gr.Audio(label="éŸ³é¢‘æ–‡ä»¶ 1 (Obamaæ¼”è®²)", type="filepath")
                    demo2_audio2 = gr.Audio(label="éŸ³é¢‘æ–‡ä»¶ 2 (å¤©æ°”æŠ¥å‘Š)", type="filepath") 
                    demo2_audio3 = gr.Audio(label="éŸ³é¢‘æ–‡ä»¶ 3 (å¯¹æ¯”éŸ³é¢‘)", type="filepath")
                    demo2_question = gr.Textbox(
                        label="è¿½é—®é—®é¢˜",
                        placeholder="ä¾‹å¦‚ï¼šå¥½çš„ï¼Œç°åœ¨è¯·æ¯”è¾ƒè¿™ä¸ªæ–°éŸ³é¢‘ä¸ä¹‹å‰çš„éŸ³é¢‘æœ‰ä»€ä¹ˆä¸åŒã€‚",
                        value="å¥½çš„ï¼Œç°åœ¨è¯·æ¯”è¾ƒè¿™ä¸ªæ–°éŸ³é¢‘ä¸ä¹‹å‰çš„éŸ³é¢‘æœ‰ä»€ä¹ˆä¸åŒã€‚"
                    )
                    demo2_btn = gr.Button("ğŸ—£ï¸ å¯¹è¯åˆ†æ", variant="primary")
                
                with gr.Column():
                    demo2_output = gr.Textbox(label="AIå›ç­”", lines=15, max_lines=30, show_copy_button=True)
            
            # æ·»åŠ ç¤ºä¾‹
            gr.Examples(
                examples=[
                    [sample_files.get("obama.mp3"), sample_files.get("bcn_weather.mp3"), sample_files.get("winning_call.mp3"), "å¥½çš„ï¼Œç°åœ¨è¯·æ¯”è¾ƒè¿™ä¸ªæ–°éŸ³é¢‘ä¸ä¹‹å‰çš„éŸ³é¢‘æœ‰ä»€ä¹ˆä¸åŒã€‚"]
                ],
                inputs=[demo2_audio1, demo2_audio2, demo2_audio3, demo2_question],
                label="ğŸ“ ç¤ºä¾‹ï¼ˆç‚¹å‡»åŠ è½½ï¼‰"
            )
            
            demo2_btn.click(
                demo2_function,
                inputs=[demo2_audio1, demo2_audio2, demo2_audio3, demo2_question],
                outputs=demo2_output
            )
        
        # Demo 5 Tab - æ‰¹é‡å¯¹è¯å¤„ç† (ç¬¬å››ä¸ª)
        with gr.TabItem("æ‰¹é‡å¯¹è¯å¤„ç†"):
            gr.Markdown("### ğŸ”„ æ‰¹é‡å¯¹è¯å¤„ç†")
            gr.Markdown("åŒæ—¶å¤„ç†å¤šä¸ªå¯¹è¯ï¼Œé€‚åˆæ‰¹é‡éŸ³é¢‘å†…å®¹åˆ†æã€‚")
            
            with gr.Row():
                with gr.Column():
                    demo5_audio1 = gr.Audio(label="å¯¹è¯1 - éŸ³é¢‘æ–‡ä»¶ 1", type="filepath")
                    demo5_audio2 = gr.Audio(label="å¯¹è¯1 - éŸ³é¢‘æ–‡ä»¶ 2", type="filepath")
                    demo5_question1 = gr.Textbox(
                        label="å¯¹è¯1 é—®é¢˜",
                        placeholder="ä¾‹å¦‚ï¼šæ¼”è®²ä¸­è°åœ¨è¯´è¯ï¼Œè®¨è®ºçš„æ˜¯å“ªä¸ªåŸå¸‚çš„å¤©æ°”ï¼Ÿ",
                        value="æ¼”è®²ä¸­è°åœ¨è¯´è¯ï¼Œè®¨è®ºçš„æ˜¯å“ªä¸ªåŸå¸‚çš„å¤©æ°”ï¼Ÿ"
                    )
                    demo5_audio3 = gr.Audio(label="å¯¹è¯2 - éŸ³é¢‘æ–‡ä»¶", type="filepath")
                    demo5_question2 = gr.Textbox(
                        label="å¯¹è¯2 é—®é¢˜",
                        placeholder="ä¾‹å¦‚ï¼šæ‚¨èƒ½å‘Šè¯‰æˆ‘è¿™ä¸ªéŸ³é¢‘çš„å†…å®¹å—ï¼Ÿ",
                        value="æ‚¨èƒ½å‘Šè¯‰æˆ‘è¿™ä¸ªéŸ³é¢‘çš„å†…å®¹å—ï¼Ÿ"
                    )
                    demo5_btn = gr.Button("âš¡ æ‰¹é‡å¤„ç†", variant="primary")
                
                with gr.Column():
                    demo5_output = gr.Textbox(label="æ‰¹é‡å¤„ç†ç»“æœ", lines=20, max_lines=40, show_copy_button=True)
            
            # æ·»åŠ ç¤ºä¾‹
            gr.Examples(
                examples=[
                    [
                        sample_files.get("obama.mp3"), 
                        sample_files.get("bcn_weather.mp3"), 
                        sample_files.get("winning_call.mp3"),
                        "æ¼”è®²ä¸­è°åœ¨è¯´è¯ï¼Œè®¨è®ºçš„æ˜¯å“ªä¸ªåŸå¸‚çš„å¤©æ°”ï¼Ÿ",
                        "æ‚¨èƒ½å‘Šè¯‰æˆ‘è¿™ä¸ªéŸ³é¢‘çš„å†…å®¹å—ï¼Ÿ"
                    ]
                ],
                inputs=[demo5_audio1, demo5_audio2, demo5_audio3, demo5_question1, demo5_question2],
                label="ğŸ“ ç¤ºä¾‹ï¼ˆç‚¹å‡»åŠ è½½ï¼‰"
            )
            
            demo5_btn.click(
                demo5_function,
                inputs=[demo5_audio1, demo5_audio2, demo5_audio3, demo5_question1, demo5_question2],
                outputs=demo5_output
            )
    
    gr.Markdown("---")
    gr.Markdown("ğŸ”§ **æŠ€æœ¯æ ˆ**: Voxtral-Small-24B-2507 | Transformers | Gradio")
    gr.Markdown("ğŸ’¡ **æç¤º**: æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼ï¼Œæ¨èä½¿ç”¨æ¸…æ™°çš„éŸ³é¢‘æ–‡ä»¶ä»¥è·å¾—æœ€ä½³æ•ˆæœã€‚")
    
    # æ˜¾ç¤ºå·²ä¸‹è½½çš„æ ·æœ¬æ–‡ä»¶ä¿¡æ¯
    with gr.Accordion("ğŸ“ å·²ä¸‹è½½çš„æ ·æœ¬æ–‡ä»¶", open=False):
        sample_info = "å·²ä¸‹è½½çš„æ ·æœ¬éŸ³é¢‘æ–‡ä»¶:\n"
        for filename, filepath in sample_files.items():
            if filepath and os.path.exists(filepath):
                sample_info += f"âœ… {filename}: {filepath}\n"
            else:
                sample_info += f"âŒ {filename}: ä¸‹è½½å¤±è´¥\n"
        gr.Markdown(f"```\n{sample_info}\n```")

if __name__ == "__main__":
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        inbrowser=False
    )
