#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
StoryMem Gradio Web ç•Œé¢
åŸºäº StoryMem çš„æ•…äº‹è§†é¢‘ç”Ÿæˆå·¥å…·
"""

import os
import gc
import sys
import glob
import json5
import logging
import time
import shutil
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Any

import torch
import gradio as gr
from PIL import Image
import numpy as np

# å†…å­˜ä¼˜åŒ–è®¾ç½®
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

# é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.absolute()
sys.path.insert(0, str(PROJECT_ROOT))

import wan
from wan.configs import MAX_AREA_CONFIGS, SIZE_CONFIGS, SUPPORTED_SIZES, WAN_CONFIGS
from wan.utils.utils import save_video

# ==================== å…¨å±€é…ç½® ====================
# æ¨¡å‹è·¯å¾„é…ç½®
T2V_MODEL_PATH = PROJECT_ROOT / "checkpoints" / "Wan2.2-T2V-A14B"
I2V_MODEL_PATH = PROJECT_ROOT / "checkpoints" / "Wan2.2-I2V-A14B"
LORA_MI2V_PATH = PROJECT_ROOT / "checkpoints" / "StoryMem" / "Wan2.2-MI2V-A14B"
LORA_MM2V_PATH = PROJECT_ROOT / "checkpoints" / "StoryMem" / "Wan2.2-MM2V-A14B"
STORY_DIR = PROJECT_ROOT / "story"
OUTPUT_DIR = PROJECT_ROOT / "results"

# é»˜è®¤å‚æ•°
DEFAULT_SIZE = "832*480"
DEFAULT_MAX_MEMORY_SIZE = 10
DEFAULT_SEED = 0
DEFAULT_SAMPLE_GUIDE_SCALE = 3.5
DEFAULT_LORA_RANK = 128
DEFAULT_FRAME_NUM = 81  # å¸§æ•° (å¸§æ•°å¿…é¡»æ˜¯ 4n+1)ï¼Œ81å¸§çº¦5ç§’

# æ˜¾å­˜å……è¶³æ—¶å¯ä»¥ç¦ç”¨ offload ä»¥æå‡é€Ÿåº¦
# H20 141GB æ˜¾å­˜è¶³å¤Ÿè¿è¡Œå•ä¸ªæ¨¡å‹ä¸éœ€è¦ offload
USE_OFFLOAD_MODEL = False  # è®¾ä¸º False å¯å¤§å¹…æå‡æ¨ç†é€Ÿåº¦ (141GBæ˜¾å­˜å»ºè®® False)

# ==================== æ—¥å¿—é…ç½® ====================
logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] %(levelname)s: %(message)s",
    handlers=[logging.StreamHandler(stream=sys.stdout)]
)
logger = logging.getLogger(__name__)


# ==================== å†…å­˜ç®¡ç†è¾…åŠ©å‡½æ•° ====================
def clear_memory():
    """å¼ºåˆ¶æ¸…ç† GPU å’Œ CPU å†…å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    gc.collect()
    
    # å°è¯•é‡Šæ”¾ C åº“çš„å†…å­˜ç¼“å­˜ (Linux)
    try:
        import ctypes
        libc = ctypes.CDLL("libc.so.6")
        libc.malloc_trim(0)
    except:
        pass


def get_memory_info():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    info = []
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        info.append(f"GPU: {allocated:.1f}GB allocated, {reserved:.1f}GB reserved")
    try:
        import psutil
        mem = psutil.virtual_memory()
        info.append(f"CPU: {mem.used/1024**3:.1f}GB / {mem.total/1024**3:.1f}GB ({mem.percent}%)")
    except:
        pass
    return " | ".join(info)


def extract_keyframes_simple(video_path: str, output_dir: Path):
    """ç®€åŒ–çš„å…³é”®å¸§æå– - åªä¿å­˜é¦–å°¾å¸§ï¼Œé¿å…åŠ è½½é¢å¤–æ¨¡å‹"""
    try:
        import cv2
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            logger.warning(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if total_frames <= 0:
            return
        
        # è¯»å–ç¬¬ä¸€å¸§
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        ret, first_frame = cap.read()
        if ret:
            cv2.imwrite(str(output_dir / f"{Path(video_path).stem}_keyframe0.jpg"), first_frame)
        
        # è¯»å–ä¸­é—´å¸§
        if total_frames > 2:
            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames // 2)
            ret, mid_frame = cap.read()
            if ret:
                cv2.imwrite(str(output_dir / f"{Path(video_path).stem}_keyframe1.jpg"), mid_frame)
        
        # è¯»å–æœ€åä¸€å¸§
        cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)
        ret, last_frame = cap.read()
        if ret:
            cv2.imwrite(str(output_dir / "last_frame.jpg"), last_frame)
            # ä¹Ÿä¿å­˜æœ€å 5 å¸§ä½œä¸º motion_frames
            frames_for_motion = []
            for i in range(max(0, total_frames - 5), total_frames):
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                if ret:
                    frames_for_motion.append(frame)
            
            if frames_for_motion:
                h, w = frames_for_motion[0].shape[:2]
                fourcc = cv2.VideoWriter_fourcc(*"mp4v")
                motion_path = str(output_dir / "motion_frames.mp4")
                writer = cv2.VideoWriter(motion_path, fourcc, 5, (w, h))
                for frame in frames_for_motion:
                    writer.write(frame)
                writer.release()
        
        cap.release()
        logger.info(f"ç®€åŒ–å…³é”®å¸§æå–å®Œæˆ: {video_path}")
    except Exception as e:
        logger.warning(f"å…³é”®å¸§æå–å¤±è´¥: {e}")


# ==================== å…¨å±€æ¨¡å‹å®ä¾‹ ====================
class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ï¼Œè´Ÿè´£æ¨¡å‹çš„åŠ è½½å’Œç®¡ç† - åŒä¸€æ—¶é—´åªä¿ç•™ä¸€ä¸ªæ¨¡å‹åœ¨å†…å­˜ä¸­"""
    
    def __init__(self):
        self.t2v_model = None
        self.m2v_model_mi2v = None
        self.m2v_model_mm2v = None
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.t2v_config = None
        self.m2v_config = None
        self.current_model = None  # è®°å½•å½“å‰åŠ è½½çš„æ¨¡å‹ç±»å‹
    
    def _unload_other_models(self, keep: str = None):
        """å¸è½½å…¶ä»–æ¨¡å‹ï¼Œåªä¿ç•™æŒ‡å®šçš„æ¨¡å‹"""
        logger.info(f"æ­£åœ¨å¸è½½å…¶ä»–æ¨¡å‹ (ä¿ç•™: {keep})...")
        logger.info(f"å¸è½½å‰å†…å­˜çŠ¶æ€: {get_memory_info()}")
        
        if keep != "t2v" and self.t2v_model is not None:
            logger.info("å¸è½½ T2V æ¨¡å‹...")
            # å…ˆå°†æ¨¡å‹ç§»åˆ° CPU å¹¶åˆ é™¤
            try:
                if hasattr(self.t2v_model, 'text_encoder'):
                    del self.t2v_model.text_encoder
                if hasattr(self.t2v_model, 'vae'):
                    del self.t2v_model.vae
                if hasattr(self.t2v_model, 'low_noise_model'):
                    del self.t2v_model.low_noise_model
                if hasattr(self.t2v_model, 'high_noise_model'):
                    del self.t2v_model.high_noise_model
            except:
                pass
            del self.t2v_model
            self.t2v_model = None
            gc.collect()
            torch.cuda.empty_cache()
        
        if keep != "mi2v" and self.m2v_model_mi2v is not None:
            logger.info("å¸è½½ M2V (MI2V) æ¨¡å‹...")
            try:
                if hasattr(self.m2v_model_mi2v, 'text_encoder'):
                    del self.m2v_model_mi2v.text_encoder
                if hasattr(self.m2v_model_mi2v, 'vae'):
                    del self.m2v_model_mi2v.vae
                if hasattr(self.m2v_model_mi2v, 'low_noise_model'):
                    del self.m2v_model_mi2v.low_noise_model
                if hasattr(self.m2v_model_mi2v, 'high_noise_model'):
                    del self.m2v_model_mi2v.high_noise_model
            except:
                pass
            del self.m2v_model_mi2v
            self.m2v_model_mi2v = None
            gc.collect()
            torch.cuda.empty_cache()
        
        if keep != "mm2v" and self.m2v_model_mm2v is not None:
            logger.info("å¸è½½ M2V (MM2V) æ¨¡å‹...")
            try:
                if hasattr(self.m2v_model_mm2v, 'text_encoder'):
                    del self.m2v_model_mm2v.text_encoder
                if hasattr(self.m2v_model_mm2v, 'vae'):
                    del self.m2v_model_mm2v.vae
                if hasattr(self.m2v_model_mm2v, 'low_noise_model'):
                    del self.m2v_model_mm2v.low_noise_model
                if hasattr(self.m2v_model_mm2v, 'high_noise_model'):
                    del self.m2v_model_mm2v.high_noise_model
            except:
                pass
            del self.m2v_model_mm2v
            self.m2v_model_mm2v = None
            gc.collect()
            torch.cuda.empty_cache()
        
        # å¼ºåˆ¶å¤šæ¬¡åƒåœ¾å›æ”¶
        for _ in range(3):
            gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        
        logger.info(f"æ¨¡å‹å¸è½½å®Œæˆï¼Œå†…å­˜çŠ¶æ€: {get_memory_info()}")
        
    def load_t2v_model(self):
        """åŠ è½½ T2V æ¨¡å‹"""
        if self.t2v_model is not None:
            logger.info("T2V æ¨¡å‹å·²åŠ è½½")
            return
        
        # å…ˆå¸è½½å…¶ä»–æ¨¡å‹
        self._unload_other_models(keep="t2v")
        
        logger.info("æ­£åœ¨åŠ è½½ T2V æ¨¡å‹...")
        self.t2v_config = WAN_CONFIGS["t2v-A14B"]
        
        self.t2v_model = wan.WanT2V(
            config=self.t2v_config,
            checkpoint_dir=str(T2V_MODEL_PATH),
            device_id=0,
            rank=0,
            t5_fsdp=False,
            dit_fsdp=False,
            use_sp=False,
            t5_cpu=False,
        )
        self.current_model = "t2v"
        logger.info("T2V æ¨¡å‹åŠ è½½å®Œæˆ")
        
    def load_m2v_model(self, mode="mi2v"):
        """åŠ è½½ M2V æ¨¡å‹
        
        Args:
            mode: "mi2v" æˆ– "mm2v"
        """
        if mode == "mi2v":
            if self.m2v_model_mi2v is not None:
                logger.info("M2V (MI2V) æ¨¡å‹å·²åŠ è½½")
                return self.m2v_model_mi2v
            lora_path = LORA_MI2V_PATH
        else:
            if self.m2v_model_mm2v is not None:
                logger.info("M2V (MM2V) æ¨¡å‹å·²åŠ è½½")
                return self.m2v_model_mm2v
            lora_path = LORA_MM2V_PATH
        
        # å…ˆå¸è½½å…¶ä»–æ¨¡å‹ï¼ˆåŒ…æ‹¬ T2Vï¼‰
        self._unload_other_models(keep=mode)
        
        logger.info(f"æ­£åœ¨åŠ è½½ M2V ({mode.upper()}) æ¨¡å‹...")
        logger.info(f"å†…å­˜çŠ¶æ€: {get_memory_info()}")
        
        self.m2v_config = WAN_CONFIGS["m2v-A14B"]
        
        # é…ç½® LoRA æƒé‡è·¯å¾„
        self.m2v_config.low_noise_lora.weight = os.path.join(str(lora_path), "backbone_low_noise.safetensors")
        self.m2v_config.high_noise_lora.weight = os.path.join(str(lora_path), "backbone_high_noise.safetensors")
        self.m2v_config.low_noise_lora.r = self.m2v_config.low_noise_lora.lora_alpha = DEFAULT_LORA_RANK
        self.m2v_config.high_noise_lora.r = self.m2v_config.high_noise_lora.lora_alpha = DEFAULT_LORA_RANK
        
        m2v_model = wan.WanM2V(
            config=self.m2v_config,
            checkpoint_dir=str(I2V_MODEL_PATH),
            device_id=0,
            rank=0,
            t5_fsdp=False,
            dit_fsdp=False,
            use_sp=False,
            t5_cpu=False,
        )
        
        if mode == "mi2v":
            self.m2v_model_mi2v = m2v_model
        else:
            self.m2v_model_mm2v = m2v_model
        
        self.current_model = mode
        logger.info(f"M2V ({mode.upper()}) æ¨¡å‹åŠ è½½å®Œæˆ")
        logger.info(f"å†…å­˜çŠ¶æ€: {get_memory_info()}")
        return m2v_model
    
    def unload_all(self):
        """å¸è½½æ‰€æœ‰æ¨¡å‹"""
        self._unload_other_models(keep=None)
        self.current_model = None
        logger.info("æ‰€æœ‰æ¨¡å‹å·²å¸è½½")


# å…¨å±€æ¨¡å‹ç®¡ç†å™¨
model_manager = ModelManager()


# ==================== è¾…åŠ©å‡½æ•° ====================
def get_story_files() -> List[str]:
    """è·å–æ‰€æœ‰æ•…äº‹è„šæœ¬æ–‡ä»¶"""
    story_files = list(STORY_DIR.glob("*.json"))
    return [f.stem for f in sorted(story_files)]


def load_story_script(story_name: str) -> Dict[str, Any]:
    """åŠ è½½æ•…äº‹è„šæœ¬"""
    story_path = STORY_DIR / f"{story_name}.json"
    with open(story_path, "r", encoding="utf-8") as f:
        return json5.load(f)


def get_story_preview(story_name: str) -> str:
    """è·å–æ•…äº‹é¢„è§ˆä¿¡æ¯"""
    if not story_name:
        return "è¯·é€‰æ‹©ä¸€ä¸ªæ•…äº‹è„šæœ¬"
    
    try:
        script = load_story_script(story_name)
        preview = f"## ğŸ“– {script.get('story_name', story_name)}\n\n"
        preview += f"**æ•…äº‹æ¦‚è¿°:**\n{script.get('story_overview', 'æ— ')}\n\n"
        
        scenes = script.get("scenes", [])
        preview += f"**åœºæ™¯æ•°é‡:** {len(scenes)}\n\n"
        
        total_shots = sum(len(scene.get("video_prompts", [])) for scene in scenes)
        preview += f"**æ€»é•œå¤´æ•°:** {total_shots}\n\n"
        
        preview += "---\n### åœºæ™¯è¯¦æƒ…:\n"
        for scene in scenes:
            scene_num = scene.get("scene_num", "?")
            prompts = scene.get("video_prompts", [])
            cuts = scene.get("cut", [])
            preview += f"\n**åœºæ™¯ {scene_num}** ({len(prompts)} ä¸ªé•œå¤´):\n"
            for i, prompt in enumerate(prompts):
                cut_info = "ğŸ¬ æ–°é•œå¤´" if (i < len(cuts) and cuts[i]) else "â¡ï¸ è¿ç»­"
                preview += f"- {cut_info}: {prompt[:100]}{'...' if len(prompt) > 100 else ''}\n"
        
        return preview
    except Exception as e:
        return f"åŠ è½½æ•…äº‹è„šæœ¬å¤±è´¥: {str(e)}"


def create_output_dir(story_name: str) -> Path:
    """åˆ›å»ºè¾“å‡ºç›®å½•"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = OUTPUT_DIR / f"{story_name}_{timestamp}"
    output_path.mkdir(parents=True, exist_ok=True)
    return output_path


def concat_videos(output_dir: Path, output_name: str) -> Optional[str]:
    """åˆå¹¶è§†é¢‘"""
    videos = sorted(glob.glob(str(output_dir / "*.mp4")))
    if not videos:
        return None
    
    # è¿‡æ»¤æ‰å·²ç»åˆå¹¶çš„è§†é¢‘å’Œmotion_frames
    videos = [v for v in videos if not v.endswith(f"{output_name}.mp4") and "motion_frames" not in v]
    
    if not videos:
        return None
    
    list_path = output_dir / "concat_list.txt"
    with open(list_path, "w", encoding="utf-8") as f:
        for v in videos:
            f.write(f"file '{os.path.abspath(v)}'\n")
    
    out_path = output_dir / f"{output_name}.mp4"
    
    ret = subprocess.run(
        ["ffmpeg", "-f", "concat", "-safe", "0", "-i", str(list_path), "-c", "copy", "-y", str(out_path)],
        capture_output=True
    )
    
    if ret.returncode != 0:
        subprocess.run([
            "ffmpeg", "-f", "concat", "-safe", "0", "-i", str(list_path),
            "-c:v", "libx264", "-crf", "18", "-preset", "medium", "-pix_fmt", "yuv420p",
            "-c:a", "aac", "-b:a", "192k", "-r", "30", "-y", str(out_path)
        ], check=True)
    
    return str(out_path)


# ==================== æ ¸å¿ƒç”Ÿæˆå‡½æ•° ====================
def generate_first_shot_t2v(
    prompt: str,
    output_dir: Path,
    size: str,
    seed: int,
    guide_scale: float,
    frame_num: int = DEFAULT_FRAME_NUM,
    progress_callback=None
) -> Optional[str]:
    """ä½¿ç”¨ T2V æ¨¡å‹ç”Ÿæˆé¦–ä¸ªé•œå¤´"""
    logger.info(f"ä½¿ç”¨ T2V ç”Ÿæˆé¦–ä¸ªé•œå¤´: {prompt[:50]}...")
    logger.info(f"å†…å­˜çŠ¶æ€: {get_memory_info()}")
    
    # ç”Ÿæˆå‰æ¸…ç†å†…å­˜
    clear_memory()
    
    model_manager.load_t2v_model()
    t2v_model = model_manager.t2v_model
    t2v_config = model_manager.t2v_config
    
    logger.info(f"å¼€å§‹ T2V æ¨ç†ï¼Œå¸§æ•°: {frame_num}...")
    
    try:
        video = t2v_model.generate(
            prompt,
            size=SIZE_CONFIGS[size],
            frame_num=frame_num,  # ä½¿ç”¨è‡ªå®šä¹‰å¸§æ•°
            shift=t2v_config.sample_shift,
            sample_solver='unipc',
            sampling_steps=t2v_config.sample_steps,
            guide_scale=guide_scale,
            seed=seed,
            offload_model=USE_OFFLOAD_MODEL
        )
        logger.info(f"T2V æ¨ç†å®Œæˆï¼Œè§†é¢‘ tensor shape: {video.shape}")
        logger.info(f"å†…å­˜çŠ¶æ€: {get_memory_info()}")
        
        output_path = output_dir / "01_01.mp4"
        logger.info(f"æ­£åœ¨ä¿å­˜è§†é¢‘åˆ°: {output_path}")
        
        # ä½¿ç”¨ torch.no_grad() å‡å°‘å†…å­˜
        with torch.no_grad():
            save_video(
                tensor=video[None],
                save_file=str(output_path),
                fps=t2v_config.sample_fps,
                nrow=1,
                normalize=True,
                value_range=(-1, 1)
            )
        logger.info("è§†é¢‘ä¿å­˜å®Œæˆ")
        
        # å…ˆæ¸…ç†æ˜¾å­˜
        del video
        clear_memory()
        logger.info("æ˜¾å­˜å·²æ¸…ç†")
        
        # æå–å…³é”®å¸§ - ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        logger.info("æ­£åœ¨æå–å…³é”®å¸§...")
        extract_keyframes_simple(str(output_path), output_dir)
        logger.info("å…³é”®å¸§æå–å®Œæˆ")
        
        logger.info(f"é¦–ä¸ªé•œå¤´ç”Ÿæˆå®Œæˆ: {output_path}")
        return str(output_path)
        
    except Exception as e:
        logger.error(f"T2V ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        clear_memory()
        raise


def generate_next_shots_m2v(
    story_script: Dict[str, Any],
    output_dir: Path,
    size: str,
    max_memory_size: int,
    seed: int,
    guide_scale: float,
    mode: str = "mi2v",
    fix_keyframes: int = 3,
    skip_first: bool = True,
    frame_num: int = DEFAULT_FRAME_NUM,
    progress_callback=None
) -> List[str]:
    """ä½¿ç”¨ M2V æ¨¡å‹ç”Ÿæˆåç»­é•œå¤´"""
    logger.info(f"ä½¿ç”¨ M2V ({mode.upper()}) ç”Ÿæˆåç»­é•œå¤´...")
    logger.info(f"å†…å­˜çŠ¶æ€: {get_memory_info()}")
    
    # ç”Ÿæˆå‰æ¸…ç†å†…å­˜
    clear_memory()
    
    m2v_model = model_manager.load_m2v_model(mode)
    m2v_config = model_manager.m2v_config
    
    generated_videos = []
    
    for scene in story_script["scenes"]:
        scene_num = scene["scene_num"]
        
        for i, prompt in enumerate(scene["video_prompts"]):
            shot_num = i + 1
            
            # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªé•œå¤´ä¸” skip_first=Trueï¼Œè·³è¿‡
            if skip_first and scene_num == 1 and shot_num == 1:
                continue
            
            logger.info(f"ç”Ÿæˆåœºæ™¯ {scene_num} / é•œå¤´ {shot_num}: {prompt[:50]}...")
            logger.info(f"å†…å­˜çŠ¶æ€: {get_memory_info()}")
            
            if progress_callback:
                progress_callback(f"æ­£åœ¨ç”Ÿæˆåœºæ™¯ {scene_num} / é•œå¤´ {shot_num}...")
            
            # ç”Ÿæˆå‰æ¸…ç†å†…å­˜
            clear_memory()
            
            # è·å–è®°å¿†åº“
            memory_bank = sorted(glob.glob(str(output_dir / "*keyframe*.jpg")))
            if len(memory_bank) > max_memory_size:
                memory_bank = memory_bank[:fix_keyframes] + memory_bank[-(max_memory_size - fix_keyframes):]
            
            # ç¡®å®šé¦–å¸§å’Œè¿åŠ¨å¸§æ–‡ä»¶
            is_cut = scene["cut"][i] if i < len(scene.get("cut", [])) else True
            
            if mode == "mi2v" and not is_cut:
                first_frame_file = str(output_dir / "last_frame.jpg")
                if not os.path.exists(first_frame_file):
                    first_frame_file = None
            else:
                first_frame_file = None
            
            if mode == "mm2v" and not is_cut:
                motion_frames_file = str(output_dir / "motion_frames.mp4")
                if not os.path.exists(motion_frames_file):
                    motion_frames_file = None
            else:
                motion_frames_file = None
            
            try:
                video = m2v_model.generate(
                    prompt,
                    memory_bank,
                    first_frame_file=first_frame_file,
                    motion_frames_file=motion_frames_file,
                    max_area=MAX_AREA_CONFIGS[size],
                    frame_num=frame_num,  # ä½¿ç”¨è‡ªå®šä¹‰å¸§æ•°
                    shift=m2v_config.sample_shift,
                    sample_solver='unipc',
                    sampling_steps=m2v_config.sample_steps,
                    guide_scale=guide_scale,
                    seed=seed + i,
                    offload_model=USE_OFFLOAD_MODEL
                )
                
                # å¤„ç†è§†é¢‘å¸§
                if first_frame_file is not None:
                    video = video[:, 1:]
                elif motion_frames_file is not None:
                    video = video[:, 5:]
                
                output_path = output_dir / f"{scene_num:02d}_{shot_num:02d}.mp4"
                
                with torch.no_grad():
                    save_video(
                        tensor=video[None],
                        save_file=str(output_path),
                        fps=m2v_config.sample_fps,
                        nrow=1,
                        normalize=True,
                        value_range=(-1, 1)
                    )
                
                # å…ˆæ¸…ç†æ˜¾å­˜
                del video
                clear_memory()
                
                # æå–å…³é”®å¸§ - ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                extract_keyframes_simple(str(output_path), output_dir)
                
                generated_videos.append(str(output_path))
                logger.info(f"é•œå¤´ç”Ÿæˆå®Œæˆ: {output_path}")
                
            except Exception as e:
                logger.error(f"é•œå¤´ç”Ÿæˆå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                clear_memory()
                continue
    
    return generated_videos


# ==================== Gradio ç•Œé¢å‡½æ•° ====================
def generate_story_video(
    story_name: str,
    size: str,
    max_memory_size: int,
    seed: int,
    guide_scale: float,
    mode: str,
    use_t2v_first: bool,
    frame_num: int = DEFAULT_FRAME_NUM,
    progress=gr.Progress()
):
    """ç”Ÿæˆå®Œæ•´æ•…äº‹è§†é¢‘çš„ä¸»å‡½æ•°"""
    if not story_name:
        return None, None, "âŒ è¯·é€‰æ‹©ä¸€ä¸ªæ•…äº‹è„šæœ¬"
    
    try:
        progress(0, desc="æ­£åœ¨å‡†å¤‡...")
        
        # åŠ è½½æ•…äº‹è„šæœ¬
        story_script = load_story_script(story_name)
        output_dir = create_output_dir(story_name)
        
        log_messages = [f"ğŸš€ å¼€å§‹ç”Ÿæˆæ•…äº‹è§†é¢‘: {story_script.get('story_name', story_name)}"]
        log_messages.append(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        log_messages.append(f"ğŸï¸ å¸§æ•°è®¾ç½®: {frame_num} (é»˜è®¤ 81ï¼Œå‡å°‘å¸§æ•°å¯èŠ‚çœå†…å­˜)")
        
        total_scenes = len(story_script.get("scenes", []))
        total_shots = sum(len(scene.get("video_prompts", [])) for scene in story_script.get("scenes", []))
        
        log_messages.append(f"ğŸ“Š æ€»åœºæ™¯æ•°: {total_scenes}, æ€»é•œå¤´æ•°: {total_shots}")
        
        current_shot = 0
        
        # ç”Ÿæˆé¦–ä¸ªé•œå¤´
        if use_t2v_first:
            progress(0.1, desc="æ­£åœ¨ä½¿ç”¨ T2V ç”Ÿæˆé¦–ä¸ªé•œå¤´...")
            first_prompt = story_script["scenes"][0]["video_prompts"][0]
            log_messages.append(f"\nğŸ¬ ä½¿ç”¨ T2V ç”Ÿæˆé¦–ä¸ªé•œå¤´...")
            log_messages.append(f"   Prompt: {first_prompt[:100]}...")
            
            first_video = generate_first_shot_t2v(
                prompt=first_prompt,
                output_dir=output_dir,
                size=size,
                seed=seed,
                guide_scale=guide_scale,
                frame_num=frame_num
            )
            
            if first_video:
                log_messages.append(f"âœ… é¦–ä¸ªé•œå¤´ç”Ÿæˆå®Œæˆ: {Path(first_video).name}")
            current_shot = 1
        
        # ç”Ÿæˆåç»­é•œå¤´
        progress(0.2, desc=f"æ­£åœ¨ä½¿ç”¨ M2V ({mode.upper()}) ç”Ÿæˆåç»­é•œå¤´...")
        log_messages.append(f"\nğŸ¬ ä½¿ç”¨ M2V ({mode.upper()}) ç”Ÿæˆåç»­é•œå¤´...")
        
        def progress_callback(msg):
            progress(0.2 + 0.7 * (current_shot / total_shots), desc=msg)
        
        generated_videos = generate_next_shots_m2v(
            story_script=story_script,
            output_dir=output_dir,
            size=size,
            max_memory_size=max_memory_size,
            seed=seed,
            guide_scale=guide_scale,
            mode=mode,
            skip_first=use_t2v_first,
            frame_num=frame_num,
            progress_callback=progress_callback
        )
        
        for v in generated_videos:
            log_messages.append(f"âœ… é•œå¤´ç”Ÿæˆå®Œæˆ: {Path(v).name}")
        
        # åˆå¹¶è§†é¢‘
        progress(0.95, desc="æ­£åœ¨åˆå¹¶è§†é¢‘...")
        log_messages.append(f"\nğŸ”— æ­£åœ¨åˆå¹¶æ‰€æœ‰è§†é¢‘...")
        
        final_video = concat_videos(output_dir, story_name)
        
        if final_video:
            log_messages.append(f"âœ… æœ€ç»ˆè§†é¢‘: {final_video}")
        
        progress(1.0, desc="å®Œæˆ!")
        log_messages.append(f"\nğŸ‰ æ•…äº‹è§†é¢‘ç”Ÿæˆå®Œæˆ!")
        
        # è·å–æ‰€æœ‰ç”Ÿæˆçš„è§†é¢‘
        all_videos = sorted(glob.glob(str(output_dir / "*.mp4")))
        video_gallery = [v for v in all_videos if "motion_frames" not in v]
        
        return final_video, video_gallery, "\n".join(log_messages)
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        logger.error(error_msg)
        return None, None, error_msg


def generate_single_shot(
    prompt: str,
    memory_images: List[str],
    first_frame: Optional[str],
    size: str,
    seed: int,
    guide_scale: float,
    mode: str,
    frame_num: int = DEFAULT_FRAME_NUM,
    progress=gr.Progress()
):
    """ç”Ÿæˆå•ä¸ªé•œå¤´"""
    if not prompt:
        return None, "âŒ è¯·è¾“å…¥ Prompt"
    
    try:
        progress(0.1, desc="æ­£åœ¨å‡†å¤‡...")
        
        # æ¸…ç†å†…å­˜
        clear_memory()
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = OUTPUT_DIR / f"single_shot_{timestamp}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        log_messages = [f"ğŸš€ å¼€å§‹ç”Ÿæˆå•é•œå¤´è§†é¢‘"]
        log_messages.append(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        log_messages.append(f"ğŸ“ Prompt: {prompt[:100]}...")
        log_messages.append(f"ğŸï¸ å¸§æ•°: {frame_num}")
        
        # å¤„ç†è®°å¿†å›¾ç‰‡
        memory_bank = []
        if memory_images:
            for i, img_path in enumerate(memory_images):
                if img_path:
                    # å¤åˆ¶å›¾ç‰‡åˆ°è¾“å‡ºç›®å½•
                    dst_path = output_dir / f"00_00_keyframe{i}.jpg"
                    shutil.copy(img_path, dst_path)
                    memory_bank.append(str(dst_path))
            log_messages.append(f"ğŸ“· è®°å¿†å›¾ç‰‡æ•°é‡: {len(memory_bank)}")
        
        # å¤„ç†é¦–å¸§
        first_frame_file = None
        if first_frame and mode == "mi2v":
            first_frame_file = str(output_dir / "last_frame.jpg")
            shutil.copy(first_frame, first_frame_file)
            log_messages.append(f"ğŸ–¼ï¸ ä½¿ç”¨é¦–å¸§: {first_frame}")
        
        progress(0.2, desc=f"æ­£åœ¨ä½¿ç”¨ M2V ({mode.upper()}) ç”Ÿæˆ...")
        
        m2v_model = model_manager.load_m2v_model(mode)
        m2v_config = model_manager.m2v_config
        
        video = m2v_model.generate(
            prompt,
            memory_bank,
            first_frame_file=first_frame_file,
            motion_frames_file=None,
            max_area=MAX_AREA_CONFIGS[size],
            frame_num=frame_num,  # ä½¿ç”¨è‡ªå®šä¹‰å¸§æ•°
            shift=m2v_config.sample_shift,
            sample_solver='unipc',
            sampling_steps=m2v_config.sample_steps,
            guide_scale=guide_scale,
            seed=seed,
            offload_model=USE_OFFLOAD_MODEL
        )
        
        if first_frame_file is not None:
            video = video[:, 1:]
        
        output_path = output_dir / "output.mp4"
        
        with torch.no_grad():
            save_video(
                tensor=video[None],
                save_file=str(output_path),
                fps=m2v_config.sample_fps,
                nrow=1,
                normalize=True,
                value_range=(-1, 1)
            )
        
        del video
        clear_memory()
        
        progress(1.0, desc="å®Œæˆ!")
        log_messages.append(f"\nâœ… è§†é¢‘ç”Ÿæˆå®Œæˆ: {output_path}")
        
        return str(output_path), "\n".join(log_messages)
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        logger.error(error_msg)
        return None, error_msg


def generate_t2v_single(
    prompt: str,
    size: str,
    seed: int,
    guide_scale: float,
    frame_num: int = DEFAULT_FRAME_NUM,
    progress=gr.Progress()
):
    """ä½¿ç”¨ T2V ç”Ÿæˆå•ä¸ªè§†é¢‘"""
    if not prompt:
        return None, "âŒ è¯·è¾“å…¥ Prompt"
    
    try:
        progress(0.1, desc="æ­£åœ¨å‡†å¤‡...")
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = OUTPUT_DIR / f"t2v_{timestamp}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        log_messages = [f"ğŸš€ å¼€å§‹ä½¿ç”¨ T2V ç”Ÿæˆè§†é¢‘"]
        log_messages.append(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        log_messages.append(f"ğŸ“ Prompt: {prompt[:100]}...")
        log_messages.append(f"ğŸï¸ å¸§æ•°: {frame_num}")
        
        progress(0.2, desc="æ­£åœ¨ä½¿ç”¨ T2V ç”Ÿæˆ...")
        
        output_path = generate_first_shot_t2v(
            prompt=prompt,
            output_dir=output_dir,
            size=size,
            seed=seed,
            guide_scale=guide_scale,
            frame_num=frame_num
        )
        
        progress(1.0, desc="å®Œæˆ!")
        log_messages.append(f"\nâœ… è§†é¢‘ç”Ÿæˆå®Œæˆ: {output_path}")
        
        return output_path, "\n".join(log_messages)
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        logger.error(error_msg)
        return None, error_msg


# ==================== åˆ›å»º Gradio ç•Œé¢ ====================
def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    # è·å–æ•…äº‹åˆ—è¡¨
    story_list = get_story_files()
    
    # è‡ªå®šä¹‰ CSS
    custom_css = """
    .gradio-container {
        max-width: 1400px !important;
    }
    .story-preview {
        max-height: 400px;
        overflow-y: auto;
    }
    """
    
    with gr.Blocks(
        title="ğŸ¬ StoryMem - æ•…äº‹è§†é¢‘ç”Ÿæˆå™¨",
        css=custom_css,
        theme=gr.themes.Soft()
    ) as demo:
        gr.Markdown("""
        # ğŸ¬ StoryMem - æ•…äº‹è§†é¢‘ç”Ÿæˆå™¨
        
        åŸºäº StoryMem çš„æ•…äº‹è§†é¢‘ç”Ÿæˆå·¥å…·ï¼Œæ”¯æŒæ–‡æœ¬åˆ°è§†é¢‘ (T2V) å’Œè®°å¿†å¢å¼ºè§†é¢‘ç”Ÿæˆ (M2V)ã€‚
        
        **åŠŸèƒ½ç‰¹ç‚¹:**
        - ğŸ“– å®Œæ•´æ•…äº‹ç”Ÿæˆï¼šåŠ è½½æ•…äº‹è„šæœ¬ï¼Œè‡ªåŠ¨ç”Ÿæˆå¤šé•œå¤´è§†é¢‘
        - ğŸ¯ å•é•œå¤´ç”Ÿæˆï¼šçµæ´»ç”Ÿæˆå•ä¸ªè§†é¢‘ç‰‡æ®µ
        - ğŸ–¼ï¸ è®°å¿†å¢å¼ºï¼šä½¿ç”¨å‚è€ƒå›¾ç‰‡ä¿æŒè§’è‰²ä¸€è‡´æ€§
        - ğŸ”— åœºæ™¯è¿æ¥ï¼šMI2V/MM2V æ¨¡å¼å®ç°ç›¸é‚»é•œå¤´çš„å¹³æ»‘è¿‡æ¸¡
        """)
        
        with gr.Tabs():
            # ==================== Tab 1: å®Œæ•´æ•…äº‹ç”Ÿæˆ ====================
            with gr.TabItem("ğŸ“– å®Œæ•´æ•…äº‹ç”Ÿæˆ", id="story"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### âš™ï¸ ç”Ÿæˆè®¾ç½®")
                        
                        story_dropdown = gr.Dropdown(
                            label="é€‰æ‹©æ•…äº‹è„šæœ¬",
                            choices=story_list,
                            value=story_list[0] if story_list else None,
                            interactive=True
                        )
                        
                        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°æ•…äº‹åˆ—è¡¨", size="sm")
                        
                        with gr.Group():
                            size_dropdown = gr.Dropdown(
                                label="è§†é¢‘åˆ†è¾¨ç‡",
                                choices=list(SIZE_CONFIGS.keys()),
                                value=DEFAULT_SIZE
                            )
                            
                            frame_num_slider = gr.Slider(
                                label="è§†é¢‘å¸§æ•°",
                                minimum=17,
                                maximum=81,
                                value=DEFAULT_FRAME_NUM,
                                step=4,
                                info="å¸§æ•°è¶Šå°‘å†…å­˜å ç”¨è¶Šå° (17â‰ˆ1ç§’, 41â‰ˆ2.5ç§’, 81â‰ˆ5ç§’)"
                            )
                            
                            max_memory = gr.Slider(
                                label="æœ€å¤§è®°å¿†å¸§æ•°",
                                minimum=1,
                                maximum=20,
                                value=DEFAULT_MAX_MEMORY_SIZE,
                                step=1
                            )
                            
                            seed_input = gr.Number(
                                label="éšæœºç§å­ (0=å›ºå®š, -1=éšæœº)",
                                value=DEFAULT_SEED,
                                precision=0
                            )
                            
                            guide_scale = gr.Slider(
                                label="å¼•å¯¼å¼ºåº¦ (Guidance Scale)",
                                minimum=1.0,
                                maximum=10.0,
                                value=DEFAULT_SAMPLE_GUIDE_SCALE,
                                step=0.5
                            )
                        
                        with gr.Group():
                            mode_radio = gr.Radio(
                                label="M2V æ¨¡å¼",
                                choices=["mi2v", "mm2v"],
                                value="mi2v",
                                info="MI2V: é¦–å¸§æ¡ä»¶è¿æ¥ | MM2V: è¿åŠ¨å¸§æ¡ä»¶è¿æ¥"
                            )
                            
                            t2v_first = gr.Checkbox(
                                label="ä½¿ç”¨ T2V ç”Ÿæˆé¦–ä¸ªé•œå¤´",
                                value=True,
                                info="å‹¾é€‰åå°†ä½¿ç”¨ T2V æ¨¡å‹ç”Ÿæˆç¬¬ä¸€ä¸ªé•œå¤´ä½œä¸ºåˆå§‹è®°å¿†"
                            )
                        
                        generate_btn = gr.Button("ğŸš€ å¼€å§‹ç”Ÿæˆ", variant="primary", size="lg")
                    
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ“‹ æ•…äº‹é¢„è§ˆ")
                        story_preview = gr.Markdown(
                            value=get_story_preview(story_list[0]) if story_list else "æ— æ•…äº‹è„šæœ¬",
                            elem_classes=["story-preview"]
                        )
                
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("### ğŸ¬ ç”Ÿæˆç»“æœ")
                        output_video = gr.Video(label="æœ€ç»ˆè§†é¢‘")
                        
                    with gr.Column():
                        gr.Markdown("### ğŸ“¹ æ‰€æœ‰é•œå¤´")
                        output_gallery = gr.Gallery(
                            label="ç”Ÿæˆçš„è§†é¢‘ç‰‡æ®µ",
                            columns=3,
                            height="auto"
                        )
                
                output_log = gr.Textbox(
                    label="ğŸ“ ç”Ÿæˆæ—¥å¿—",
                    lines=10,
                    max_lines=20
                )
                
                # äº‹ä»¶ç»‘å®š
                story_dropdown.change(
                    fn=get_story_preview,
                    inputs=[story_dropdown],
                    outputs=[story_preview]
                )
                
                refresh_btn.click(
                    fn=lambda: gr.update(choices=get_story_files()),
                    outputs=[story_dropdown]
                )
                
                generate_btn.click(
                    fn=generate_story_video,
                    inputs=[
                        story_dropdown,
                        size_dropdown,
                        max_memory,
                        seed_input,
                        guide_scale,
                        mode_radio,
                        t2v_first,
                        frame_num_slider
                    ],
                    outputs=[output_video, output_gallery, output_log]
                )
            
            # ==================== Tab 2: å•é•œå¤´ç”Ÿæˆ (M2V) ====================
            with gr.TabItem("ğŸ¯ å•é•œå¤´ç”Ÿæˆ (M2V)", id="single"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### âš™ï¸ ç”Ÿæˆè®¾ç½®")
                        
                        single_prompt = gr.Textbox(
                            label="è§†é¢‘æè¿° (Prompt)",
                            placeholder="Enter your video prompt here...",
                            lines=4
                        )
                        
                        gr.Markdown("### ğŸ–¼ï¸ è®°å¿†å›¾ç‰‡ (å¯é€‰)")
                        memory_images = gr.File(
                            label="ä¸Šä¼ å‚è€ƒå›¾ç‰‡ (å¯å¤šé€‰)",
                            file_count="multiple",
                            file_types=["image"]
                        )
                        
                        first_frame_input = gr.Image(
                            label="é¦–å¸§å›¾ç‰‡ (MI2V æ¨¡å¼å¯ç”¨)",
                            type="filepath"
                        )
                        
                        with gr.Group():
                            single_size = gr.Dropdown(
                                label="è§†é¢‘åˆ†è¾¨ç‡",
                                choices=list(SIZE_CONFIGS.keys()),
                                value=DEFAULT_SIZE
                            )
                            
                            single_frame_num = gr.Slider(
                                label="è§†é¢‘å¸§æ•°",
                                minimum=17,
                                maximum=81,
                                value=DEFAULT_FRAME_NUM,
                                step=4,
                                info="å¸§æ•°è¶Šå°‘å†…å­˜å ç”¨è¶Šå° (17â‰ˆ1ç§’, 41â‰ˆ2.5ç§’, 81â‰ˆ5ç§’)"
                            )
                            
                            single_seed = gr.Number(
                                label="éšæœºç§å­",
                                value=DEFAULT_SEED,
                                precision=0
                            )
                            
                            single_guide = gr.Slider(
                                label="å¼•å¯¼å¼ºåº¦",
                                minimum=1.0,
                                maximum=10.0,
                                value=DEFAULT_SAMPLE_GUIDE_SCALE,
                                step=0.5
                            )
                            
                            single_mode = gr.Radio(
                                label="M2V æ¨¡å¼",
                                choices=["mi2v", "mm2v"],
                                value="mi2v"
                            )
                        
                        single_generate_btn = gr.Button("ğŸš€ ç”Ÿæˆè§†é¢‘", variant="primary", size="lg")
                    
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ¬ ç”Ÿæˆç»“æœ")
                        single_output_video = gr.Video(label="ç”Ÿæˆçš„è§†é¢‘")
                        single_output_log = gr.Textbox(
                            label="ğŸ“ ç”Ÿæˆæ—¥å¿—",
                            lines=10
                        )
                
                # äº‹ä»¶ç»‘å®š
                single_generate_btn.click(
                    fn=generate_single_shot,
                    inputs=[
                        single_prompt,
                        memory_images,
                        first_frame_input,
                        single_size,
                        single_seed,
                        single_guide,
                        single_mode,
                        single_frame_num
                    ],
                    outputs=[single_output_video, single_output_log]
                )
            
            # ==================== Tab 3: æ–‡æœ¬åˆ°è§†é¢‘ (T2V) ====================
            with gr.TabItem("ğŸ“ æ–‡æœ¬åˆ°è§†é¢‘ (T2V)", id="t2v"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("### âš™ï¸ ç”Ÿæˆè®¾ç½®")
                        
                        t2v_prompt = gr.Textbox(
                            label="è§†é¢‘æè¿° (Prompt)",
                            placeholder="Enter your video prompt here...",
                            lines=4
                        )
                        
                        with gr.Group():
                            t2v_size = gr.Dropdown(
                                label="è§†é¢‘åˆ†è¾¨ç‡",
                                choices=list(SIZE_CONFIGS.keys()),
                                value=DEFAULT_SIZE
                            )
                            
                            t2v_frame_num = gr.Slider(
                                label="è§†é¢‘å¸§æ•°",
                                minimum=17,
                                maximum=81,
                                value=DEFAULT_FRAME_NUM,
                                step=4,
                                info="å¸§æ•°è¶Šå°‘å†…å­˜å ç”¨è¶Šå° (17â‰ˆ1ç§’, 41â‰ˆ2.5ç§’, 81â‰ˆ5ç§’)"
                            )
                            
                            t2v_seed = gr.Number(
                                label="éšæœºç§å­",
                                value=DEFAULT_SEED,
                                precision=0
                            )
                            
                            t2v_guide = gr.Slider(
                                label="å¼•å¯¼å¼ºåº¦",
                                minimum=1.0,
                                maximum=10.0,
                                value=DEFAULT_SAMPLE_GUIDE_SCALE,
                                step=0.5
                            )
                        
                        t2v_generate_btn = gr.Button("ğŸš€ ç”Ÿæˆè§†é¢‘", variant="primary", size="lg")
                    
                    with gr.Column(scale=1):
                        gr.Markdown("### ğŸ¬ ç”Ÿæˆç»“æœ")
                        t2v_output_video = gr.Video(label="ç”Ÿæˆçš„è§†é¢‘")
                        t2v_output_log = gr.Textbox(
                            label="ğŸ“ ç”Ÿæˆæ—¥å¿—",
                            lines=10
                        )
                
                # ç¤ºä¾‹ Prompts
                gr.Markdown("### ğŸ’¡ ç¤ºä¾‹ Prompts")
                gr.Examples(
                    examples=[
                        ["A cat walking on the beach at sunset, cinematic lighting, 4K quality"],
                        ["An astronaut floating in space with Earth in the background, realistic"],
                        ["A beautiful forest with sunlight streaming through the trees, peaceful atmosphere"],
                        ["A futuristic city at night with neon lights, cyberpunk style"],
                    ],
                    inputs=[t2v_prompt]
                )
                
                # äº‹ä»¶ç»‘å®š
                t2v_generate_btn.click(
                    fn=generate_t2v_single,
                    inputs=[
                        t2v_prompt,
                        t2v_size,
                        t2v_seed,
                        t2v_guide,
                        t2v_frame_num
                    ],
                    outputs=[t2v_output_video, t2v_output_log]
                )
            
            # ==================== Tab 4: æ•…äº‹è„šæœ¬ç¼–è¾‘å™¨ ====================
            with gr.TabItem("âœï¸ æ•…äº‹è„šæœ¬ç¼–è¾‘å™¨", id="editor"):
                gr.Markdown("""
                ### ğŸ“ æ•…äº‹è„šæœ¬ç¼–è¾‘å™¨
                
                åœ¨è¿™é‡Œå¯ä»¥åˆ›å»ºæˆ–ç¼–è¾‘æ•…äº‹è„šæœ¬ã€‚è„šæœ¬ä½¿ç”¨ JSON æ ¼å¼ã€‚
                """)
                
                with gr.Row():
                    with gr.Column(scale=1):
                        editor_story = gr.Dropdown(
                            label="é€‰æ‹©è¦ç¼–è¾‘çš„æ•…äº‹",
                            choices=["[æ–°å»ºæ•…äº‹]"] + story_list,
                            value="[æ–°å»ºæ•…äº‹]"
                        )
                        
                        story_name_input = gr.Textbox(
                            label="æ•…äº‹åç§° (æ–‡ä»¶å)",
                            placeholder="my_story"
                        )
                        
                        load_btn = gr.Button("ğŸ“‚ åŠ è½½æ•…äº‹", size="sm")
                        save_btn = gr.Button("ğŸ’¾ ä¿å­˜æ•…äº‹", variant="primary")
                    
                    with gr.Column(scale=2):
                        script_editor = gr.Code(
                            label="æ•…äº‹è„šæœ¬ (JSON)",
                            language="json",
                            lines=30,
                            value='''{
  "story_name": "My Story",
  "story_overview": "A brief description of your story...",
  "scenes": [
    {
      "scene_num": 1,
      "video_prompts": [
        "First shot description...",
        "Second shot description..."
      ],
      "cut": [true, false]
    }
  ]
}'''
                        )
                
                editor_output = gr.Textbox(label="æ“ä½œç»“æœ", lines=3)
                
                def load_story_for_edit(story_name):
                    if story_name == "[æ–°å»ºæ•…äº‹]":
                        return '''{
  "story_name": "My Story",
  "story_overview": "A brief description of your story...",
  "scenes": [
    {
      "scene_num": 1,
      "video_prompts": [
        "First shot description...",
        "Second shot description..."
      ],
      "cut": [true, false]
    }
  ]
}''', ""
                    try:
                        story_path = STORY_DIR / f"{story_name}.json"
                        with open(story_path, "r", encoding="utf-8") as f:
                            content = f.read()
                        return content, f"âœ… å·²åŠ è½½: {story_name}.json"
                    except Exception as e:
                        return "", f"âŒ åŠ è½½å¤±è´¥: {str(e)}"
                
                def save_story_script(name, content):
                    if not name:
                        return "âŒ è¯·è¾“å…¥æ•…äº‹åç§°"
                    try:
                        # éªŒè¯ JSON æ ¼å¼
                        json5.loads(content)
                        
                        story_path = STORY_DIR / f"{name}.json"
                        with open(story_path, "w", encoding="utf-8") as f:
                            f.write(content)
                        return f"âœ… å·²ä¿å­˜: {story_path}"
                    except json5.JSON5DecodeError as e:
                        return f"âŒ JSON æ ¼å¼é”™è¯¯: {str(e)}"
                    except Exception as e:
                        return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"
                
                load_btn.click(
                    fn=load_story_for_edit,
                    inputs=[editor_story],
                    outputs=[script_editor, editor_output]
                )
                
                save_btn.click(
                    fn=save_story_script,
                    inputs=[story_name_input, script_editor],
                    outputs=[editor_output]
                )
        
        # åº•éƒ¨ä¿¡æ¯
        gr.Markdown("""
        ---
        ### ğŸ“Œ ä½¿ç”¨è¯´æ˜
        
        1. **å®Œæ•´æ•…äº‹ç”Ÿæˆ**: é€‰æ‹©é¢„è®¾çš„æ•…äº‹è„šæœ¬ï¼Œè‡ªåŠ¨ç”Ÿæˆå®Œæ•´çš„å¤šé•œå¤´è§†é¢‘
        2. **å•é•œå¤´ç”Ÿæˆ (M2V)**: ä½¿ç”¨è®°å¿†å›¾ç‰‡ç”Ÿæˆå•ä¸ªè§†é¢‘ç‰‡æ®µï¼Œä¿æŒè§’è‰²ä¸€è‡´æ€§
        3. **æ–‡æœ¬åˆ°è§†é¢‘ (T2V)**: ç›´æ¥ä»æ–‡æœ¬æè¿°ç”Ÿæˆè§†é¢‘
        4. **æ•…äº‹è„šæœ¬ç¼–è¾‘å™¨**: åˆ›å»ºæˆ–ç¼–è¾‘è‡ªå®šä¹‰æ•…äº‹è„šæœ¬
        
        **å…³äº M2V æ¨¡å¼:**
        - **MI2V**: Memory + First-frame Image - ä½¿ç”¨ä¸Šä¸€é•œå¤´çš„æœ€åä¸€å¸§ä½œä¸ºæ–°é•œå¤´çš„é¦–å¸§æ¡ä»¶
        - **MM2V**: Memory + Motion Frames - ä½¿ç”¨ä¸Šä¸€é•œå¤´çš„æœ€å5å¸§ä½œä¸ºè¿åŠ¨æ¡ä»¶
        
        **æç¤º:** 
        - é¦–æ¬¡è¿è¡Œéœ€è¦åŠ è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…
        - å»ºè®®ä½¿ç”¨ 832*480 åˆ†è¾¨ç‡ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
        - è®¾ç½®éšæœºç§å­ä¸º 0 å¯ä»¥è·å¾—å¯å¤ç°çš„ç»“æœ
        """)
    
    return demo


# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == "__main__":
    # åˆ›å»ºè¾“å‡ºç›®å½•
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    logger.info("=" * 50)
    logger.info("StoryMem Gradio Web ç•Œé¢")
    logger.info("=" * 50)
    logger.info(f"é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")
    logger.info(f"T2V æ¨¡å‹è·¯å¾„: {T2V_MODEL_PATH}")
    logger.info(f"I2V æ¨¡å‹è·¯å¾„: {I2V_MODEL_PATH}")
    logger.info(f"MI2V LoRA è·¯å¾„: {LORA_MI2V_PATH}")
    logger.info(f"MM2V LoRA è·¯å¾„: {LORA_MM2V_PATH}")
    logger.info(f"æ•…äº‹è„šæœ¬ç›®å½•: {STORY_DIR}")
    logger.info(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    logger.info(f"é»˜è®¤å¸§æ•°: {DEFAULT_FRAME_NUM} (åŸå§‹ 81 å¸§ï¼Œå‡å°‘å¸§æ•°ä»¥èŠ‚çœå†…å­˜)")
    logger.info(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        logger.info(f"GPU: {torch.cuda.get_device_name(0)}")
        logger.info(f"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    logger.info("=" * 50)
    
    # ä¸å†é¢„åŠ è½½æ¨¡å‹ï¼Œåœ¨ä½¿ç”¨æ—¶åŠ è½½ä»¥èŠ‚çœå†…å­˜
    logger.info("âš ï¸ æ¨¡å‹å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_ui()
    demo.queue(max_size=5)  # å‡å°‘é˜Ÿåˆ—å¤§å°
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
