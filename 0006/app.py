"""
MOVA Gradio Web Application
åŸºäº MOVA æ¨¡å‹çš„è§†é¢‘ç”Ÿæˆ Web åº”ç”¨
"""

import os
import gc
import sys
import tempfile
import uuid
from contextlib import contextmanager
from datetime import datetime

import gradio as gr
import torch
import torch.distributed as dist
from PIL import Image
from torch.distributed.device_mesh import DeviceMesh

# ä¿å­˜åŸå§‹çš„ tqdm æ¨¡å—ï¼Œç”¨äºé¿å… Gradio çš„ tqdm åŒ…è£…å†²çª
# è¿™æ˜¯ä¸šç•Œé€šç”¨åšæ³•ï¼šGradio ä¼š monkey-patch tqdm ä»¥æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œ
# ä½†è¿™å¯èƒ½ä¸æŸäº›åº“ï¼ˆå¦‚ diffusers pipelineï¼‰çš„ tqdm è°ƒç”¨å†²çªã€‚
# è§£å†³æ–¹æ¡ˆæ˜¯åœ¨è°ƒç”¨è¿™äº›åº“æ—¶ä¸´æ—¶æ¢å¤åŸå§‹ tqdmã€‚
import tqdm as _original_tqdm_module
_original_tqdm = _original_tqdm_module.tqdm
_original_tqdm_auto = None
try:
    from tqdm import auto as _tqdm_auto_module
    _original_tqdm_auto = _tqdm_auto_module.tqdm
except ImportError:
    pass

from mova.datasets.transforms.custom import crop_and_resize
from mova.diffusion.pipelines.pipeline_mova import MOVA
from mova.utils.data import save_video_with_audio


@contextmanager
def restore_original_tqdm():
    """
    ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼šä¸´æ—¶æ¢å¤åŸå§‹çš„ tqdm æ¨¡å—ã€‚
    
    Gradio ä¼šé€šè¿‡ monkey-patching æ›¿æ¢ tqdm.tqdm ä¸ºè‡ªå·±çš„ TqdmProgress ç±»ï¼Œ
    ä»¥ä¾¿åœ¨ UI ä¸Šæ˜¾ç¤ºè¿›åº¦æ¡ã€‚ä½†è¿™ä¼šå¯¼è‡´æŸäº›æƒ…å†µä¸‹å‡ºç° "list index out of range" é”™è¯¯ï¼Œ
    å› ä¸º Gradio çš„åŒ…è£…å™¨ä¾èµ–äºç‰¹å®šçš„è°ƒç”¨ä¸Šä¸‹æ–‡ã€‚
    
    è¿™ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨åœ¨æ‰§è¡Œ pipeline æ—¶ä¸´æ—¶æ¢å¤åŸå§‹çš„ tqdmï¼Œ
    ç¡®ä¿ pipeline å†…éƒ¨çš„ tqdm è°ƒç”¨ä¸å— Gradio åŒ…è£…å½±å“ã€‚
    
    è¿™æ˜¯ä¸šç•Œé€šç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œè¢« Hugging Face Spacesã€ComfyUI ç­‰å¹¿æ³›é‡‡ç”¨ã€‚
    """
    import tqdm
    import tqdm.auto
    
    # ä¿å­˜ Gradio åŒ…è£…åçš„ tqdm
    gradio_tqdm = tqdm.tqdm
    gradio_tqdm_auto = tqdm.auto.tqdm
    
    try:
        # ä¸´æ—¶æ¢å¤åŸå§‹ tqdm
        tqdm.tqdm = _original_tqdm
        tqdm.auto.tqdm = _original_tqdm_auto if _original_tqdm_auto else _original_tqdm
        yield
    finally:
        # æ¢å¤ Gradio çš„ tqdm åŒ…è£…
        tqdm.tqdm = gradio_tqdm
        tqdm.auto.tqdm = gradio_tqdm_auto

# é»˜è®¤è´Ÿé¢æç¤ºè¯
NEGATIVE_PROMPT = (
    "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œ"
    "æ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡"
)

# æ¨¡å‹è·¯å¾„
CKPT_PATH = "checkpoints/MOVA-720p/"

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "data/gradio_outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# å…¨å±€å˜é‡
pipe = None
mesh = None


def init_distributed():
    """åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ"""
    global mesh
    
    # è®¾ç½®å• GPU ç¯å¢ƒ
    os.environ["MASTER_ADDR"] = "localhost"
    os.environ["MASTER_PORT"] = "29500"
    os.environ["RANK"] = "0"
    os.environ["WORLD_SIZE"] = "1"
    os.environ["LOCAL_RANK"] = "0"
    
    local_rank = 0
    
    if not dist.is_initialized():
        dist.init_process_group(backend="nccl", device_id=torch.device("cuda", local_rank))
        torch.cuda.set_device(local_rank)
    
    rank = dist.get_rank()
    world_size = dist.get_world_size()
    
    cp_size = 1
    dp_size = world_size // cp_size
    mesh = DeviceMesh(
        "cuda",
        torch.arange(dist.get_world_size()).view(dp_size, cp_size),
        mesh_dim_names=("dp", "cp"),
    )
    
    return mesh


def load_model():
    """åŠ è½½ MOVA æ¨¡å‹"""
    global pipe, mesh
    
    if pipe is not None:
        return pipe, mesh
    
    print("æ­£åœ¨åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ...")
    mesh = init_distributed()
    
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {CKPT_PATH}")
    torch_dtype = torch.bfloat16
    pipe = MOVA.from_pretrained(CKPT_PATH, torch_dtype=torch_dtype)
    
    # ç›´æ¥åŠ è½½åˆ° GPUï¼Œä¸ä½¿ç”¨ offloadï¼ˆH20 æ˜¾å¡æœ‰ 141GB æ˜¾å­˜ï¼‰
    local_rank = int(os.environ.get("LOCAL_RANK", 0))
    pipe.to(torch.device("cuda", local_rank))
    
    print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
    return pipe, mesh


def generate_video(
    prompt: str,
    ref_image,
    height: int,
    width: int,
    num_frames: int,
    fps: float,
    num_inference_steps: int,
    cfg_scale: float,
    sigma_shift: float,
    seed: int,
    negative_prompt: str,
):
    """ç”Ÿæˆè§†é¢‘"""
    global pipe, mesh
    
    if pipe is None:
        pipe, mesh = load_model()
    
    if ref_image is None:
        raise gr.Error("è¯·ä¸Šä¼ å‚è€ƒå›¾ç‰‡ï¼")
    
    if not prompt.strip():
        raise gr.Error("è¯·è¾“å…¥æç¤ºè¯ï¼")
    
    try:
        # å¤„ç†å‚è€ƒå›¾ç‰‡
        if isinstance(ref_image, str):
            img = Image.open(ref_image).convert("RGB")
        else:
            img = Image.fromarray(ref_image).convert("RGB")
        
        ref_img = crop_and_resize(img, height=height, width=width)
        
        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(seed)
        
        print(f"å¼€å§‹ç”Ÿæˆè§†é¢‘...")
        print(f"æç¤ºè¯: {prompt[:100]}...")
        print(f"åˆ†è¾¨ç‡: {width}x{height}, å¸§æ•°: {num_frames}, FPS: {fps}")
        
        # ç”Ÿæˆè§†é¢‘å’ŒéŸ³é¢‘
        # ä½¿ç”¨ restore_original_tqdm ä¸Šä¸‹æ–‡ç®¡ç†å™¨é¿å… Gradio tqdm åŒ…è£…å†²çª
        with restore_original_tqdm():
            video, audio = pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_frames=num_frames,
                image=ref_img,
                height=height,
                width=width,
                video_fps=fps,
                num_inference_steps=num_inference_steps,
                sigma_shift=sigma_shift,
                cfg_scale=cfg_scale,
                seed=seed,
                cp_mesh=mesh["cp"],
                remove_video_dit=False,
            )
        
        # ä¿å­˜è§†é¢‘
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_id = str(uuid.uuid4())[:8]
        output_path = os.path.join(OUTPUT_DIR, f"mova_{timestamp}_{unique_id}.mp4")
        
        audio_save = audio[0].cpu().squeeze()
        
        save_video_with_audio(
            video[0],
            audio_save,
            output_path,
            fps=fps,
            sample_rate=pipe.audio_sample_rate,
            quality=9,
        )
        
        print(f"è§†é¢‘å·²ä¿å­˜åˆ°: {output_path}")
        
        # æ¸…ç†æ˜¾å­˜
        torch.cuda.empty_cache()
        gc.collect()
        
        return output_path
        
    except Exception as e:
        torch.cuda.empty_cache()
        gc.collect()
        raise gr.Error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")


# ç¤ºä¾‹æ•°æ®
SINGLE_PERSON_EXAMPLE = {
    "prompt": 'A man in a blue blazer and glasses speaks in a formal indoor setting, framed by wooden furniture and a filled bookshelf. Quiet room acoustics underscore his measured tone as he delivers his remarks. At one point, he says, "I would also say that this election in Germany wasn\'t surprising."',
    "ref_image": "./assets/single_person.jpg",
}

MULTI_PERSON_EXAMPLE = {
    "prompt": 'The scene shows a man and a child walking together through a park, surrounded by open greenery and a calm, everyday atmosphere. As they stroll side by side, the man turns his head toward the child and asks with mild curiosity, in English, "What do you want to do when you grow up?" The boy answers with clear confidence, saying, "A bond trader. That\'s what Don does, and he took me to his office." The man lets out a soft chuckle, then responds warmly, "It\'s a good profession." as their walk continues at an unhurried pace, the conversation settling into a quiet, reflective moment.',
    "ref_image": "./assets/multi_person.png",
}

NEWS_ANCHOR_EXAMPLE = {
    "prompt": 'A female news anchor sits at a modern broadcast desk with multiple screens behind her showing news graphics. The studio lighting is professional and bright. She looks directly at the camera and speaks clearly, saying "Breaking news tonight: scientists have made a remarkable discovery that could change how we understand climate change. Our correspondent is live at the research facility with more details."',
    "ref_image": "./assets/single_person.jpg",
}


def load_single_person_example():
    """åŠ è½½å•äººç¤ºä¾‹"""
    return SINGLE_PERSON_EXAMPLE["prompt"], SINGLE_PERSON_EXAMPLE["ref_image"]


def load_multi_person_example():
    """åŠ è½½å¤šäººç¤ºä¾‹"""
    return MULTI_PERSON_EXAMPLE["prompt"], MULTI_PERSON_EXAMPLE["ref_image"]


def load_news_anchor_example():
    """åŠ è½½æ–°é—»ä¸»æ’­ç¤ºä¾‹"""
    return NEWS_ANCHOR_EXAMPLE["prompt"], NEWS_ANCHOR_EXAMPLE["ref_image"]


# æ„å»º Gradio ç•Œé¢
def create_ui():
    with gr.Blocks(
        title="MOVA - å¤šæ¨¡æ€è§†é¢‘éŸ³é¢‘ç”Ÿæˆ",
        theme=gr.themes.Soft(),
        css="""
        .youtube-banner {
            background: linear-gradient(135deg, #ff0000 0%, #cc0000 100%);
            padding: 15px 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            text-align: center;
        }
        .youtube-banner a {
            color: white;
            text-decoration: none;
            font-size: 18px;
            font-weight: bold;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
            line-height: 1.1;
        }
        .youtube-banner a:hover {
            text-decoration: underline;
        }
        .youtube-icon {
            display: block;
        }
        """
    ) as demo:
        # YouTube é¢‘é“ä¿¡æ¯æ¨ªå¹…
        gr.HTML("""
        <div class="youtube-banner">
            <a href="https://www.youtube.com/@rongyi-ai" target="_blank">
                <svg class="youtube-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="white">
                    <path d="M19.615 3.184c-3.604-.246-11.631-.245-15.23 0-3.897.266-4.356 2.62-4.385 8.816.029 6.185.484 8.549 4.385 8.816 3.6.245 11.626.246 15.23 0 3.897-.266 4.356-2.62 4.385-8.816-.029-6.185-.484-8.549-4.385-8.816zm-10.615 12.816v-8l8 3.993-8 4.007z"/>
                </svg>
                ğŸ¬ AI æŠ€æœ¯åˆ†äº«é¢‘é“ - æ¬¢è¿è®¢é˜…å…³æ³¨ï¼ç‚¹å‡»è®¿é—® â†’
            </a>
        </div>
        """)
        
        gr.Markdown("""
        # ğŸ¬ MOVA - å¤šæ¨¡æ€è§†é¢‘éŸ³é¢‘ç”Ÿæˆç³»ç»Ÿ
        
        **MOVA** æ˜¯ä¸€ä¸ªå¼ºå¤§çš„è§†é¢‘éŸ³é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬æè¿°å’Œå‚è€ƒå›¾ç‰‡ç”Ÿæˆå¸¦æœ‰åŒæ­¥éŸ³é¢‘çš„è§†é¢‘ã€‚
        
        ### ä½¿ç”¨è¯´æ˜ï¼š
        1. ä¸Šä¼ ä¸€å¼ å‚è€ƒå›¾ç‰‡ï¼ˆäººç‰©ç…§ç‰‡ï¼‰
        2. è¾“å…¥è¯¦ç»†çš„åœºæ™¯å’Œå¯¹è¯æè¿°ï¼ˆè‹±æ–‡æ•ˆæœæœ€ä½³ï¼‰
        3. è°ƒæ•´ç”Ÿæˆå‚æ•°ï¼ˆå¯é€‰ï¼‰
        4. ç‚¹å‡»"ç”Ÿæˆè§†é¢‘"æŒ‰é’®
        """)
        
        with gr.Tabs():
            with gr.TabItem("ğŸ¥ è§†é¢‘ç”Ÿæˆ"):
                with gr.Row():
                    with gr.Column(scale=1):
                        # è¾“å…¥åŒºåŸŸ
                        gr.Markdown("### ğŸ“ è¾“å…¥è®¾ç½®")
                        
                        ref_image = gr.Image(
                            label="å‚è€ƒå›¾ç‰‡",
                            type="filepath",
                            height=300,
                        )
                        
                        prompt = gr.Textbox(
                            label="æç¤ºè¯",
                            placeholder="è¯·è¾“å…¥åœºæ™¯æè¿°å’Œå¯¹è¯å†…å®¹ï¼ˆè‹±æ–‡æ•ˆæœæœ€ä½³ï¼‰...",
                            lines=6,
                            max_lines=10,
                        )
                        
                        negative_prompt = gr.Textbox(
                            label="è´Ÿé¢æç¤ºè¯",
                            value=NEGATIVE_PROMPT,
                            lines=3,
                            max_lines=5,
                        )
                        
                        # ç¤ºä¾‹æŒ‰é’®
                        gr.Markdown("### ğŸ“‹ ç¤ºä¾‹")
                        with gr.Row():
                            single_person_btn = gr.Button("ğŸ‘¤ å•äººè¯´è¯", size="sm")
                            multi_person_btn = gr.Button("ğŸ‘¥ å¤šäººå¯¹è¯", size="sm")
                            news_anchor_btn = gr.Button("ğŸ“º æ–°é—»ä¸»æ’­", size="sm")
                    
                    with gr.Column(scale=1):
                        # å‚æ•°è®¾ç½®
                        gr.Markdown("### âš™ï¸ ç”Ÿæˆå‚æ•°")
                        
                        with gr.Row():
                            height = gr.Slider(
                                label="è§†é¢‘é«˜åº¦",
                                minimum=480,
                                maximum=1080,
                                value=720,
                                step=16,
                            )
                            width = gr.Slider(
                                label="è§†é¢‘å®½åº¦",
                                minimum=640,
                                maximum=1920,
                                value=1280,
                                step=16,
                            )
                        
                        with gr.Row():
                            num_frames = gr.Slider(
                                label="è§†é¢‘å¸§æ•°",
                                minimum=49,
                                maximum=289,
                                value=193,
                                step=8,
                                info="å¸§æ•°è¶Šå¤šï¼Œè§†é¢‘è¶Šé•¿",
                            )
                            fps = gr.Slider(
                                label="å¸§ç‡ (FPS)",
                                minimum=12,
                                maximum=30,
                                value=24,
                                step=1,
                            )
                        
                        with gr.Row():
                            num_inference_steps = gr.Slider(
                                label="æ¨ç†æ­¥æ•°",
                                minimum=20,
                                maximum=100,
                                value=50,
                                step=5,
                                info="æ­¥æ•°è¶Šå¤šï¼Œè´¨é‡è¶Šé«˜ï¼Œä½†é€Ÿåº¦è¶Šæ…¢",
                            )
                            cfg_scale = gr.Slider(
                                label="CFG å¼ºåº¦",
                                minimum=1.0,
                                maximum=15.0,
                                value=5.0,
                                step=0.5,
                                info="æ§åˆ¶ç”Ÿæˆå†…å®¹ä¸æç¤ºè¯çš„åŒ¹é…ç¨‹åº¦",
                            )
                        
                        with gr.Row():
                            sigma_shift = gr.Slider(
                                label="Sigma åç§»",
                                minimum=1.0,
                                maximum=10.0,
                                value=5.0,
                                step=0.5,
                            )
                            seed = gr.Number(
                                label="éšæœºç§å­",
                                value=42,
                                precision=0,
                                info="ç›¸åŒç§å­å¯å¤ç°ç»“æœ",
                            )
                        
                        # ç”ŸæˆæŒ‰é’®
                        generate_btn = gr.Button(
                            "ğŸš€ ç”Ÿæˆè§†é¢‘",
                            variant="primary",
                            size="lg",
                        )
                        
                        # è¾“å‡ºåŒºåŸŸ
                        gr.Markdown("### ğŸ¬ ç”Ÿæˆç»“æœ")
                        output_video = gr.Video(
                            label="ç”Ÿæˆçš„è§†é¢‘",
                            height=400,
                        )
            
            with gr.TabItem("ğŸ“– ä½¿ç”¨å¸®åŠ©"):
                gr.Markdown("""
                ## ğŸ“– è¯¦ç»†ä½¿ç”¨æŒ‡å—
                
                ### 1ï¸âƒ£ å‚è€ƒå›¾ç‰‡è¦æ±‚
                - å»ºè®®ä½¿ç”¨æ¸…æ™°çš„äººç‰©æ­£é¢æˆ–ä¾§é¢ç…§ç‰‡
                - å›¾ç‰‡ä¼šè‡ªåŠ¨è£å‰ªå’Œè°ƒæ•´å¤§å°ä»¥åŒ¹é…ç›®æ ‡åˆ†è¾¨ç‡
                - æ”¯æŒ JPGã€PNG ç­‰å¸¸è§å›¾ç‰‡æ ¼å¼
                
                ### 2ï¸âƒ£ æç¤ºè¯ç¼–å†™æŠ€å·§
                - **åœºæ™¯æè¿°**ï¼šæè¿°ç¯å¢ƒã€å…‰çº¿ã€æ°›å›´ç­‰
                - **äººç‰©åŠ¨ä½œ**ï¼šæè¿°è¯´è¯ã€è¡¨æƒ…ã€è‚¢ä½“åŠ¨ä½œ
                - **å¯¹è¯å†…å®¹**ï¼šä½¿ç”¨å¼•å·åŒ…å«å…·ä½“å¯¹è¯ï¼Œå¦‚ `"Hello, how are you?"`
                - **è¯­è¨€**ï¼šå»ºè®®ä½¿ç”¨è‹±æ–‡ç¼–å†™æç¤ºè¯ï¼Œæ•ˆæœæœ€ä½³
                
                ### 3ï¸âƒ£ å‚æ•°è¯´æ˜
                | å‚æ•° | è¯´æ˜ | å»ºè®®å€¼ |
                |------|------|--------|
                | è§†é¢‘é«˜åº¦/å®½åº¦ | è¾“å‡ºè§†é¢‘åˆ†è¾¨ç‡ | 720x1280 (720p) |
                | è§†é¢‘å¸§æ•° | æ§åˆ¶è§†é¢‘æ—¶é•¿ | 193 å¸§ â‰ˆ 8 ç§’ |
                | å¸§ç‡ | è§†é¢‘æ’­æ”¾é€Ÿåº¦ | 24 FPS |
                | æ¨ç†æ­¥æ•° | å½±å“ç”Ÿæˆè´¨é‡ | 50 æ­¥ |
                | CFG å¼ºåº¦ | æç¤ºè¯åŒ¹é…åº¦ | 5.0 |
                | éšæœºç§å­ | å¯å¤ç°ç»“æœ | ä»»æ„æ•´æ•° |
                
                ### 4ï¸âƒ£ å¸¸è§é—®é¢˜
                - **ç”Ÿæˆé€Ÿåº¦æ…¢**ï¼šå‡å°‘å¸§æ•°æˆ–æ¨ç†æ­¥æ•°å¯åŠ å¿«é€Ÿåº¦
                - **è§†é¢‘è´¨é‡å·®**ï¼šå¢åŠ æ¨ç†æ­¥æ•°ï¼Œè°ƒæ•´ CFG å¼ºåº¦
                - **å£å‹ä¸åŒæ­¥**ï¼šå°è¯•è°ƒæ•´æç¤ºè¯ä¸­çš„å¯¹è¯æè¿°
                
                ### 5ï¸âƒ£ ç¤ºä¾‹æç¤ºè¯
                
                **å•äººæ¼”è®²åœºæ™¯ï¼š**
                ```
                A man in a blue blazer and glasses speaks in a formal indoor setting, 
                framed by wooden furniture and a filled bookshelf. At one point, he says, 
                "I would also say that this election in Germany wasn't surprising."
                ```
                
                **å¤šäººå¯¹è¯åœºæ™¯ï¼š**
                ```
                The scene shows a man and a child walking together through a park. 
                The man asks, "What do you want to do when you grow up?" 
                The boy answers, "A bond trader."
                ```
                """)
            
            with gr.TabItem("â„¹ï¸ å…³äº"):
                gr.Markdown("""
                ## â„¹ï¸ å…³äº MOVA
                
                **MOVA** (Multimodal Omni Video-Audio) æ˜¯ä¸€ä¸ªå…ˆè¿›çš„å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ï¼Œ
                èƒ½å¤ŸåŒæ—¶ç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘å’ŒåŒæ­¥éŸ³é¢‘ã€‚
                
                ### ğŸ”§ æŠ€æœ¯è§„æ ¼
                - **æ¨¡å‹ç‰ˆæœ¬**: MOVA-720p
                - **æ”¯æŒåˆ†è¾¨ç‡**: 720p (1280x720)
                - **è§†é¢‘æ ¼å¼**: MP4 (H.264)
                - **éŸ³é¢‘æ ¼å¼**: AAC
                - **æ¨ç†è®¾å¤‡**: NVIDIA H20 (141GB VRAM)
                
                ### ğŸ“º å…³æ³¨æˆ‘çš„é¢‘é“
                æ¬¢è¿è®¿é—® [AI æŠ€æœ¯åˆ†äº«é¢‘é“](https://www.youtube.com/@rongyi-ai) è·å–æ›´å¤š AI æŠ€æœ¯å†…å®¹ï¼
                
                ### ğŸ“„ è®¸å¯è¯
                æœ¬é¡¹ç›®éµå¾ªåŸå§‹ MOVA é¡¹ç›®çš„è®¸å¯è¯æ¡æ¬¾ã€‚
                """)
        
        # ç»‘å®šäº‹ä»¶
        single_person_btn.click(
            fn=load_single_person_example,
            outputs=[prompt, ref_image],
        )
        
        multi_person_btn.click(
            fn=load_multi_person_example,
            outputs=[prompt, ref_image],
        )
        
        news_anchor_btn.click(
            fn=load_news_anchor_example,
            outputs=[prompt, ref_image],
        )
        
        generate_btn.click(
            fn=generate_video,
            inputs=[
                prompt,
                ref_image,
                height,
                width,
                num_frames,
                fps,
                num_inference_steps,
                cfg_scale,
                sigma_shift,
                seed,
                negative_prompt,
            ],
            outputs=output_video,
        )
    
    return demo


if __name__ == "__main__":
    # é¢„åŠ è½½æ¨¡å‹
    print("=" * 60)
    print("MOVA Gradio Web Application")
    print("=" * 60)

    # å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡ MOVA_PRELOAD=0 å…³é—­ï¼‰
    if os.environ.get("MOVA_PRELOAD", "1") != "0":
        try:
            load_model()
        except Exception as e:
            print(f"æ¨¡å‹é¢„åŠ è½½å¤±è´¥: {e}", file=sys.stderr)
            raise
    
    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    demo = create_ui()
    
    # å¯åŠ¨ Gradio æœåŠ¡
    demo.queue(max_size=5)
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
    )
