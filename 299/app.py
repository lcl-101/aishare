"""
Qwen-Image å›¾åƒç”Ÿæˆä¸ç¼–è¾‘ Gradio Web åº”ç”¨
- Tab 1: Qwen-Image-2512 å›¾åƒç”Ÿæˆ
- Tab 2: Qwen-Image-Edit-2511 + Multi-Angles LoRA å¤šè§†è§’ç¼–è¾‘
"""

import gradio as gr
import torch
from PIL import Image
import os

# æ¨¡å‹è·¯å¾„
IMAGE_GEN_MODEL_PATH = "./checkpoints/Qwen-Image-2512"
IMAGE_EDIT_MODEL_PATH = "./checkpoints/Qwen-Image-Edit-2511"
MULTI_ANGLES_LORA_PATH = "./checkpoints/Qwen-Image-Edit-2511-Multiple-Angles-LoRA/qwen-image-edit-2511-multiple-angles-lora.safetensors"

# é¢„è®¾çš„å®½é«˜æ¯”é€‰é¡¹
ASPECT_RATIOS = {
    "1:1 (1328Ã—1328)": (1328, 1328),
    "16:9 (1664Ã—928)": (1664, 928),
    "9:16 (928Ã—1664)": (928, 1664),
    "4:3 (1472Ã—1104)": (1472, 1104),
    "3:4 (1104Ã—1472)": (1104, 1472),
    "3:2 (1584Ã—1056)": (1584, 1056),
    "2:3 (1056Ã—1584)": (1056, 1584),
}

# é»˜è®¤è´Ÿé¢æç¤ºè¯
DEFAULT_NEGATIVE_PROMPT = "ä½åˆ†è¾¨ç‡ï¼Œä½ç”»è´¨ï¼Œè‚¢ä½“ç•¸å½¢ï¼Œæ‰‹æŒ‡ç•¸å½¢ï¼Œç”»é¢è¿‡é¥±å’Œï¼Œèœ¡åƒæ„Ÿï¼Œäººè„¸æ— ç»†èŠ‚ï¼Œè¿‡åº¦å…‰æ»‘ï¼Œç”»é¢å…·æœ‰AIæ„Ÿã€‚æ„å›¾æ··ä¹±ã€‚æ–‡å­—æ¨¡ç³Šï¼Œæ‰­æ›²ã€‚"

# å¤šè§†è§’ LoRA é…ç½®
AZIMUTHS = {
    "æ­£é¢ (front view)": "front view",
    "å³å‰45Â° (front-right quarter view)": "front-right quarter view",
    "å³ä¾§ (right side view)": "right side view",
    "å³å135Â° (back-right quarter view)": "back-right quarter view",
    "èƒŒé¢ (back view)": "back view",
    "å·¦å225Â° (back-left quarter view)": "back-left quarter view",
    "å·¦ä¾§ (left side view)": "left side view",
    "å·¦å‰315Â° (front-left quarter view)": "front-left quarter view",
}

ELEVATIONS = {
    "ä»°è§† -30Â° (low-angle shot)": "low-angle shot",
    "å¹³è§† 0Â° (eye-level shot)": "eye-level shot",
    "ä¿¯è§† 30Â° (elevated shot)": "elevated shot",
    "é«˜è§’åº¦ 60Â° (high-angle shot)": "high-angle shot",
}

DISTANCES = {
    "ç‰¹å†™ (close-up)": "close-up",
    "ä¸­æ™¯ (medium shot)": "medium shot",
    "è¿œæ™¯ (wide shot)": "wide shot",
}

# ç¤ºä¾‹æç¤ºè¯ - æŒ‰åŠŸèƒ½åˆ†ç±» [åŠŸèƒ½å¢å¼ºç±»åˆ«, æç¤ºè¯]
EXAMPLE_PROMPTS = [
    # äººç‰©å†™å®
    [
        "ğŸ§‘ äººç‰©å†™å® - ç²¾ç»†å‘ä¸å’Œè‡ªç„¶è¡¨æƒ…",
        "A 20-year-old East Asian girl with delicate, charming features and large, bright brown eyesâ€”expressive and lively, with a cheerful or subtly smiling expression. Her naturally wavy long hair is either loose or tied in twin ponytails. She has fair skin and light makeup accentuating her youthful freshness. She wears a modern, cute dress or relaxed outfit in bright, soft colorsâ€”lightweight fabric, minimalist cut. She stands indoors at an anime convention, surrounded by banners, posters, or stalls. Lighting is typical indoor illuminationâ€”no staged lightingâ€”and the image resembles a casual iPhone snapshot: unpretentious composition, yet brimming with vivid, fresh, youthful charm.",
    ],
    [
        "ğŸ§‘ äººç‰©å†™å® - é¢éƒ¨ç»†èŠ‚å’Œç¯å¢ƒèƒŒæ™¯",
        "A Chinese female college student, around 20 years old, with a very short haircut that conveys a gentle, artistic vibe. Her hair naturally falls to partially cover her cheeks, projecting a tomboyish yet charming demeanor. She has cool-toned fair skin and delicate features, with a slightly shy yet subtly confident expressionâ€”her mouth crooked in a playful, youthful smirk. She wears an off-shoulder top, revealing one shoulder, with a well-proportioned figure. The image is framed as a close-up selfie: she dominates the foreground, while the background clearly shows her dormitoryâ€”a neatly made bed with white linens on the top bunk, a tidy study desk with organized stationery, and wooden cabinets and drawers. The photo is captured on a smartphone under soft, even ambient lighting, with natural tones, high clarity, and a bright, lively atmosphere full of youthful, everyday energy.",
    ],
    [
        "ğŸ§‘ äººç‰©å†™å® - ç²¾ç¡®å§¿æ€è¯­ä¹‰éµå¾ª",
        "An East Asian teenage boy, aged 15â€“18, with soft, fluffy black short hair and refined facial contours. His large, warm brown eyes sparkle with energy. His fair skin and sunny, open smile convey an approachable, friendly demeanorâ€”no makeup or blemishes. He wears a blue-and-white summer uniform shirt, slightly unbuttoned, made of thin breathable fabric, with black headphones hanging around his neck. His hands are in his pockets, body leaning slightly forward in a relaxed pose, as if engaged in conversation. Behind him lies a summer school playground: lush green grass and a red rubber track in the foreground, blurred school buildings in the distance, a clear blue sky with fluffy white clouds. The bright, airy lighting evokes a joyful, carefree adolescent atmosphere.",
    ],
    [
        "ğŸ§‘ äººç‰©å†™å® - å¹´é¾„ç‰¹å¾ï¼ˆçš±çº¹ï¼‰æ¸²æŸ“",
        "An elderly Chinese couple in their 70s in a clean, organized home kitchen. The woman has a kind face and a warm smile, wearing a patterned apron; the man stands behind her, also smiling, as they both gaze at a steaming pot of buns on the stove. The kitchen is bright and tidy, exuding warmth and harmony. The scene is captured with a wide-angle lens to fully show the subjects and their surroundings.",
    ],
    # è‡ªç„¶é£æ™¯
    [
        "ğŸŒ¿ è‡ªç„¶çº¹ç† - æ°´æµæ¤è¢«é›¾æ°”æ¸²æŸ“",
        "A turquoise river winds through a lush canyon. Thick moss and dense ferns blanket the rocky walls; multiple waterfalls cascade from above, enveloped in mist. At noon, sunlight filters through the dense canopy, dappling the river surface with shimmering light. The atmosphere is humid and fresh, pulsing with primal jungle vitality. No humans, text, or artificial traces present.",
    ],
    [
        "ğŸŒ¿ è‡ªç„¶çº¹ç† - æµ·æµªä¸æ™¨é›¾æ¸²æŸ“",
        "At dawn, a thin mist veils the sea. An ancient stone lighthouse stands at the cliff's edge, its beacon faintly visible through the fog. Black rocks are pounded by waves, sending up bursts of white spray. The sky glows in soft blue-purple hues under cool, hazy lightâ€”evoking solitude and solemn grandeur.",
    ],
    # åŠ¨ç‰©æ¯›å‘
    [
        "ğŸ• åŠ¨ç‰©æ¯›å‘ - ç²¾ç»†æ¯›å‘çº¹ç†",
        "An ultra-realistic close-up of a golden retriever outdoors under soft daylight. Hair is exquisitely detailed: strands distinct, color transitioning naturally from warm gold to light cream, light glinting delicately at the tips; a gentle breeze adds subtle volume. Undercoat is soft and dense; guard hairs are long and well-defined, with visible layering. Eyes are moist, expressive; nose is slightly damp with fine specular highlights. Background is softly blurred to emphasize the dog's tangible texture and vivid expression.",
    ],
    [
        "ğŸ• åŠ¨ç‰©æ¯›å‘ - ç²—ç³™é‡ç”ŸåŠ¨ç‰©çº¹ç†",
        "A male argali stands atop a barren, rocky mountainside. Its coarse, dense grey-brown coat covers a powerful, muscular body. Most striking are its massive, thick, outward-spiraling hornsâ€”a symbol of wild strength. Its gaze is alert and sharp. The background reveals steep alpine terrain: jagged peaks, sparse low vegetation, and abundant sunlightâ€”conveying the harsh yet majestic wilderness and the animal's resilient vitality.",
    ],
    # æ–‡å­—æ¸²æŸ“
    [
        "ğŸ“ æ–‡å­—æ¸²æŸ“ - PPTæ—¶é—´è½´å›¾æ–‡æ··æ’",
        'è¿™æ˜¯ä¸€å¼ ç°ä»£é£æ ¼çš„ç§‘æŠ€æ„Ÿå¹»ç¯ç‰‡ï¼Œæ•´ä½“é‡‡ç”¨æ·±è“è‰²æ¸å˜èƒŒæ™¯ã€‚æ ‡é¢˜æ˜¯"Qwen-Imageå‘å±•å†ç¨‹"ã€‚ä¸‹æ–¹ä¸€æ¡æ°´å¹³å»¶ä¼¸çš„å‘å…‰æ—¶é—´è½´ï¼Œè½´çº¿ä¸­é—´å†™ç€"ç”Ÿå›¾è·¯çº¿"ã€‚ç”±å·¦ä¾§æ·¡è“è‰²æ¸å˜ä¸ºå³ä¾§æ·±ç´«è‰²ï¼Œå¹¶ä»¥ç²¾è‡´çš„ç®­å¤´æ”¶å°¾ã€‚æ—¶é—´è½´ä¸Šæ¯ä¸ªèŠ‚ç‚¹é€šè¿‡è™šçº¿è¿æ¥è‡³ä¸‹æ–¹é†’ç›®çš„è“è‰²åœ†è§’çŸ©å½¢æ—¥æœŸæ ‡ç­¾ï¼Œæ ‡ç­¾å†…ä¸ºæ¸…æ™°ç™½è‰²å­—ä½“ï¼Œä»å·¦å‘å³ä¾æ¬¡å†™ç€ï¼š"2025å¹´5æœˆ6æ—¥ Qwen-Image é¡¹ç›®å¯åŠ¨""2025å¹´8æœˆ4æ—¥ Qwen-Image å¼€æºå‘å¸ƒ""2025å¹´12æœˆ31æ—¥ Qwen-Image-2512 å¼€æºå‘å¸ƒ"',
    ],
    [
        "ğŸ“ æ–‡å­—æ¸²æŸ“ - äº§å“å¯¹æ¯”å›¾æ··åˆæ¸²æŸ“",
        'è¿™æ˜¯ä¸€å¼ ç°ä»£é£æ ¼çš„ç§‘æŠ€æ„Ÿå¹»ç¯ç‰‡ï¼Œæ•´ä½“é‡‡ç”¨æ·±è“è‰²æ¸å˜èƒŒæ™¯ã€‚é¡¶éƒ¨ä¸­å¤®ä¸ºç™½è‰²æ— è¡¬çº¿ç²—ä½“å¤§å­—æ ‡é¢˜"Qwen-Image-2512é‡ç£…å‘å¸ƒ"ã€‚ç”»é¢ä¸»ä½“ä¸ºæ¨ªå‘å¯¹æ¯”å›¾ï¼Œè§†è§‰ç„¦ç‚¹é›†ä¸­äºä¸­é—´çš„å‡çº§å¯¹æ¯”åŒºåŸŸã€‚å·¦ä¾§ä¸ºé¢éƒ¨å…‰æ»‘æ²¡æœ‰ä»»ä½•ç»†èŠ‚çš„å¥³æ€§äººåƒï¼Œè´¨æ„Ÿå·®ï¼›å³ä¾§ä¸ºé«˜åº¦å†™å®çš„å¹´è½»å¥³æ€§è‚–åƒï¼Œçš®è‚¤å‘ˆç°çœŸå®æ¯›å­”çº¹ç†ä¸ç»†å¾®å…‰å½±å˜åŒ–ï¼Œå‘ä¸æ ¹æ ¹åˆ†æ˜ï¼Œçœ¼çœ¸é€äº®ï¼Œè¡¨æƒ…è‡ªç„¶ï¼Œæ•´ä½“è´¨æ„Ÿæ¥è¿‘å†™å®æ‘„å½±ã€‚',
    ],
]

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹ç®¡é“
gen_pipe = None
edit_pipe = None
lora_loaded = False


def load_gen_model():
    """åŠ è½½ Qwen-Image-2512 å›¾åƒç”Ÿæˆæ¨¡å‹"""
    global gen_pipe
    
    if gen_pipe is not None:
        return gen_pipe
    
    from diffusers import DiffusionPipeline
    
    print("æ­£åœ¨åŠ è½½ Qwen-Image-2512 å›¾åƒç”Ÿæˆæ¨¡å‹...")
    
    if torch.cuda.is_available():
        torch_dtype = torch.bfloat16
        device = "cuda"
        print(f"ä½¿ç”¨ CUDA è®¾å¤‡: {torch.cuda.get_device_name(0)}")
    else:
        torch_dtype = torch.float32
        device = "cpu"
        print("CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPUï¼ˆç”Ÿæˆé€Ÿåº¦ä¼šè¾ƒæ…¢ï¼‰")
    
    gen_pipe = DiffusionPipeline.from_pretrained(
        IMAGE_GEN_MODEL_PATH, 
        torch_dtype=torch_dtype
    ).to(device)
    
    print("Qwen-Image-2512 æ¨¡å‹åŠ è½½å®Œæˆï¼")
    return gen_pipe


def load_edit_model():
    """åŠ è½½ Qwen-Image-Edit-2511 å›¾åƒç¼–è¾‘æ¨¡å‹"""
    global edit_pipe, lora_loaded
    
    if edit_pipe is not None:
        return edit_pipe
    
    from diffusers import QwenImageEditPlusPipeline
    
    print("æ­£åœ¨åŠ è½½ Qwen-Image-Edit-2511 å›¾åƒç¼–è¾‘æ¨¡å‹...")
    
    if torch.cuda.is_available():
        torch_dtype = torch.bfloat16
        device = "cuda"
    else:
        torch_dtype = torch.float32
        device = "cpu"
    
    edit_pipe = QwenImageEditPlusPipeline.from_pretrained(
        IMAGE_EDIT_MODEL_PATH, 
        torch_dtype=torch_dtype
    )
    edit_pipe.to(device)
    edit_pipe.set_progress_bar_config(disable=None)
    
    # åŠ è½½ Multi-Angles LoRA
    print("æ­£åœ¨åŠ è½½ Multi-Angles LoRA...")
    edit_pipe.load_lora_weights(MULTI_ANGLES_LORA_PATH)
    lora_loaded = True
    
    print("Qwen-Image-Edit-2511 + Multi-Angles LoRA åŠ è½½å®Œæˆï¼")
    return edit_pipe


def generate_image(
    prompt: str,
    negative_prompt: str,
    aspect_ratio: str,
    num_inference_steps: int,
    true_cfg_scale: float,
    seed: int,
    progress=gr.Progress()
):
    """ç”Ÿæˆå›¾åƒ"""
    global gen_pipe
    
    if gen_pipe is None:
        gen_pipe = load_gen_model()
    
    if not prompt.strip():
        return None, "é”™è¯¯ï¼šè¯·è¾“å…¥æç¤ºè¯ã€‚"
    
    try:
        width, height = ASPECT_RATIOS[aspect_ratio]
        device = "cuda" if torch.cuda.is_available() else "cpu"
        generator = torch.Generator(device=device).manual_seed(seed)
        
        progress(0, desc="å¼€å§‹ç”Ÿæˆå›¾åƒ...")
        
        result = gen_pipe(
            prompt=prompt,
            negative_prompt=negative_prompt if negative_prompt.strip() else None,
            width=width,
            height=height,
            num_inference_steps=num_inference_steps,
            true_cfg_scale=true_cfg_scale,
            generator=generator
        )
        
        image = result.images[0]
        info = f"âœ… ç”ŸæˆæˆåŠŸï¼\nå°ºå¯¸: {width}Ã—{height}\næ­¥æ•°: {num_inference_steps}\nCFG: {true_cfg_scale}\nç§å­: {seed}"
        
        return image, info
        
    except Exception as e:
        error_msg = f"âŒ ç”Ÿæˆå¤±è´¥ï¼š{str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return None, error_msg


def edit_image_multi_angle(
    input_image,
    azimuth: str,
    elevation: str,
    distance: str,
    num_inference_steps: int,
    true_cfg_scale: float,
    seed: int,
    progress=gr.Progress()
):
    """ä½¿ç”¨å¤šè§†è§’ LoRA ç¼–è¾‘å›¾åƒ"""
    global edit_pipe
    
    if edit_pipe is None:
        edit_pipe = load_edit_model()
    
    if input_image is None:
        return None, "é”™è¯¯ï¼šè¯·å…ˆä¸Šä¼ æˆ–ä»ç”Ÿæˆ Tab ä¼ å…¥å›¾åƒã€‚"
    
    try:
        # æ„å»º LoRA æç¤ºè¯
        azimuth_text = AZIMUTHS[azimuth]
        elevation_text = ELEVATIONS[elevation]
        distance_text = DISTANCES[distance]
        
        prompt = f"<sks> {azimuth_text} {elevation_text} {distance_text}"
        
        progress(0, desc=f"æ­£åœ¨ç”Ÿæˆå¤šè§†è§’å›¾åƒ: {prompt}")
        
        # ç¡®ä¿è¾“å…¥å›¾åƒæ˜¯ PIL Image
        if not isinstance(input_image, Image.Image):
            input_image = Image.fromarray(input_image)
        
        generator = torch.manual_seed(seed)
        
        with torch.inference_mode():
            result = edit_pipe(
                image=[input_image],
                prompt=prompt,
                generator=generator,
                true_cfg_scale=true_cfg_scale,
                negative_prompt=" ",
                num_inference_steps=num_inference_steps,
                guidance_scale=1.0,
                num_images_per_prompt=1,
            )
        
        output_image = result.images[0]
        info = f"âœ… å¤šè§†è§’ç¼–è¾‘æˆåŠŸï¼\næç¤ºè¯: {prompt}\næ­¥æ•°: {num_inference_steps}\nCFG: {true_cfg_scale}\nç§å­: {seed}"
        
        return output_image, info
        
    except Exception as e:
        error_msg = f"âŒ ç¼–è¾‘å¤±è´¥ï¼š{str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return None, error_msg


def send_to_edit_tab(generated_image):
    """å°†ç”Ÿæˆçš„å›¾åƒå‘é€åˆ°ç¼–è¾‘ Tab"""
    if generated_image is None:
        gr.Warning("æ²¡æœ‰ç”Ÿæˆçš„å›¾åƒå¯ä»¥å‘é€")
        return None
    return generated_image


def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    with gr.Blocks(
        title="Qwen-Image å›¾åƒç”Ÿæˆä¸å¤šè§†è§’ç¼–è¾‘"
    ) as demo:
        
        gr.HTML("""
        <div style="text-align: center; margin-bottom: 1rem;">
            <h1>ğŸ¨ Qwen-Image å›¾åƒç”Ÿæˆä¸å¤šè§†è§’ç¼–è¾‘</h1>
            <p>Tab 1: ä½¿ç”¨ Qwen-Image-2512 ç”Ÿæˆå›¾åƒ | Tab 2: ä½¿ç”¨ Qwen-Image-Edit-2511 + Multi-Angles LoRA å¤šè§†è§’ç¼–è¾‘</p>
        </div>
        """)
        
        with gr.Tabs() as tabs:
            # ==================== Tab 1: å›¾åƒç”Ÿæˆ ====================
            with gr.TabItem("ğŸ–¼ï¸ å›¾åƒç”Ÿæˆ", id=0):
                with gr.Row():
                    # å·¦ä¾§è¾“å…¥åŒºåŸŸ
                    with gr.Column(scale=1):
                        gen_prompt = gr.Textbox(
                            label="âœï¸ æç¤ºè¯ (Prompt)",
                            placeholder="è¯·è¾“å…¥å›¾åƒæè¿°...",
                            lines=5,
                            max_lines=10
                        )
                        
                        gen_negative_prompt = gr.Textbox(
                            label="ğŸš« è´Ÿé¢æç¤ºè¯ (Negative Prompt)",
                            value=DEFAULT_NEGATIVE_PROMPT,
                            lines=3,
                            max_lines=5
                        )
                        
                        with gr.Row():
                            gen_aspect_ratio = gr.Dropdown(
                                label="ğŸ“ å®½é«˜æ¯”",
                                choices=list(ASPECT_RATIOS.keys()),
                                value="16:9 (1664Ã—928)"
                            )
                            
                            gen_seed = gr.Number(
                                label="ğŸ² éšæœºç§å­",
                                value=42,
                                precision=0
                            )
                        
                        with gr.Row():
                            gen_steps = gr.Slider(
                                label="ğŸ”„ æ¨ç†æ­¥æ•°",
                                minimum=10,
                                maximum=100,
                                value=50,
                                step=1
                            )
                            
                            gen_cfg = gr.Slider(
                                label="ğŸ¯ CFG å¼ºåº¦",
                                minimum=1.0,
                                maximum=10.0,
                                value=4.0,
                                step=0.5
                            )
                        
                        with gr.Row():
                            gen_btn = gr.Button(
                                "ğŸš€ ç”Ÿæˆå›¾åƒ",
                                variant="primary",
                                size="lg"
                            )
                            send_to_edit_btn = gr.Button(
                                "ğŸ“¤ å‘é€åˆ°å¤šè§†è§’ç¼–è¾‘",
                                variant="secondary",
                                size="lg"
                            )
                    
                    # å³ä¾§è¾“å‡ºåŒºåŸŸ
                    with gr.Column(scale=1):
                        gen_output_image = gr.Image(
                            label="ğŸ–¼ï¸ ç”Ÿæˆç»“æœ",
                            type="pil"
                        )
                        
                        gen_output_info = gr.Textbox(
                            label="ğŸ“Š ç”Ÿæˆä¿¡æ¯",
                            lines=5,
                            interactive=False
                        )
                
                # ç¤ºä¾‹åŒºåŸŸ
                gr.HTML("""
                <div style="margin-top: 2rem;">
                    <h3>ğŸ“š ç¤ºä¾‹æç¤ºè¯</h3>
                    <p style="color: #666; font-size: 0.9em;">ç‚¹å‡»ä¸‹æ–¹ç¤ºä¾‹å¿«é€Ÿä½“éªŒä¸åŒåŠŸèƒ½åœºæ™¯</p>
                </div>
                """)
                
                feature_category = gr.Textbox(visible=False)
                
                gr.Examples(
                    examples=EXAMPLE_PROMPTS,
                    inputs=[feature_category, gen_prompt],
                    label="",
                    examples_per_page=10
                )
            
            # ==================== Tab 2: å¤šè§†è§’ç¼–è¾‘ ====================
            with gr.TabItem("ğŸ”„ å¤šè§†è§’ç¼–è¾‘", id=1):
                gr.HTML("""
                <div style="margin-bottom: 1rem; padding: 1rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; color: white;">
                    <h3 style="margin: 0;">ğŸ“· Multi-Angles LoRA å¤šè§†è§’ç›¸æœºæ§åˆ¶</h3>
                    <p style="margin: 0.5rem 0 0 0; font-size: 0.9em;">
                        æ”¯æŒ 96 ç§ç²¾ç¡®ç›¸æœºä½ç½®ï¼š8 ä¸ªæ°´å¹³è§’åº¦ Ã— 4 ä¸ªå‚ç›´è§’åº¦ Ã— 3 ä¸ªè·ç¦»
                    </p>
                </div>
                """)
                
                with gr.Row():
                    # å·¦ä¾§è¾“å…¥åŒºåŸŸ
                    with gr.Column(scale=1):
                        edit_input_image = gr.Image(
                            label="ğŸ“¥ è¾“å…¥å›¾åƒï¼ˆå¯ä»ç”ŸæˆTabå‘é€æˆ–ç›´æ¥ä¸Šä¼ ï¼‰",
                            type="pil"
                        )
                        
                        gr.HTML("<h4>ğŸ“· ç›¸æœºä½ç½®è®¾ç½®</h4>")
                        
                        with gr.Row():
                            edit_azimuth = gr.Dropdown(
                                label="ğŸ”„ æ°´å¹³è§’åº¦ (Azimuth)",
                                choices=list(AZIMUTHS.keys()),
                                value="æ­£é¢ (front view)"
                            )
                        
                        with gr.Row():
                            edit_elevation = gr.Dropdown(
                                label="ğŸ“ å‚ç›´è§’åº¦ (Elevation)",
                                choices=list(ELEVATIONS.keys()),
                                value="å¹³è§† 0Â° (eye-level shot)"
                            )
                        
                        with gr.Row():
                            edit_distance = gr.Dropdown(
                                label="ğŸ“ æ‹æ‘„è·ç¦» (Distance)",
                                choices=list(DISTANCES.keys()),
                                value="ä¸­æ™¯ (medium shot)"
                            )
                        
                        with gr.Row():
                            edit_steps = gr.Slider(
                                label="ğŸ”„ æ¨ç†æ­¥æ•°",
                                minimum=10,
                                maximum=80,
                                value=40,
                                step=1
                            )
                            
                            edit_cfg = gr.Slider(
                                label="ğŸ¯ CFG å¼ºåº¦",
                                minimum=1.0,
                                maximum=10.0,
                                value=4.0,
                                step=0.5
                            )
                        
                        edit_seed = gr.Number(
                            label="ğŸ² éšæœºç§å­",
                            value=0,
                            precision=0
                        )
                        
                        edit_btn = gr.Button(
                            "ğŸ”„ ç”Ÿæˆå¤šè§†è§’å›¾åƒ",
                            variant="primary",
                            size="lg"
                        )
                    
                    # å³ä¾§è¾“å‡ºåŒºåŸŸ
                    with gr.Column(scale=1):
                        edit_output_image = gr.Image(
                            label="ğŸ–¼ï¸ å¤šè§†è§’ç¼–è¾‘ç»“æœ",
                            type="pil"
                        )
                        
                        edit_output_info = gr.Textbox(
                            label="ğŸ“Š ç¼–è¾‘ä¿¡æ¯",
                            lines=5,
                            interactive=False
                        )
                
                # ç›¸æœºä½ç½®å‚è€ƒ
                with gr.Accordion("ğŸ“– ç›¸æœºä½ç½®å‚è€ƒ", open=False):
                    gr.Markdown("""
### ğŸ”„ æ°´å¹³è§’åº¦ (Azimuth) - 8ä¸ªæ–¹å‘
```
                         0Â° 
                    (æ­£é¢ front)
                         â”‚
         315Â°            â”‚            45Â°
      (å·¦å‰)             â”‚          (å³å‰)
              â•²          â”‚          â•±
               â•²         â”‚         â•±
                â•²        â”‚        â•±
   270Â° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 90Â°
   (å·¦ä¾§)             ç‰©ä½“            (å³ä¾§)
                â•±        â”‚        â•²
               â•±         â”‚         â•²
              â•±          â”‚          â•²
         225Â°            â”‚            135Â°
       (å·¦å)            â”‚          (å³å)
                         â”‚
                        180Â°
                     (èƒŒé¢ back)
```

### ğŸ“ å‚ç›´è§’åº¦ (Elevation) - 4ä¸ªé«˜åº¦
| è§’åº¦ | æè¿° | è¯´æ˜ |
|------|------|------|
| -30Â° | ä»°è§† (low-angle) | ç›¸æœºåœ¨ä¸‹æ–¹ï¼Œå‘ä¸Šçœ‹ |
| 0Â° | å¹³è§† (eye-level) | ç›¸æœºä¸ç‰©ä½“åŒé«˜ |
| 30Â° | ä¿¯è§† (elevated) | ç›¸æœºç•¥é«˜äºç‰©ä½“ |
| 60Â° | é«˜è§’åº¦ (high-angle) | ç›¸æœºåœ¨é«˜å¤„å‘ä¸‹çœ‹ |

### ğŸ“ æ‹æ‘„è·ç¦» (Distance) - 3ç§è·ç¦»
| ç±»å‹ | æè¿° | ç”¨é€” |
|------|------|------|
| Ã—0.6 | ç‰¹å†™ (close-up) | ç»†èŠ‚ã€çº¹ç† |
| Ã—1.0 | ä¸­æ™¯ (medium shot) | å¹³è¡¡ã€æ ‡å‡† |
| Ã—1.8 | è¿œæ™¯ (wide shot) | ç¯å¢ƒã€å…¨æ™¯ |
                    """)
        
        # ==================== äº‹ä»¶ç»‘å®š ====================
        
        # ç”ŸæˆæŒ‰é’®
        gen_btn.click(
            fn=generate_image,
            inputs=[gen_prompt, gen_negative_prompt, gen_aspect_ratio, gen_steps, gen_cfg, gen_seed],
            outputs=[gen_output_image, gen_output_info]
        )
        
        # å‘é€åˆ°ç¼–è¾‘ Tab
        send_to_edit_btn.click(
            fn=send_to_edit_tab,
            inputs=[gen_output_image],
            outputs=[edit_input_image]
        ).then(
            fn=lambda: gr.Tabs(selected=1),
            outputs=[tabs]
        )
        
        # å¤šè§†è§’ç¼–è¾‘æŒ‰é’®
        edit_btn.click(
            fn=edit_image_multi_angle,
            inputs=[edit_input_image, edit_azimuth, edit_elevation, edit_distance, edit_steps, edit_cfg, edit_seed],
            outputs=[edit_output_image, edit_output_info]
        )
    
    return demo


if __name__ == "__main__":
    # é¢„åŠ è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼Œä¹Ÿå¯ä»¥åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½ï¼‰
    print("=" * 50)
    print("Qwen-Image å›¾åƒç”Ÿæˆä¸å¤šè§†è§’ç¼–è¾‘")
    print("=" * 50)
    
    # å¯ä»¥é€‰æ‹©é¢„åŠ è½½æ¨¡å‹
    # load_gen_model()
    # load_edit_model()
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
