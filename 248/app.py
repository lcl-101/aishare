import os


def _sanitize_ipv6_in_no_proxy():
    """httpx 0.24 å¯¹æœªå¸¦[]çš„ IPv6 loopback å¤„ç†æœ‰ bugï¼Œæå‰å‰”é™¤"""
    for key in ("no_proxy", "NO_PROXY"):
        value = os.environ.get(key)
        if not value:
            continue
        cleaned = ",".join(part for part in value.split(",") if "::" not in part)
        if cleaned:
            os.environ[key] = cleaned
        else:
            os.environ.pop(key, None)


_sanitize_ipv6_in_no_proxy()

import torch
import gradio as gr
from transformers import ARCHunyuanVideoProcessor, ARCHunyuanVideoForConditionalGeneration
from video_inference import inference

# æ¨¡å‹è·¯å¾„
MODEL_PATH = "checkpoints/ARC-Hunyuan-Video-7B"

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹å’Œå¤„ç†å™¨
model = None
processor = None

# ä»»åŠ¡ç±»å‹è¯´æ˜
TASK_DESCRIPTIONS = {
    "summary": "è§†é¢‘æ‘˜è¦ - å¯¹è§†é¢‘å†…å®¹è¿›è¡Œæ•´ä½“æ¦‚æ‹¬",
    "QA": "é—®ç­” - å›ç­”å…³äºè§†é¢‘å†…å®¹çš„é—®é¢˜",
    "MCQ": "å¤šé€‰é¢˜ - å›ç­”é€‰æ‹©é¢˜æ ¼å¼çš„é—®é¢˜ï¼ˆéœ€è¦æä¾›é€‰é¡¹ A/B/C/Dï¼‰",
    "Grounding": "æ—¶åºå®šä½ - å®šä½è§†é¢‘ä¸­ç‰¹å®šäº‹ä»¶å‘ç”Ÿçš„æ—¶é—´èŒƒå›´",
    "segment": "ç« èŠ‚åˆ†å‰² - æŒ‰æ—¶é—´é¡ºåºç»™å‡ºè§†é¢‘çš„ç« èŠ‚æ‘˜è¦å’Œå¯¹åº”æ—¶é—´ç‚¹",
}


def load_model():
    """å¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½æ¨¡å‹"""
    global model, processor
    
    if model is not None:
        return
    
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH}")
    
    model = (
        ARCHunyuanVideoForConditionalGeneration.from_pretrained(
            MODEL_PATH,
            torch_dtype=torch.bfloat16,
            attn_implementation="flash_attention_2",
        )
        .eval()
        .to("cuda")
    )
    
    processor = ARCHunyuanVideoProcessor.from_pretrained(MODEL_PATH)
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {MODEL_PATH}")


def process_video(video_file, question, task_type, audio_file=None):
    """å¤„ç†ä¸Šä¼ çš„è§†é¢‘"""
    global model, processor
    
    if model is None or processor is None:
        return "âŒ é”™è¯¯: æ¨¡å‹æœªåŠ è½½ï¼"
    
    if video_file is None:
        return "âŒ é”™è¯¯: è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶ï¼"
    
    if not question or question.strip() == "":
        return "âŒ é”™è¯¯: è¯·è¾“å…¥é—®é¢˜æˆ–æŒ‡ä»¤ï¼"
    
    try:
        # è·å–ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶è·¯å¾„
        video_path = video_file
        audio_path = audio_file if audio_file else None
        
        print(f"å¤„ç†è§†é¢‘: {video_path}")
        print(f"é—®é¢˜: {question}")
        print(f"ä»»åŠ¡ç±»å‹: {task_type}")
        print(f"éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        
        # è°ƒç”¨æ¨ç†å‡½æ•°
        output_text = inference(
            model=model,
            processor=processor,
            question=question,
            video_path=video_path,
            audio_path=audio_path,
            task=task_type
        )
        
        return output_text
    
    except Exception as e:
        import traceback
        error_msg = f"âŒ å¤„ç†è§†é¢‘æ—¶å‡ºé”™:\n{str(e)}\n\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}"
        print(error_msg)
        return error_msg


def get_example_questions(task_type):
    """æ ¹æ®ä»»åŠ¡ç±»å‹è¿”å›ç¤ºä¾‹é—®é¢˜"""
    examples = {
        "summary": "è¯¥è§†é¢‘æ ‡é¢˜ä¸º[æ ‡é¢˜]\næè¿°è§†é¢‘å†…å®¹.",
        "QA": "è¿™ä¸ªè§†é¢‘æœ‰ä»€ä¹ˆäº®ç‚¹ï¼Ÿ",
        "MCQ": "è§†é¢‘ä¸­æœ€åå‡ºç°çš„æ˜¯ä»€ä¹ˆï¼Ÿ\nA.äººç‰©\nB.åŠ¨ç‰©\nC.å»ºç­‘\nD.é£æ™¯",
        "Grounding": "æˆ‘ä»¬ä½•æ—¶èƒ½çœ‹åˆ°ç‰¹å®šåœºæ™¯æˆ–äº‹ä»¶ï¼Ÿ",
        "segment": "è¯·æŒ‰æ—¶é—´é¡ºåºç»™å‡ºè§†é¢‘çš„ç« èŠ‚æ‘˜è¦å’Œå¯¹åº”æ—¶é—´ç‚¹",
    }
    return examples.get(task_type, "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")


# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="ARC Hunyuan Video åˆ†æç³»ç»Ÿ") as demo:
    gr.Markdown(
        """
        # ğŸ¬ ARC Hunyuan Video åˆ†æç³»ç»Ÿ
        
        è¿™æ˜¯ä¸€ä¸ªåŸºäºè…¾è®¯ ARC å®éªŒå®¤å¼€å‘çš„å¤šæ¨¡æ€è§†é¢‘ç†è§£æ¨¡å‹çš„ Web åº”ç”¨ã€‚
        æ”¯æŒè§†é¢‘æ‘˜è¦ã€é—®ç­”ã€æ—¶åºå®šä½ã€ç« èŠ‚åˆ†å‰²ç­‰å¤šç§ä»»åŠ¡ã€‚
        
        ## ä½¿ç”¨æ­¥éª¤:
        1. ä¸Šä¼ è§†é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ mp4, mov, avi ç­‰æ ¼å¼ï¼‰
        2. é€‰æ‹©ä»»åŠ¡ç±»å‹
        3. è¾“å…¥é—®é¢˜æˆ–æŒ‡ä»¤
        4. å¯é€‰ï¼šä¸Šä¼ å•ç‹¬çš„éŸ³é¢‘æ–‡ä»¶
        5. ç‚¹å‡»"å¼€å§‹åˆ†æ"
        """
    )
    
    with gr.Row():
        with gr.Column(scale=1):
            # ä»»åŠ¡ç±»å‹é€‰æ‹©
            gr.Markdown("### 1ï¸âƒ£ ä»»åŠ¡è®¾ç½®")
            task_dropdown = gr.Dropdown(
                choices=list(TASK_DESCRIPTIONS.keys()),
                value="summary",
                label="ä»»åŠ¡ç±»å‹",
                interactive=True
            )
            task_description = gr.Textbox(
                label="ä»»åŠ¡è¯´æ˜",
                value=TASK_DESCRIPTIONS["summary"],
                interactive=False,
                lines=2
            )
            
            # æ–‡ä»¶ä¸Šä¼ 
            gr.Markdown("### 2ï¸âƒ£ æ–‡ä»¶ä¸Šä¼ ")
            video_input = gr.Video(
                label="ä¸Šä¼ è§†é¢‘",
                sources=["upload"]
            )
            audio_input = gr.Audio(
                label="ä¸Šä¼ éŸ³é¢‘ï¼ˆå¯é€‰ï¼Œå¦‚ä¸ä¸Šä¼ å°†è‡ªåŠ¨ä»è§†é¢‘æå–ï¼‰",
                type="filepath",
                sources=["upload"]
            )
        
        with gr.Column(scale=1):
            # é—®é¢˜è¾“å…¥
            gr.Markdown("### 3ï¸âƒ£ é—®é¢˜/æŒ‡ä»¤")
            question_input = gr.Textbox(
                label="è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æŒ‡ä»¤",
                placeholder="è¯·è¾“å…¥é—®é¢˜...",
                lines=5,
                value=""
            )
            
            example_btn = gr.Button("ğŸ’¡ å¡«å……ç¤ºä¾‹é—®é¢˜")
            
            # æäº¤æŒ‰é’®
            submit_btn = gr.Button("ğŸš€ å¼€å§‹åˆ†æ", variant="primary")
            
            # è¾“å‡ºç»“æœ
            gr.Markdown("### 4ï¸âƒ£ åˆ†æç»“æœ")
            output_text = gr.Textbox(
                label="æ¨¡å‹è¾“å‡º",
                lines=15,
                interactive=False
            )
    
    # ç¤ºä¾‹
    gr.Markdown("### ğŸ“ ä½¿ç”¨ç¤ºä¾‹")
    gr.Examples(
        examples=[
            ["summary", "è¯¥è§†é¢‘æ ‡é¢˜ä¸º[æ ‡é¢˜]\næè¿°è§†é¢‘å†…å®¹."],
            ["QA", "è¿™ä¸ªè§†é¢‘çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ"],
            ["Grounding", "æˆ‘ä»¬ä½•æ—¶èƒ½çœ‹åˆ°ç‰¹å®šçš„åœºæ™¯æˆ–äº‹ä»¶ï¼Ÿ"],
            ["MCQ", "è§†é¢‘ä¸­æœ€åå‡ºç°çš„æ˜¯ä»€ä¹ˆï¼Ÿ\nA.é€‰é¡¹1\nB.é€‰é¡¹2\nC.é€‰é¡¹3\nD.é€‰é¡¹4"],
            ["segment", "è¯·æŒ‰æ—¶é—´é¡ºåºç»™å‡ºè§†é¢‘çš„ç« èŠ‚æ‘˜è¦å’Œå¯¹åº”æ—¶é—´ç‚¹"],
        ],
        inputs=[task_dropdown, question_input],
        label="ç‚¹å‡»åŠ è½½ç¤ºä¾‹"
    )
    
    # äº‹ä»¶å¤„ç†
    def update_task_description(task):
        return TASK_DESCRIPTIONS[task]
    
    def fill_example_question(task):
        return get_example_questions(task)
    
    # ç»‘å®šäº‹ä»¶
    task_dropdown.change(
        fn=update_task_description,
        inputs=[task_dropdown],
        outputs=[task_description]
    )
    
    example_btn.click(
        fn=fill_example_question,
        inputs=[task_dropdown],
        outputs=[question_input]
    )
    
    submit_btn.click(
        fn=process_video,
        inputs=[video_input, question_input, task_dropdown, audio_input],
        outputs=[output_text]
    )
    
    gr.Markdown(
        """
        ---
        ### ğŸ“Œ æ³¨æ„äº‹é¡¹
        
        - é¦–æ¬¡åŠ è½½æ¨¡å‹éœ€è¦ä¸€å®šæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
        - è§†é¢‘å¤„ç†æ—¶é—´å–å†³äºè§†é¢‘é•¿åº¦å’Œå¤æ‚åº¦
        - æ”¯æŒæœ€é•¿ 300 ç§’çš„è§†é¢‘ï¼Œè¶…è¿‡ä¼šè‡ªåŠ¨æˆªå–
        - å»ºè®®ä½¿ç”¨ GPU è¿è¡Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½
        - ä¸åŒä»»åŠ¡ç±»å‹éœ€è¦ä¸åŒçš„æé—®æ–¹å¼ï¼Œè¯·å‚è€ƒç¤ºä¾‹
        
        ### ğŸ”§ æŠ€æœ¯ä¿¡æ¯
        
        - æ¨¡å‹: TencentARC ARC-Hunyuan-Video-7B
        - æ¡†æ¶: Transformers + Gradio
        - æ”¯æŒ: è§†é¢‘ç†è§£ã€éŸ³é¢‘åˆ†æã€å¤šæ¨¡æ€èåˆ
        """
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    # æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        print("âš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ° CUDAï¼Œæ¨¡å‹å°†æ— æ³•æ­£å¸¸è¿è¡Œï¼")
        print("è¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒé…ç½®äº† GPU æ”¯æŒ")
    else:
        print(f"âœ… æ£€æµ‹åˆ° CUDAï¼Œä½¿ç”¨ GPU: {torch.cuda.get_device_name(0)}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    print("\næ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    if os.path.exists(MODEL_PATH):
        print(f"âœ… æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    else:
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {MODEL_PATH}")
        exit(1)
    
    # å¯åŠ¨æ—¶è‡ªåŠ¨åŠ è½½æ¨¡å‹
    print("\næ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
    load_model()
    
    print("\nå¯åŠ¨ Gradio åº”ç”¨...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
