import torch
import gradio as gr
from diffusers import Step1XEditPipelineV1P2
from PIL import Image

# åŠ è½½æ¨¡å‹
print("=== åŠ è½½æ¨¡å‹ ===")
pipe = Step1XEditPipelineV1P2.from_pretrained("checkpoints/Step1X-Edit-v1p2", torch_dtype=torch.bfloat16)
pipe.to("cuda")
print("=== æ¨¡å‹åŠ è½½å®Œæˆ ===")

# å®šä¹‰ç¤ºä¾‹
EXAMPLES = [
    # [å›¾ç‰‡è·¯å¾„, ç¼–è¾‘æç¤ºè¯]
    ["checkpoints/Step1X-Edit-v1p2/examples/0000.jpg", "add a ruby pendant on the girl's neck"],
    ["checkpoints/Step1X-Edit-v1p2/examples/0001.png", "change the blazer color from red to blue"],
    ["checkpoints/Step1X-Edit-v1p2/examples/0002.jpg", "change the guitar color from blue to red"],
    ["checkpoints/Step1X-Edit-v1p2/examples/0003.png", "change the headband color to red"],
    ["checkpoints/Step1X-Edit-v1p2/examples/0004.jpg", "change the text 'NEW ENGLAND' to 'SWITZERLAND'"],
]


def process_image(
    image: Image.Image,
    prompt: str,
    num_inference_steps: int,
    true_cfg_scale: float,
    seed: int,
    enable_thinking_mode: bool,
    enable_reflection_mode: bool,
):
    """å¤„ç†å›¾ç‰‡ç¼–è¾‘è¯·æ±‚"""
    if image is None:
        return None, "è¯·ä¸Šä¼ å›¾ç‰‡"
    
    if not prompt.strip():
        return None, "è¯·è¾“å…¥ç¼–è¾‘æç¤ºè¯"
    
    # è½¬æ¢å›¾ç‰‡æ ¼å¼
    image = image.convert("RGB")
    
    # è¿è¡Œ pipeline
    pipe_output = pipe(
        image=image,
        prompt=prompt,
        num_inference_steps=num_inference_steps,
        true_cfg_scale=true_cfg_scale,
        generator=torch.Generator().manual_seed(seed),
        enable_thinking_mode=enable_thinking_mode,
        enable_reflection_mode=enable_reflection_mode,
    )
    
    # æ„å»ºè¾“å‡ºä¿¡æ¯
    info_text = ""
    if enable_thinking_mode and pipe_output.reformat_prompt:
        info_text += f"**Reformat Prompt:** {pipe_output.reformat_prompt}\n\n"
    
    if enable_reflection_mode and pipe_output.think_info:
        info_text += f"**Think Info:** {pipe_output.think_info[0]}\n\n"
    
    if enable_reflection_mode and pipe_output.best_info:
        info_text += f"**Best Info:** {pipe_output.best_info[0]}\n\n"
    
    # è¿”å›æœ€ç»ˆå›¾ç‰‡å’Œä¿¡æ¯
    final_image = pipe_output.final_images[0] if pipe_output.final_images else pipe_output.images[0]
    
    return final_image, info_text if info_text else "ç¼–è¾‘å®Œæˆ"


# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="Step1X-Edit V1P2") as demo:
    gr.Markdown(
        """
        # ğŸ¨ Step1X-Edit V1P2
        
        åŸºäº Step1X-Edit çš„å›¾åƒç¼–è¾‘å·¥å…·ï¼Œæ”¯æŒé€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç¼–è¾‘å›¾ç‰‡ã€‚
        
        **ä½¿ç”¨æ–¹æ³•ï¼š**
        1. ä¸Šä¼ å›¾ç‰‡æˆ–é€‰æ‹©ä¸‹æ–¹ç¤ºä¾‹
        2. è¾“å…¥ç¼–è¾‘æç¤ºè¯ï¼ˆå¦‚ï¼šæ·»åŠ é¡¹é“¾ã€æ”¹å˜é¢œè‰²ã€æ›¿æ¢æ–‡å­—ç­‰ï¼‰
        3. è°ƒæ•´å‚æ•°åç‚¹å‡»"å¼€å§‹ç¼–è¾‘"
        """
    )
    
    with gr.Row():
        with gr.Column(scale=1):
            # è¾“å…¥åŒºåŸŸ
            input_image = gr.Image(label="è¾“å…¥å›¾ç‰‡", type="pil", height=400)
            prompt = gr.Textbox(
                label="ç¼–è¾‘æç¤ºè¯",
                placeholder="ä¾‹å¦‚ï¼šadd a ruby pendant on the girl's neck",
                lines=2
            )
            
            with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
                num_steps = gr.Slider(
                    minimum=10, maximum=100, value=50, step=1,
                    label="æ¨ç†æ­¥æ•° (num_inference_steps)"
                )
                cfg_scale = gr.Slider(
                    minimum=1.0, maximum=15.0, value=6.0, step=0.5,
                    label="CFG Scale (true_cfg_scale)"
                )
                seed = gr.Number(value=42, label="éšæœºç§å­", precision=0)
                enable_thinking = gr.Checkbox(value=True, label="å¯ç”¨æ€è€ƒæ¨¡å¼ (Thinking Mode)")
                enable_reflection = gr.Checkbox(value=True, label="å¯ç”¨åæ€æ¨¡å¼ (Reflection Mode)")
            
            submit_btn = gr.Button("ğŸš€ å¼€å§‹ç¼–è¾‘", variant="primary", size="lg")
        
        with gr.Column(scale=1):
            # è¾“å‡ºåŒºåŸŸ
            output_image = gr.Image(label="ç¼–è¾‘ç»“æœ", type="pil", height=400)
            output_info = gr.Markdown(label="å¤„ç†ä¿¡æ¯")
    
    # ç¤ºä¾‹åŒºåŸŸ
    gr.Markdown("### ğŸ“· ç¤ºä¾‹å›¾ç‰‡")
    gr.Examples(
        examples=EXAMPLES,
        inputs=[input_image, prompt],
        label="ç‚¹å‡»é€‰æ‹©ç¤ºä¾‹",
        examples_per_page=5,
    )
    
    # ç»‘å®šäº‹ä»¶
    submit_btn.click(
        fn=process_image,
        inputs=[
            input_image,
            prompt,
            num_steps,
            cfg_scale,
            seed,
            enable_thinking,
            enable_reflection,
        ],
        outputs=[output_image, output_info],
    )


if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
