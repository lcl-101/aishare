#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LightX2V Qwen-Image æ–‡ç”Ÿå›¾æ¼”ç¤ºç¨‹åº
åŸºäº Gradio çš„ç‹¬ç«‹ Web ç•Œé¢

ä½œè€…: AI æŠ€æœ¯åˆ†äº«é¢‘é“
YouTube: https://www.youtube.com/@rongyikanshijie-ai
"""

import gc
import json
import os
import sys
import time
import warnings
from datetime import datetime

# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["PROFILING_DEBUG_LEVEL"] = "2"
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.environ["DTYPE"] = "BF16"

import gradio as gr
import torch
from loguru import logger

# é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, PROJECT_ROOT)

from lightx2v.utils.registry_factory import RUNNER_REGISTER
from lightx2v.utils.set_config import set_config, print_config
from lightx2v.utils.utils import seed_all
from lightx2v.utils.input_info import set_input_info
from lightx2v.models.runners.qwen_image.qwen_image_runner import QwenImageRunner  # noqa: F401

# æ¨¡å‹è·¯å¾„é…ç½®
CHECKPOINT_DIR = os.path.join(PROJECT_ROOT, "checkpoints")
MODEL_PATH_ORIGINAL = os.path.join(CHECKPOINT_DIR, "Qwen-Image-2512")
MODEL_PATH_LIGHTNING = os.path.join(CHECKPOINT_DIR, "Qwen-Image-2512-Lightning")
LORA_PATH = os.path.join(MODEL_PATH_LIGHTNING, "Qwen-Image-2512-Lightning-4steps-V1.0-fp32.safetensors")

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_DIR = os.path.join(PROJECT_ROOT, "configs", "qwen_image")
CONFIG_ORIGINAL = os.path.join(CONFIG_DIR, "qwen_image_t2i_2512.json")
CONFIG_LORA = os.path.join(CONFIG_DIR, "qwen_image_t2i_2512_lora.json")

# è¾“å‡ºè·¯å¾„
SAVE_DIR = os.path.join(PROJECT_ROOT, "save_results")
os.makedirs(SAVE_DIR, exist_ok=True)

# ç¤ºä¾‹æç¤ºè¯ - æŒ‰åŠŸèƒ½åˆ†ç±» [åŠŸèƒ½å¢å¼ºç±»åˆ«, æç¤ºè¯]
EXAMPLE_PROMPTS = [
    # äººç‰©å†™å®
    [
        "ğŸ§‘ äººç‰©å†™å® - ç²¾ç»†å‘ä¸å’Œè‡ªç„¶è¡¨æƒ…",
        "A 20-year-old East Asian girl with delicate, charming features and large, bright brown eyesâ€”expressive and lively, with a cheerful or subtly smiling expression. Her naturally wavy long hair is either loose or tied in twin ponytails. She has fair skin and light makeup accentuating her youthful freshness. She wears a modern, cute dress or relaxed outfit in bright, soft colorsâ€”lightweight fabric, minimalist cut. She stands indoors at an anime convention, surrounded by banners, posters, or stalls. Lighting is typical indoor illuminationâ€”no staged lightingâ€”and the image resembles a casual iPhone snapshot: unpretentious composition, yet brimming with vivid, fresh, youthful charm.",
    ],
    [
        "ğŸ§‘ äººç‰©å†™å® - é¢éƒ¨ç»†èŠ‚å’Œç¯å¢ƒèƒŒæ™¯",
        "A Chinese female college student, around 20 years old, with a very short haircut that conveys a gentle, artistic vibe. Her hair naturally falls to partially cover her cheeks, projecting a tomboyish yet charming demeanor. She has cool-toned fair skin and delicate features, with a slightly shy yet subtly confident expressionâ€”her mouth crooked in a playful, youthful smirk. She wears an off-shoulder top, revealing one shoulder, with a well-proportioned figure. The image is framed as a close-up selfie: she dominates the foreground, while the background clearly shows her dormitoryâ€”a neatly made bed with white linens on the top bunk, a tidy study desk with organized stationery, and wooden cabinets and drawers. The photo is captured on a smartphone under soft, even ambient lighting, with natural tones, high clarity, and a bright, lively atmosphere full of youthful, everyday energy.",
    ],
    [
        "ğŸ§‘ äººç‰©å†™å® - ç²¾ç¡®å§¿æ€è¯­ä¹‰éµå¾ª",
        "An East Asian teenage boy, aged 15â€“18, with soft, fluffy black short hair and refined facial contours. His large, warm brown eyes sparkle with energy. His fair skin and sunny, open smile convey an approachable, friendly demeanorâ€”no makeup or blemishes. He wears a blue-and-white summer uniform shirt, slightly unbuttoned, made of thin breathable fabric, with black headphones hanging around his neck. His hands are in his pockets, body leaning slightly forward in a relaxed pose, as if engaged in conversation. Behind him lies a summer school playground: lush green grass and a red rubber track in the foreground, blurred school buildings in the distance, a clear blue sky with fluffy white clouds. The bright, airy lighting evokes a joyful, carefree adolescent atmosphere.",
    ],
    [
        "ğŸ§‘ äººç‰©å†™å® - å¹´é¾„ç‰¹å¾ï¼ˆçš±çº¹ï¼‰æ¸²æŸ“",
        "An elderly Chinese couple in their 70s in a clean, organized home kitchen. The woman has a kind face and a warm smile, wearing a patterned apron; the man stands behind her, also smiling, as they both gaze at a steaming pot of buns on the stove. The kitchen is bright and tidy, exuding warmth and harmony. The scene is captured with a wide-angle lens to fully show the subjects and their surroundings.",
    ],
    # è‡ªç„¶é£æ™¯
    [
        "ğŸŒ¿ è‡ªç„¶çº¹ç† - æ°´æµæ¤è¢«é›¾æ°”æ¸²æŸ“",
        "A turquoise river winds through a lush canyon. Thick moss and dense ferns blanket the rocky walls; multiple waterfalls cascade from above, enveloped in mist. At noon, sunlight filters through the dense canopy, dappling the river surface with shimmering light. The atmosphere is humid and fresh, pulsing with primal jungle vitality. No humans, text, or artificial traces present.",
    ],
    [
        "ğŸŒ¿ è‡ªç„¶çº¹ç† - æµ·æµªä¸æ™¨é›¾æ¸²æŸ“",
        "At dawn, a thin mist veils the sea. An ancient stone lighthouse stands at the cliff's edge, its beacon faintly visible through the fog. Black rocks are pounded by waves, sending up bursts of white spray. The sky glows in soft blue-purple hues under cool, hazy lightâ€”evoking solitude and solemn grandeur.",
    ],
    # åŠ¨ç‰©æ¯›å‘
    [
        "ğŸ• åŠ¨ç‰©æ¯›å‘ - ç²¾ç»†æ¯›å‘çº¹ç†",
        "An ultra-realistic close-up of a golden retriever outdoors under soft daylight. Hair is exquisitely detailed: strands distinct, color transitioning naturally from warm gold to light cream, light glinting delicately at the tips; a gentle breeze adds subtle volume. Undercoat is soft and dense; guard hairs are long and well-defined, with visible layering. Eyes are moist, expressive; nose is slightly damp with fine specular highlights. Background is softly blurred to emphasize the dog's tangible texture and vivid expression.",
    ],
    [
        "ğŸ• åŠ¨ç‰©æ¯›å‘ - ç²—ç³™é‡ç”ŸåŠ¨ç‰©çº¹ç†",
        "A male argali stands atop a barren, rocky mountainside. Its coarse, dense grey-brown coat covers a powerful, muscular body. Most striking are its massive, thick, outward-spiraling hornsâ€”a symbol of wild strength. Its gaze is alert and sharp. The background reveals steep alpine terrain: jagged peaks, sparse low vegetation, and abundant sunlightâ€”conveying the harsh yet majestic wilderness and the animal's resilient vitality.",
    ],
    # æ–‡å­—æ¸²æŸ“
    [
        "ğŸ“ æ–‡å­—æ¸²æŸ“ - PPTæ—¶é—´è½´å›¾æ–‡æ··æ’",
        'è¿™æ˜¯ä¸€å¼ ç°ä»£é£æ ¼çš„ç§‘æŠ€æ„Ÿå¹»ç¯ç‰‡ï¼Œæ•´ä½“é‡‡ç”¨æ·±è“è‰²æ¸å˜èƒŒæ™¯ã€‚æ ‡é¢˜æ˜¯"Qwen-Imageå‘å±•å†ç¨‹"ã€‚ä¸‹æ–¹ä¸€æ¡æ°´å¹³å»¶ä¼¸çš„å‘å…‰æ—¶é—´è½´ï¼Œè½´çº¿ä¸­é—´å†™ç€"ç”Ÿå›¾è·¯çº¿"ã€‚ç”±å·¦ä¾§æ·¡è“è‰²æ¸å˜ä¸ºå³ä¾§æ·±ç´«è‰²ï¼Œå¹¶ä»¥ç²¾è‡´çš„ç®­å¤´æ”¶å°¾ã€‚æ—¶é—´è½´ä¸Šæ¯ä¸ªèŠ‚ç‚¹é€šè¿‡è™šçº¿è¿æ¥è‡³ä¸‹æ–¹é†’ç›®çš„è“è‰²åœ†è§’çŸ©å½¢æ—¥æœŸæ ‡ç­¾ï¼Œæ ‡ç­¾å†…ä¸ºæ¸…æ™°ç™½è‰²å­—ä½“ï¼Œä»å·¦å‘å³ä¾æ¬¡å†™ç€ï¼š"2025å¹´5æœˆ6æ—¥ Qwen-Image é¡¹ç›®å¯åŠ¨""2025å¹´8æœˆ4æ—¥ Qwen-Image å¼€æºå‘å¸ƒ""2025å¹´12æœˆ31æ—¥ Qwen-Image-2512 å¼€æºå‘å¸ƒ" ï¼ˆå‘¨å›´å…‰æ™•æ˜¾è‘—ï¼‰åœ¨ä¸‹æ–¹ä¸€æ¡æ°´å¹³å»¶ä¼¸çš„å‘å…‰æ—¶é—´è½´ï¼Œè½´çº¿ä¸­é—´å†™ç€"ç¼–è¾‘è·¯çº¿"ã€‚ç”±å·¦ä¾§æ·¡è“è‰²æ¸å˜ä¸ºå³ä¾§æ·±ç´«è‰²ï¼Œå¹¶ä»¥ç²¾è‡´çš„ç®­å¤´æ”¶å°¾ã€‚æ—¶é—´è½´ä¸Šæ¯ä¸ªèŠ‚ç‚¹é€šè¿‡è™šçº¿è¿æ¥è‡³ä¸‹æ–¹é†’ç›®çš„è“è‰²åœ†è§’çŸ©å½¢æ—¥æœŸæ ‡ç­¾ï¼Œæ ‡ç­¾å†…ä¸ºæ¸…æ™°ç™½è‰²å­—ä½“ï¼Œä»å·¦å‘å³ä¾æ¬¡å†™ç€ï¼š"2025å¹´8æœˆ18æ—¥ Qwen-Image-Edit å¼€æºå‘å¸ƒ""2025å¹´9æœˆ22æ—¥ Qwen-Image-Edit-2509 å¼€æºå‘å¸ƒ""2025å¹´12æœˆ19æ—¥ Qwen-Image-Layered å¼€æºå‘å¸ƒ""2025å¹´12æœˆ23æ—¥ Qwen-Image-Edit-2511 å¼€æºå‘å¸ƒ"',
    ],
    [
        "ğŸ“ æ–‡å­—æ¸²æŸ“ - äº§å“å¯¹æ¯”å›¾æ··åˆæ¸²æŸ“",
        'è¿™æ˜¯ä¸€å¼ ç°ä»£é£æ ¼çš„ç§‘æŠ€æ„Ÿå¹»ç¯ç‰‡ï¼Œæ•´ä½“é‡‡ç”¨æ·±è“è‰²æ¸å˜èƒŒæ™¯ã€‚é¡¶éƒ¨ä¸­å¤®ä¸ºç™½è‰²æ— è¡¬çº¿ç²—ä½“å¤§å­—æ ‡é¢˜"Qwen-Image-2512é‡ç£…å‘å¸ƒ"ã€‚ç”»é¢ä¸»ä½“ä¸ºæ¨ªå‘å¯¹æ¯”å›¾ï¼Œè§†è§‰ç„¦ç‚¹é›†ä¸­äºä¸­é—´çš„å‡çº§å¯¹æ¯”åŒºåŸŸã€‚å·¦ä¾§ä¸ºé¢éƒ¨å…‰æ»‘æ²¡æœ‰ä»»ä½•ç»†èŠ‚çš„å¥³æ€§äººåƒï¼Œè´¨æ„Ÿå·®ï¼›å³ä¾§ä¸ºé«˜åº¦å†™å®çš„å¹´è½»å¥³æ€§è‚–åƒï¼Œçš®è‚¤å‘ˆç°çœŸå®æ¯›å­”çº¹ç†ä¸ç»†å¾®å…‰å½±å˜åŒ–ï¼Œå‘ä¸æ ¹æ ¹åˆ†æ˜ï¼Œçœ¼çœ¸é€äº®ï¼Œè¡¨æƒ…è‡ªç„¶ï¼Œæ•´ä½“è´¨æ„Ÿæ¥è¿‘å†™å®æ‘„å½±ã€‚ä¸¤å›¾åƒä¹‹é—´ä»¥ä¸€ä¸ªç»¿è‰²æµçº¿å‹ç®­å¤´é“¾æ¥ã€‚é€ å‹ç§‘æŠ€æ„Ÿåè¶³ï¼Œä¸­éƒ¨æ ‡æ³¨"2512è´¨æ„Ÿå‡çº§"ï¼Œä½¿ç”¨ç™½è‰²åŠ ç²—å­—ä½“ï¼Œå±…ä¸­æ˜¾ç¤ºã€‚ç®­å¤´ä¸¤ä¾§æœ‰å¾®å¼±å…‰æ™•æ•ˆæœï¼Œå¢å¼ºåŠ¨æ€æ„Ÿã€‚åœ¨å›¾åƒä¸‹æ–¹ï¼Œä»¥ç™½è‰²æ–‡å­—å‘ˆç°ä¸‰è¡Œè¯´æ˜ï¼š"â— æ›´çœŸå®çš„äººç‰©è´¨æ„Ÿã€‚å¤§å¹…åº¦é™ä½äº†ç”Ÿæˆå›¾ç‰‡çš„AIæ„Ÿï¼Œæå‡äº†å›¾åƒçœŸå®æ€§ â— æ›´ç»†è…»çš„è‡ªç„¶çº¹ç†ã€‚å¤§å¹…åº¦æå‡äº†ç”Ÿæˆå›¾ç‰‡çš„çº¹ç†ç»†èŠ‚ã€‚é£æ™¯å›¾ï¼ŒåŠ¨ç‰©æ¯›å‘åˆ»ç”»æ›´ç»†è…»ã€‚â— æ›´å¤æ‚çš„æ–‡å­—æ¸²æŸ“ã€‚å¤§å¹…æå‡äº†æ–‡å­—æ¸²æŸ“çš„è´¨é‡ã€‚å›¾æ–‡æ··åˆæ¸²æŸ“æ›´å‡†ç¡®ï¼Œæ’ç‰ˆæ›´å¥½"',
    ],
    [
        "ğŸ“ æ–‡å­—æ¸²æŸ“ - å·¥ä¸šä¿¡æ¯å›¾è¡¨å¤æ‚å¸ƒå±€",
        'è¿™æ˜¯ä¸€å¹…ä¸“ä¸šçº§å·¥ä¸šæŠ€æœ¯ä¿¡æ¯å›¾è¡¨ï¼Œæ•´ä½“é‡‡ç”¨æ·±è“è‰²ç§‘æŠ€æ„ŸèƒŒæ™¯ï¼Œå…‰çº¿å‡åŒ€æŸ”å’Œï¼Œè¥é€ å‡ºå†·é™ã€ç²¾å‡†çš„ç°ä»£å·¥ä¸šæ°›å›´ã€‚ç”»é¢åˆ†ä¸ºå·¦å³ä¸¤å¤§æ¿å—ï¼Œå¸ƒå±€æ¸…æ™°ï¼Œè§†è§‰å±‚æ¬¡åˆ†æ˜ã€‚å·¦ä¾§æ¿å—æ ‡é¢˜ä¸º"å®é™…å‘ç”Ÿçš„ç°è±¡"ï¼Œä»¥æµ…è“è‰²åœ†è§’çŸ©å½¢æ¡†çªå‡ºæ˜¾ç¤ºï¼Œå†…éƒ¨æ’åˆ—ä¸‰ä¸ªæ·±è“è‰²æŒ‰é’®å¼æ¡ç›®ï¼Œç¬¬ä¸€ä¸ªæ¡ç›®å±•ç¤ºä¸€å †æ£•è‰²ç²‰æœ«çŠ¶åŸæ–™ä¸Šæ»´è½æ°´æ»´çš„å›¾æ ‡ï¼Œæ–‡å­—ä¸º"å›¢èš/ç»“å—"ï¼Œåé¢é…æœ‰ç»¿è‰²å¯¹é’©ï¼›ç¬¬äºŒä¸ªæ¡ç›®ä¸ºä¸€ä¸ªè£…æœ‰è“è‰²æ¶²ä½“å¹¶å†’å‡ºæ°”æ³¡çš„é”¥å½¢ç“¶ï¼Œæ–‡å­—ä¸º"äº§ç”Ÿæ°”æ³¡/ç¼ºé™·"ï¼Œåé¢é…æœ‰ç»¿è‰²å¯¹é’©ï¼›ç¬¬ä¸‰ä¸ªæ¡ç›®ä¸ºä¸¤ä¸ªç”Ÿé”ˆçš„é½¿è½®ï¼Œæ–‡å­—ä¸º"è®¾å¤‡è…èš€/å‚¬åŒ–å‰‚å¤±æ´»"ï¼Œåé¢é…æœ‰ç»¿è‰²å¯¹é’©ã€‚å³ä¾§æ¿å—æ ‡é¢˜ä¸º"ã€ä¸ä¼šã€‘å‘ç”Ÿçš„ç°è±¡"ï¼Œä½¿ç”¨ç±³é»„è‰²åœ†è§’çŸ©å½¢æ¡†å‘ˆç°ï¼Œå†…éƒ¨å››ä¸ªæ¡ç›®å‡ç½®äºæ·±ç°è‰²èƒŒæ™¯æ–¹æ¡†ä¸­ã€‚å›¾æ ‡åˆ†åˆ«ä¸ºï¼šä¸€ç»„ç²¾å¯†å•®åˆçš„é‡‘å±é½¿è½®ï¼Œæ–‡å­—ä¸º"ååº”æ•ˆç‡ã€æ˜¾è‘—æé«˜ã€‘"ï¼Œä¸Šæ–¹è¦†ç›–é†’ç›®çš„çº¢è‰²å‰å·ï¼›ä¸€æ†æ•´é½æ’åˆ—çš„é‡‘å±ç®¡æï¼Œæ–‡å­—ä¸º"æˆå“å†…éƒ¨ã€ç»å¯¹æ— æ°”æ³¡/å­”éš™ã€‘"ï¼Œä¸Šæ–¹è¦†ç›–é†’ç›®çš„çº¢è‰²å‰å·ï¼›ä¸€æ¡åšå›ºçš„é‡‘å±é“¾æ¡æ­£åœ¨æ‰¿å—æ‹‰åŠ›ï¼Œæ–‡å­—ä¸º"ææ–™å¼ºåº¦ä¸è€ä¹…æ€§ã€å¾—åˆ°å¢å¼ºã€‘"ï¼Œä¸Šæ–¹è¦†ç›–é†’ç›®çš„çº¢è‰²å‰å·ï¼›ä¸€å †è…èš€çš„æ‰³æ‰‹ï¼Œæ–‡å­—ä¸º"åŠ å·¥è¿‡ç¨‹ã€é›¶è…èš€/é›¶å‰¯ååº”é£é™©ã€‘"ï¼Œä¸Šæ–¹è¦†ç›–é†’ç›®çš„çº¢è‰²å‰å·ã€‚åº•éƒ¨ä¸­å¤®æœ‰ä¸€è¡Œå°å­—æ³¨é‡Šï¼š"æ³¨ï¼šæ°´åˆ†çš„å­˜åœ¨é€šå¸¸ä¼šå¯¼è‡´è´Ÿé¢æˆ–å¹²æ‰°æ€§çš„ç»“æœï¼Œè€Œéç†æƒ³æˆ–å¢å¼ºçš„çŠ¶æ€"ï¼Œå­—ä½“ä¸ºç™½è‰²ï¼Œæ¸…æ™°å¯è¯»ã€‚æ•´ä½“é£æ ¼ç°ä»£ç®€çº¦ï¼Œé…è‰²å¯¹æ¯”å¼ºçƒˆï¼Œå›¾å½¢ç¬¦å·å‡†ç¡®ä¼ è¾¾æŠ€æœ¯é€»è¾‘ï¼Œé€‚åˆç”¨äºå·¥ä¸šåŸ¹è®­æˆ–ç§‘æ™®æ¼”ç¤ºåœºæ™¯ã€‚',
    ],
    [
        "ğŸ“ æ–‡å­—æ¸²æŸ“ - ç½‘æ ¼æµ·æŠ¥æ—¶é—´æ ‡æ³¨",
        'è¿™æ˜¯ä¸€å¹…ç”±åäºŒä¸ªåˆ†æ ¼ç»„æˆçš„3Ã—4ç½‘æ ¼å¸ƒå±€çš„å†™å®æ‘„å½±ä½œå“ï¼Œæ•´ä½“å‘ˆç°"å¥åº·çš„ä¸€å¤©"ä¸»é¢˜ï¼Œç”»é¢é£æ ¼ç®€æ´æ¸…æ™°ï¼Œæ¯ä¸€åˆ†æ ¼ç‹¬ç«‹æˆæ™¯åˆç»Ÿä¸€äºç”Ÿæ´»èŠ‚å¥çš„å™äº‹è„‰ç»œã€‚ç¬¬ä¸€è¡Œåˆ†åˆ«æ˜¯"06:00 æ™¨è·‘å”¤é†’èº«ä½“"ï¼šé¢éƒ¨ç‰¹å†™ï¼Œä¸€ä½å¥³æ€§èº«ç©¿ç°è‰²è¿åŠ¨å¥—è£…ï¼ŒèƒŒæ™¯æ˜¯åˆå‡çš„æœé˜³ä¸è‘±éƒç»¿æ ‘ï¼›"06:30 åŠ¨æ€æ‹‰ä¼¸æ¿€æ´»å…³èŠ‚"ï¼šå¥³æ€§èº«ç€ç‘œä¼½æœåœ¨é˜³å°åšæ™¨é—´æ‹‰ä¼¸ï¼Œèº«ä½“èˆ’å±•ï¼ŒèƒŒæ™¯ä¸ºæ·¡ç²‰è‰²å¤©ç©ºä¸è¿œå±±è½®å»“ï¼›"07:30 å‡è¡¡è¥å…»æ—©é¤"ï¼šæ¡Œä¸Šæ‘†æ”¾å…¨éº¦é¢åŒ…ã€ç‰›æ²¹æœå’Œä¸€æ¯æ©™æ±ï¼Œå¥³æ€§å¾®ç¬‘ç€å‡†å¤‡ç”¨é¤ï¼›"08:00 è¡¥æ°´æ¶¦ç‡¥"ï¼šé€æ˜ç»ç’ƒæ°´æ¯ä¸­æµ®æœ‰æŸ æª¬ç‰‡ï¼Œå¥³æ€§æ‰‹æŒæ°´æ¯è½»å•œï¼Œé˜³å…‰ä»å·¦ä¾§æ–œç…§å…¥å®¤ï¼Œæ¯å£æ°´ç æ»‘è½ï¼›ç¬¬äºŒè¡Œåˆ†åˆ«æ˜¯ï¼š"09:00 ä¸“æ³¨é«˜æ•ˆå·¥ä½œ"ï¼šå¥³æ€§ä¸“æ³¨æ•²å‡»é”®ç›˜ï¼Œå±å¹•æ˜¾ç¤ºç®€æ´ç•Œé¢ï¼Œèº«æ—æ”¾æœ‰ä¸€æ¯å’–å•¡ä¸ä¸€ç›†ç»¿æ¤ï¼›"12:00 é™å¿ƒé˜…è¯»æ—¶å…‰"ï¼šå¥³æ€§ååœ¨ä¹¦æ¡Œå‰ç¿»é˜…çº¸è´¨ä¹¦ç±ï¼Œå°ç¯æ•£å‘æš–å…‰ï¼Œä¹¦é¡µæ³›é»„ï¼Œæ—æ”¾åŠæ¯çº¢èŒ¶ï¼›"12:30 åˆåè½»æ¾æ¼«æ­¥"ï¼šå¥³æ€§åœ¨æ—è«é“ä¸Šæ¼«æ­¥ï¼Œè„¸éƒ¨ç‰¹å†™ï¼›"15:00 èŒ¶é¦™ä¼´åˆå"ï¼šå¥³æ€§ç«¯ç€éª¨ç“·èŒ¶æ¯ç«™åœ¨çª—è¾¹ï¼Œçª—å¤–æ˜¯åŸå¸‚è¡—æ™¯ä¸é£˜åŠ¨äº‘æœµï¼ŒèŒ¶é¦™è¢…è¢…ï¼›ç¬¬ä¸‰è¡Œåˆ†åˆ«æ˜¯ï¼š"18:00 è¿åŠ¨é‡Šæ”¾å‹åŠ›"ï¼šå¥èº«æˆ¿å†…ï¼Œå¥³æ€§æ­£åœ¨ç»ƒä¹ ç‘œä¼½ï¼›"19:00 ç¾å‘³æ™šé¤"ï¼šå¥³æ€§åœ¨å¼€æ”¾å¼å¨æˆ¿ä¸­åˆ‡èœï¼Œç §æ¿ä¸Šæœ‰ç•ªèŒ„ä¸é’æ¤’ï¼Œé”…ä¸­çƒ­æ°”å‡è…¾ï¼Œç¯å…‰æ¸©æš–ï¼›"21:00 å†¥æƒ³åŠ©çœ "ï¼šå¥³æ€§ç›˜è…¿ååœ¨æŸ”è½¯åœ°æ¯¯ä¸Šå†¥æƒ³ï¼ŒåŒæ‰‹è½»æ”¾è†ä¸Šï¼Œé—­ç›®å®é™ï¼›"21:30 è¿›å…¥ç¡çœ "ï¼šå¥³æ€§èººåœ¨åºŠä¸Šä¼‘æ¯ã€‚æ•´ä½“é‡‡ç”¨è‡ªç„¶å…‰çº¿ä¸ºä¸»ï¼Œè‰²è°ƒä»¥æš–ç™½ä¸ç±³ç°ä¸ºåŸºè°ƒï¼Œå…‰å½±å±‚æ¬¡åˆ†æ˜ï¼Œç”»é¢å……æ»¡æ¸©é¦¨çš„ç”Ÿæ´»æ°”æ¯ä¸è§„å¾‹çš„èŠ‚å¥æ„Ÿã€‚',
    ],
]

# æ¨¡å‹é…ç½®ä¿¡æ¯
MODEL_CONFIGS = {
    "original": {
        "name": "åŸå§‹æ¨¡å‹ (50æ­¥)",
        "description": "Qwen-Image-2512 åŸå§‹æ¨¡å‹ï¼Œé»˜è®¤50æ­¥æ¨ç†ï¼Œè´¨é‡æœ€é«˜ä½†é€Ÿåº¦è¾ƒæ…¢",
        "config_json": CONFIG_ORIGINAL,
        "model_path": MODEL_PATH_ORIGINAL,
        "infer_steps": 50,
        "lora_configs": None,
        "available": os.path.exists(MODEL_PATH_ORIGINAL),
    },
    "lora": {
        "name": "è’¸é¦åŠ é€Ÿæ¨¡å‹ (4æ­¥)",
        "description": "ä½¿ç”¨ LoRA è’¸é¦æ¨¡å‹åŠ é€Ÿï¼Œä»…éœ€4æ­¥æ¨ç†ï¼Œé€Ÿåº¦å¿«",
        "config_json": CONFIG_LORA,
        "model_path": MODEL_PATH_ORIGINAL,
        "infer_steps": 4,
        "lora_configs": [{"path": LORA_PATH, "strength": 1.0}],
        "available": os.path.exists(MODEL_PATH_ORIGINAL) and os.path.exists(LORA_PATH),
    },
}

# å…¨å±€ Runner ç¼“å­˜
runners_cache = {}


def get_device_info():
    """è·å–è®¾å¤‡ä¿¡æ¯"""
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        return f"GPU: {gpu_name} ({gpu_memory:.1f}GB)"
    return "CPU (æ—  GPU å¯ç”¨)"


def clear_gpu_memory():
    """æ¸…ç† GPU æ˜¾å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()


def create_config_for_model(model_type, aspect_ratio="16:9", seed=42):
    """ä¸ºæŒ‡å®šæ¨¡å‹ç±»å‹åˆ›å»ºé…ç½®"""
    model_info = MODEL_CONFIGS[model_type]
    
    # è¯»å–åŸºç¡€é…ç½®
    with open(model_info["config_json"], "r") as f:
        config_data = json.load(f)
    
    # åˆ›å»ºå‚æ•°å¯¹è±¡
    class Args:
        pass
    
    args = Args()
    args.model_cls = "qwen_image"
    args.task = "t2i"
    args.model_path = model_info["model_path"]
    args.config_json = model_info["config_json"]
    args.prompt = ""
    args.negative_prompt = " "
    args.save_result_path = ""
    args.seed = seed
    args.aspect_ratio = aspect_ratio
    args.custom_shape = None
    args.strength = 0.6
    args.image_path = ""
    args.last_frame_path = ""
    args.audio_path = ""
    args.src_ref_images = None
    args.src_video = None
    args.src_mask = None
    args.use_prompt_enhancer = False
    args.return_result_tensor = False
    
    config = set_config(args)
    
    # æ›´æ–° LoRA é…ç½®
    if model_info["lora_configs"]:
        config["lora_configs"] = model_info["lora_configs"]
    
    # ä½¿ç”¨ torch å®ç°çš„ ropeï¼Œé¿å… flashinfer åº“é—®é¢˜
    config["rope_type"] = "torch"
    
    # ä½¿ç”¨ PyTorch SDPA æ³¨æ„åŠ›ï¼Œé¿å… flash_attn3 åº“é—®é¢˜
    config["attn_type"] = "torch_sdpa"
    
    return config


def init_runner(config):
    """åˆå§‹åŒ– Runner"""
    torch.set_grad_enabled(False)
    runner = RUNNER_REGISTER[config["model_cls"]](config)
    runner.init_modules()
    return runner


def run_single_inference(model_type, prompt, negative_prompt, aspect_ratio, seed, progress_callback=None):
    """è¿è¡Œå•ä¸ªæ¨¡å‹æ¨ç†"""
    global runners_cache
    
    model_info = MODEL_CONFIGS[model_type]
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
    if not model_info.get("available", True):
        note = model_info.get("note", "æ¨¡å‹ä¸å¯ç”¨")
        return None, 0, 0, f"æ¨¡å‹ä¸å¯ç”¨: {note}"
    
    runner = None
    try:
        # åˆ›å»ºé…ç½®
        config = create_config_for_model(model_type, aspect_ratio, seed)
        
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_path = os.path.join(SAVE_DIR, f"qwen_image_{model_type}_{timestamp}.png")
        
        # åˆ›å»ºè¾“å…¥å‚æ•°
        class InputArgs:
            pass
        
        input_args = InputArgs()
        input_args.task = "t2i"
        input_args.prompt = prompt
        input_args.negative_prompt = negative_prompt
        input_args.save_result_path = save_path
        input_args.seed = seed
        input_args.aspect_ratio = aspect_ratio
        input_args.custom_shape = None
        input_args.return_result_tensor = False
        
        # è®¾ç½®éšæœºç§å­
        seed_all(seed)
        
        # åˆå§‹åŒ– Runnerï¼ˆæ¯æ¬¡éƒ½é‡æ–°åˆå§‹åŒ–ä»¥ç¡®ä¿é…ç½®æ­£ç¡®ï¼‰
        logger.info(f"åˆå§‹åŒ– {model_info['name']} Runner...")
        start_init = time.time()
        
        # æ¸…ç†ä¹‹å‰çš„ç¼“å­˜
        clear_gpu_memory()
        
        runner = init_runner(config)
        init_time = time.time() - start_init
        logger.info(f"Runner åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {init_time:.2f}ç§’")
        
        # è®¾ç½®è¾“å…¥ä¿¡æ¯
        input_info = set_input_info(input_args)
        
        # è¿è¡Œæ¨ç†
        logger.info(f"å¼€å§‹æ¨ç† {model_info['name']}...")
        start_infer = time.time()
        
        # æ‰‹åŠ¨æ‰§è¡Œæ¨ç†æ­¥éª¤ï¼Œé¿å… end_run ä¸­çš„é—®é¢˜
        runner.input_info = input_info
        runner.inputs = runner.run_input_encoder()
        runner.set_target_shape()
        runner.set_img_shapes()
        logger.info(f"input_info: {runner.input_info}")
        latents, generator = runner.run_dit()
        images = runner.run_vae_decoder(latents)
        
        # ä¿å­˜å›¾åƒ
        image = images[0]
        image.save(save_path)
        logger.info(f"Image saved: {save_path}")
        
        infer_time = time.time() - start_infer
        total_time = time.time() - start_init
        
        logger.info(f"{model_info['name']} æ¨ç†å®Œæˆï¼Œæ¨ç†è€—æ—¶: {infer_time:.2f}ç§’ï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        # æ¸…ç†
        del latents, generator, images
        if runner is not None:
            if hasattr(runner, 'model'):
                del runner.model
            if hasattr(runner, 'vae'):
                del runner.vae
            if hasattr(runner, 'text_encoders'):
                del runner.text_encoders
            del runner
        clear_gpu_memory()
        
        return save_path, infer_time, total_time, None
        
    except Exception as e:
        import traceback
        error_msg = f"{str(e)}\n{traceback.format_exc()}"
        logger.error(f"{model_info['name']} æ¨ç†å¤±è´¥: {error_msg}")
        if runner is not None:
            try:
                del runner
            except:
                pass
        clear_gpu_memory()
        return None, 0, 0, str(e)


def run_all_models(prompt, negative_prompt, aspect_ratio, seed, progress=gr.Progress()):
    """è¿è¡Œä¸¤ä¸ªæ¨¡å‹çš„æ¨ç†å¯¹æ¯”"""
    
    if not prompt or not prompt.strip():
        return None, "", None, "", "âŒ è¯·è¾“å…¥æç¤ºè¯ï¼"
    
    results = {}
    status_messages = []
    
    # æ¨¡å‹æ¨ç†é¡ºåº
    model_order = ["original", "lora"]
    
    for i, model_type in enumerate(model_order):
        model_info = MODEL_CONFIGS[model_type]
        progress((i / 2), f"æ­£åœ¨æ¨ç†: {model_info['name']}...")
        status_messages.append(f"ğŸ”„ æ­£åœ¨æ¨ç†: {model_info['name']}...")
        
        image_path, infer_time, total_time, error = run_single_inference(
            model_type, prompt, negative_prompt, aspect_ratio, seed
        )
        
        if error:
            results[model_type] = {
                "image": None,
                "info": f"âŒ æ¨ç†å¤±è´¥: {error}",
            }
            status_messages.append(f"âŒ {model_info['name']} å¤±è´¥: {error}")
        else:
            results[model_type] = {
                "image": image_path,
                "info": f"âœ… æ¨ç†è€—æ—¶: {infer_time:.2f}ç§’\nğŸ“¦ æ€»è€—æ—¶ï¼ˆå«åŠ è½½ï¼‰: {total_time:.2f}ç§’",
            }
            status_messages.append(f"âœ… {model_info['name']} å®Œæˆï¼Œè€—æ—¶: {infer_time:.2f}ç§’")
    
    progress(1.0, "æ¨ç†å®Œæˆï¼")
    
    # æ„å»ºæœ€ç»ˆçŠ¶æ€
    final_status = "ğŸ“Š æ¨ç†å¯¹æ¯”å®Œæˆï¼\n\n" + "\n".join(status_messages)
    
    return (
        results["original"]["image"],
        results["original"]["info"],
        results["lora"]["image"],
        results["lora"]["info"],
        final_status,
    )


def run_single_model(model_type, prompt, negative_prompt, aspect_ratio, seed, progress=gr.Progress()):
    """è¿è¡Œå•ä¸ªæ¨¡å‹çš„æ¨ç†"""
    
    if not prompt or not prompt.strip():
        return None, "âŒ è¯·è¾“å…¥æç¤ºè¯ï¼"
    
    model_info = MODEL_CONFIGS[model_type]
    progress(0.1, f"æ­£åœ¨æ¨ç†: {model_info['name']}...")
    
    image_path, infer_time, total_time, error = run_single_inference(
        model_type, prompt, negative_prompt, aspect_ratio, seed
    )
    
    progress(1.0, "æ¨ç†å®Œæˆï¼")
    
    if error:
        return None, f"âŒ æ¨ç†å¤±è´¥: {error}"
    
    return image_path, f"âœ… æ¨ç†è€—æ—¶: {infer_time:.2f}ç§’\nğŸ“¦ æ€»è€—æ—¶ï¼ˆå«åŠ è½½ï¼‰: {total_time:.2f}ç§’"


def update_prompt_from_example(example_category):
    """ä»ç¤ºä¾‹ä¸­æ›´æ–°æç¤ºè¯"""
    for category, prompt in EXAMPLE_PROMPTS:
        if category == example_category:
            return prompt
    return ""


def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    model_status = []
    if os.path.exists(MODEL_PATH_ORIGINAL):
        model_status.append("âœ… Qwen-Image-2512 åŸå§‹æ¨¡å‹å·²å°±ç»ª")
        MODEL_CONFIGS["original"]["available"] = True
    else:
        model_status.append("âŒ Qwen-Image-2512 åŸå§‹æ¨¡å‹æœªæ‰¾åˆ°")
        MODEL_CONFIGS["original"]["available"] = False
    
    if os.path.exists(LORA_PATH):
        model_status.append("âœ… Lightning LoRA æ¨¡å‹å·²å°±ç»ª")
        MODEL_CONFIGS["lora"]["available"] = os.path.exists(MODEL_PATH_ORIGINAL)
    else:
        model_status.append("âš ï¸ Lightning LoRA æ¨¡å‹æœªæ‰¾åˆ°ï¼ˆè’¸é¦åŠ é€Ÿæ¨¡å‹å°†ä¸å¯ç”¨ï¼‰")
        MODEL_CONFIGS["lora"]["available"] = False
    
    model_status_text = "\n".join(model_status)
    
    # åˆ›å»ºç¤ºä¾‹é€‰é¡¹
    example_choices = [category for category, _ in EXAMPLE_PROMPTS]
    
    with gr.Blocks(
        title="LightX2V Qwen-Image æ–‡ç”Ÿå›¾æ¼”ç¤º",
        theme=gr.themes.Soft(),
        css="""
        .header { text-align: center; margin-bottom: 20px; }
        .footer { text-align: center; margin-top: 20px; padding: 10px; background: #f0f0f0; border-radius: 8px; }
        .model-card { border: 1px solid #ddd; border-radius: 8px; padding: 10px; margin: 5px; }
        """
    ) as demo:
        
        # YouTube é¢‘é“ä¿¡æ¯ - æ”¾åœ¨é¡¶éƒ¨ï¼Œä½¿ç”¨ç´ è‰²è°ƒ
        gr.HTML(
            """
            <div style="text-align: center; padding: 10px 15px; background: #fafafa; border-radius: 6px; margin-bottom: 12px; border: 1px solid #eee;">
                <span style="color: #666; font-size: 14px;">ğŸ“º <b>AI æŠ€æœ¯åˆ†äº«é¢‘é“</b></span>
                <span style="color: #999; font-size: 12px; margin-left: 12px;">æ¬¢è¿è®¢é˜…æˆ‘çš„ YouTube é¢‘é“ï¼Œè·å–æ›´å¤š AI æŠ€æœ¯æ•™ç¨‹ï¼</span>
                <a href="https://www.youtube.com/@rongyikanshijie-ai" target="_blank" 
                   style="display: inline-block; margin-left: 12px; padding: 4px 12px; background: #777; color: white; 
                          text-decoration: none; border-radius: 3px; font-size: 12px;">
                    ğŸ”” ç‚¹å‡»è®¢é˜…
                </a>
            </div>
            """
        )
        
        # æ ‡é¢˜åŒºåŸŸ
        gr.Markdown(
            """
            # ğŸ¨ LightX2V Qwen-Image æ–‡ç”Ÿå›¾æ¼”ç¤º
            
            åŸºäº **Qwen-Image-2512** æ¨¡å‹çš„æ–‡æœ¬ç”Ÿæˆå›¾åƒæ¼”ç¤ºç¨‹åº
            
            ---
            """
        )
        
        # è®¾å¤‡å’Œæ¨¡å‹çŠ¶æ€ä¿¡æ¯
        with gr.Row():
            gr.Markdown(f"**ğŸ–¥ï¸ è®¾å¤‡ä¿¡æ¯**: {get_device_info()}")
        
        with gr.Accordion("ğŸ“¦ æ¨¡å‹çŠ¶æ€", open=False):
            gr.Markdown(model_status_text)
        
        # ä¸»ç•Œé¢
        with gr.Row():
            # å·¦ä¾§ï¼šè¾“å…¥åŒºåŸŸ
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“ è¾“å…¥å‚æ•°")
                
                # ç¤ºä¾‹é€‰æ‹©
                example_dropdown = gr.Dropdown(
                    label="ğŸ¯ ç¤ºä¾‹æç¤ºè¯ï¼ˆé€‰æ‹©åè‡ªåŠ¨å¡«å……ï¼‰",
                    choices=example_choices,
                    value=None,
                    interactive=True,
                )
                
                # æç¤ºè¯è¾“å…¥
                prompt_input = gr.Textbox(
                    label="âœï¸ æç¤ºè¯ (Prompt)",
                    placeholder="è¯·è¾“å…¥å›¾åƒæè¿°...",
                    lines=8,
                    max_lines=15,
                )
                
                negative_prompt_input = gr.Textbox(
                    label="ğŸš« è´Ÿé¢æç¤ºè¯ (Negative Prompt)",
                    value=" ",
                    placeholder="è¾“å…¥ä¸å¸Œæœ›å‡ºç°çš„å†…å®¹...",
                    lines=2,
                )
                
                # å‚æ•°è®¾ç½®
                with gr.Row():
                    aspect_ratio = gr.Dropdown(
                        label="ğŸ“ å®½é«˜æ¯”",
                        choices=["16:9", "9:16", "1:1", "4:3", "3:4"],
                        value="16:9",
                    )
                    seed_input = gr.Number(
                        label="ğŸ² éšæœºç§å­",
                        value=42,
                        precision=0,
                    )
                
                # è¿è¡ŒæŒ‰é’®
                run_all_btn = gr.Button("ğŸš€ è¿è¡Œå…¨éƒ¨æ¨¡å‹å¯¹æ¯”", variant="primary", size="lg")
                
                with gr.Row():
                    run_original_btn = gr.Button("â–¶ï¸ ä»…è¿è¡ŒåŸå§‹æ¨¡å‹", size="sm")
                    run_lora_btn = gr.Button("â–¶ï¸ ä»…è¿è¡Œè’¸é¦æ¨¡å‹", size="sm")
                
                # çŠ¶æ€æ˜¾ç¤º
                status_output = gr.Textbox(
                    label="ğŸ“Š è¿è¡ŒçŠ¶æ€",
                    lines=6,
                    interactive=False,
                )
        
        # å³ä¾§ï¼šè¾“å‡ºåŒºåŸŸ
        gr.Markdown("### ğŸ–¼ï¸ ç”Ÿæˆç»“æœå¯¹æ¯”")
        
        with gr.Row():
            # åŸå§‹æ¨¡å‹è¾“å‡º
            with gr.Column(scale=1):
                gr.Markdown("#### åŸå§‹æ¨¡å‹ (50æ­¥)")
                gr.Markdown("*è´¨é‡æœ€é«˜ï¼Œé€Ÿåº¦è¾ƒæ…¢*")
                output_original = gr.Image(
                    label="åŸå§‹æ¨¡å‹è¾“å‡º",
                    type="filepath",
                    height=400,
                )
                info_original = gr.Textbox(
                    label="â±ï¸ è€—æ—¶ä¿¡æ¯",
                    lines=2,
                    interactive=False,
                )
            
            # è’¸é¦æ¨¡å‹è¾“å‡º
            with gr.Column(scale=1):
                gr.Markdown("#### è’¸é¦åŠ é€Ÿæ¨¡å‹ (4æ­¥)")
                gr.Markdown("*LoRAè’¸é¦ï¼Œé€Ÿåº¦å¿«*")
                output_lora = gr.Image(
                    label="è’¸é¦æ¨¡å‹è¾“å‡º",
                    type="filepath",
                    height=400,
                )
                info_lora = gr.Textbox(
                    label="â±ï¸ è€—æ—¶ä¿¡æ¯",
                    lines=2,
                    interactive=False,
                )
        
        # åº•éƒ¨ä¿¡æ¯
        gr.Markdown(
            """
            ---
            
            ### ğŸ“š ä½¿ç”¨è¯´æ˜
            
            1. **é€‰æ‹©ç¤ºä¾‹**ï¼šä»ä¸‹æ‹‰èœå•é€‰æ‹©é¢„è®¾æç¤ºè¯ï¼Œæˆ–ç›´æ¥è¾“å…¥è‡ªå®šä¹‰æç¤ºè¯
            2. **è°ƒæ•´å‚æ•°**ï¼šè®¾ç½®å®½é«˜æ¯”å’Œéšæœºç§å­
            3. **è¿è¡Œæ¨ç†**ï¼š
               - ç‚¹å‡»"è¿è¡Œå…¨éƒ¨æ¨¡å‹å¯¹æ¯”"åŒæ—¶è¿è¡Œä¸¤ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”
               - æˆ–ç‚¹å‡»å•ç‹¬æŒ‰é’®ä»…è¿è¡Œç‰¹å®šæ¨¡å‹
            4. **æŸ¥çœ‹ç»“æœ**ï¼šæ¯”è¾ƒä¸åŒæ¨¡å‹çš„ç”Ÿæˆè´¨é‡å’Œæ¨ç†é€Ÿåº¦
            
            ### âš¡ æ¨¡å‹è¯´æ˜
            
            | æ¨¡å‹ | æ¨ç†æ­¥æ•° | ç‰¹ç‚¹ |
            |------|----------|------|
            | åŸå§‹æ¨¡å‹ | 50æ­¥ | è´¨é‡æœ€é«˜ï¼Œä½†é€Ÿåº¦è¾ƒæ…¢ |
            | è’¸é¦æ¨¡å‹ | 4æ­¥ | ä½¿ç”¨LoRAåŠ é€Ÿï¼Œé€Ÿåº¦å¿«ï¼Œè´¨é‡ç•¥é™ |
            
            ### ğŸ“¦ æ¨¡å‹ä¸‹è½½åœ°å€
            
            - **åŸå§‹æ¨¡å‹**: [Qwen/Qwen-Image-2512](https://huggingface.co/Qwen/Qwen-Image-2512)
            - **Lightning åŠ é€Ÿæ¨¡å‹**: [lightx2v/Qwen-Image-2512-Lightning](https://huggingface.co/lightx2v/Qwen-Image-2512-Lightning)
            
            ---
            """
        )
        
        # åº•éƒ¨ YouTube é¢‘é“ä¿¡æ¯ - ç´ è‰²è°ƒ
        gr.HTML(
            """
            <div style="text-align: center; padding: 10px; background: #fafafa; border-radius: 6px; margin: 10px 0; border: 1px solid #eee;">
                <span style="color: #666; font-size: 13px;">ğŸ“º <b>AI æŠ€æœ¯åˆ†äº«é¢‘é“</b></span>
                <span style="color: #999; font-size: 11px; margin-left: 8px;">æ¬¢è¿è®¢é˜…è·å–æ›´å¤š AI æŠ€æœ¯æ•™ç¨‹ï¼</span>
                <a href="https://www.youtube.com/@rongyikanshijie-ai" target="_blank" 
                   style="display: inline-block; margin-left: 8px; padding: 3px 10px; background: #777; color: white; 
                          text-decoration: none; border-radius: 3px; font-size: 11px;">
                    ğŸ”” ç‚¹å‡»è®¢é˜…
                </a>
            </div>
            """
        )
        
        gr.Markdown(
            """
            <div style="text-align: center; color: #aaa; font-size: 11px; margin-top: 15px;">
                Powered by LightX2V | Qwen-Image-2512 | 
                <a href="https://www.youtube.com/@rongyikanshijie-ai" target="_blank" style="color: #aaa;">AI æŠ€æœ¯åˆ†äº«é¢‘é“</a>
            </div>
            """
        )
        
        # äº‹ä»¶ç»‘å®š
        example_dropdown.change(
            fn=update_prompt_from_example,
            inputs=[example_dropdown],
            outputs=[prompt_input],
        )
        
        run_all_btn.click(
            fn=run_all_models,
            inputs=[prompt_input, negative_prompt_input, aspect_ratio, seed_input],
            outputs=[
                output_original, info_original,
                output_lora, info_lora,
                status_output,
            ],
        )
        
        run_original_btn.click(
            fn=lambda p, n, a, s: run_single_model("original", p, n, a, s),
            inputs=[prompt_input, negative_prompt_input, aspect_ratio, seed_input],
            outputs=[output_original, info_original],
        )
        
        run_lora_btn.click(
            fn=lambda p, n, a, s: run_single_model("lora", p, n, a, s),
            inputs=[prompt_input, negative_prompt_input, aspect_ratio, seed_input],
            outputs=[output_lora, info_lora],
        )
    
    return demo


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="LightX2V Qwen-Image æ–‡ç”Ÿå›¾æ¼”ç¤º")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="æœåŠ¡å™¨åœ°å€")
    parser.add_argument("--port", type=int, default=7860, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--share", action="store_true", help="åˆ›å»ºå…¬å…±é“¾æ¥")
    args = parser.parse_args()
    
    logger.info("æ­£åœ¨å¯åŠ¨ LightX2V Qwen-Image æ–‡ç”Ÿå›¾æ¼”ç¤º...")
    logger.info(f"è®¾å¤‡ä¿¡æ¯: {get_device_info()}")
    logger.info(f"é¡¹ç›®è·¯å¾„: {PROJECT_ROOT}")
    logger.info(f"æ¨¡å‹è·¯å¾„: {CHECKPOINT_DIR}")
    
    demo = create_ui()
    demo.launch(
        server_name=args.host,
        server_port=args.port,
        share=args.share,
    )
