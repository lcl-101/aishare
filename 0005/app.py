# coding=utf-8
# Copyright 2026 The Alibaba Qwen team.
# SPDX-License-Identifier: Apache-2.0

"""
Gradio Web åº”ç”¨ç¨‹åº - Qwen3 ASR éŸ³é¢‘è½¬å†™æœåŠ¡
"""

import base64
import io
import os
import urllib.request
from typing import Optional, Tuple

import gradio as gr
import numpy as np
import soundfile as sf
import torch

from qwen_asr import Qwen3ASRModel


# æ¨¡å‹è·¯å¾„é…ç½®
ASR_MODEL_PATH = "checkpoints/Qwen3-ASR-1.7B"
FORCED_ALIGNER_PATH = "checkpoints/Qwen3-ForcedAligner-0.6B"

# ç¤ºä¾‹éŸ³é¢‘ URL
EXAMPLE_URLS = {
    "ä¸­æ–‡ç¤ºä¾‹": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-ASR-Repo/asr_zh.wav",
    "è‹±æ–‡ç¤ºä¾‹": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-ASR-Repo/asr_en.wav",
}

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹å®ä¾‹
asr_model = None
example_audios = {}


def download_example_audio(url: str, timeout: int = 30) -> Optional[bytes]:
    """ä¸‹è½½ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶"""
    try:
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            return resp.read()
    except Exception as e:
        print(f"ä¸‹è½½éŸ³é¢‘å¤±è´¥: {url}, é”™è¯¯: {e}")
        return None


def init_examples():
    """åˆå§‹åŒ–å¹¶ä¸‹è½½ç¤ºä¾‹éŸ³é¢‘"""
    global example_audios
    print("æ­£åœ¨ä¸‹è½½ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶...")
    for name, url in EXAMPLE_URLS.items():
        audio_bytes = download_example_audio(url)
        if audio_bytes:
            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_path = f"/tmp/{name}.wav"
            with open(temp_path, "wb") as f:
                f.write(audio_bytes)
            example_audios[name] = temp_path
            print(f"âœ“ {name} ä¸‹è½½å®Œæˆ")
        else:
            print(f"âœ— {name} ä¸‹è½½å¤±è´¥")


def init_model():
    """åˆå§‹åŒ– ASR æ¨¡å‹"""
    global asr_model
    print("æ­£åœ¨åŠ è½½ Qwen3 ASR æ¨¡å‹...")
    asr_model = Qwen3ASRModel.from_pretrained(
        ASR_MODEL_PATH,
        dtype=torch.bfloat16,
        device_map="cuda:0",
        forced_aligner=FORCED_ALIGNER_PATH,
        forced_aligner_kwargs=dict(
            dtype=torch.bfloat16,
            device_map="cuda:0",
        ),
        max_inference_batch_size=32,
        max_new_tokens=2048,
    )
    print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")


def format_timestamps(time_stamps):
    """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¿¡æ¯"""
    if not time_stamps or len(time_stamps) == 0:
        return ""
    
    result = []
    result.append("\n## æ—¶é—´æˆ³è¯¦æƒ…ï¼š\n")
    for i, ts in enumerate(time_stamps):
        result.append(f"{i+1}. [{ts.start_time:.2f}s - {ts.end_time:.2f}s] {ts.text}")
    return "\n".join(result)


def transcribe_audio(
    audio_input,
    language: str,
    context: str,
    return_timestamps: bool
) -> Tuple[str, str]:
    """
    è½¬å†™éŸ³é¢‘æ–‡ä»¶
    
    Args:
        audio_input: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæ¥è‡ª Gradio éŸ³é¢‘ç»„ä»¶ï¼‰
        language: è¯­è¨€é€‰æ‹©
        context: ä¸Šä¸‹æ–‡æç¤ºè¯
        return_timestamps: æ˜¯å¦è¿”å›æ—¶é—´æˆ³
    
    Returns:
        (è½¬å†™æ–‡æœ¬, æ—¶é—´æˆ³ä¿¡æ¯)
    """
    if asr_model is None:
        return "é”™è¯¯ï¼šæ¨¡å‹æœªåŠ è½½", ""
    
    if audio_input is None:
        return "è¯·ä¸Šä¼ æˆ–é€‰æ‹©éŸ³é¢‘æ–‡ä»¶", ""
    
    try:
        # å¤„ç† Gradio éŸ³é¢‘è¾“å…¥
        if isinstance(audio_input, str):
            # æ–‡ä»¶è·¯å¾„
            audio_path = audio_input
        elif isinstance(audio_input, tuple):
            # (é‡‡æ ·ç‡, éŸ³é¢‘æ•°æ®) å…ƒç»„
            sr, audio_data = audio_input
            audio_path = (audio_data.astype(np.float32) / 32768.0, sr)
        else:
            return "ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼", ""
        
        # è®¾ç½®è¯­è¨€å‚æ•°
        lang_param = None if language == "è‡ªåŠ¨æ£€æµ‹" else language
        
        # æ‰§è¡Œè½¬å†™
        results = asr_model.transcribe(
            audio=audio_path,
            language=lang_param,
            context=context if context.strip() else "",
            return_time_stamps=return_timestamps,
        )
        
        if not results or len(results) == 0:
            return "è½¬å†™å¤±è´¥ï¼šæœªè¿”å›ç»“æœ", ""
        
        result = results[0]
        
        # æ„å»ºè¾“å‡ºæ–‡æœ¬
        output_text = f"**æ£€æµ‹è¯­è¨€ï¼š** {result.language}\n\n**è½¬å†™æ–‡æœ¬ï¼š**\n{result.text}"
        
        # æ„å»ºæ—¶é—´æˆ³ä¿¡æ¯
        timestamp_text = ""
        if return_timestamps and result.time_stamps:
            timestamp_text = format_timestamps(result.time_stamps)
        
        return output_text, timestamp_text
        
    except Exception as e:
        import traceback
        error_msg = f"è½¬å†™å‡ºé”™ï¼š{str(e)}\n\n{traceback.format_exc()}"
        return error_msg, ""


def load_example_audio(example_name: str):
    """åŠ è½½ç¤ºä¾‹éŸ³é¢‘"""
    if example_name in example_audios:
        return example_audios[example_name]
    return None


def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    with gr.Blocks(title="Qwen3 ASR éŸ³é¢‘è½¬å†™æœåŠ¡", theme=gr.themes.Soft()) as demo:
        # YouTube é¢‘é“ä¿¡æ¯
        gr.Markdown(
            """
            # ğŸ™ï¸ Qwen3 ASR éŸ³é¢‘è½¬å†™æœåŠ¡
            
            ### ğŸ“º [AI æŠ€æœ¯åˆ†äº«é¢‘é“](https://www.youtube.com/@rongyi-ai) - æ¬¢è¿è®¢é˜…ï¼
            
            ---
            """
        )
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“¤ éŸ³é¢‘è¾“å…¥")
                
                # ç¤ºä¾‹éŸ³é¢‘é€‰æ‹©
                example_dropdown = gr.Dropdown(
                    choices=list(example_audios.keys()),
                    label="é€‰æ‹©ç¤ºä¾‹éŸ³é¢‘",
                    value=None,
                )
                
                load_example_btn = gr.Button("åŠ è½½ç¤ºä¾‹", variant="secondary")
                
                gr.Markdown("**æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼š**")
                
                # éŸ³é¢‘è¾“å…¥
                audio_input = gr.Audio(
                    label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶",
                    type="filepath",
                )
                
                gr.Markdown("## âš™ï¸ è½¬å†™è®¾ç½®")
                
                # è¯­è¨€é€‰æ‹©
                language_select = gr.Radio(
                    choices=["è‡ªåŠ¨æ£€æµ‹", "Chinese", "English"],
                    value="è‡ªåŠ¨æ£€æµ‹",
                    label="è¯­è¨€è®¾ç½®",
                )
                
                # ä¸Šä¸‹æ–‡æç¤ºè¯
                context_input = gr.Textbox(
                    label="ä¸Šä¸‹æ–‡æç¤ºè¯ï¼ˆå¯é€‰ï¼‰",
                    placeholder="äº¤æ˜“ åœæ»",
                    lines=2,
                )
                
                # æ—¶é—´æˆ³é€‰é¡¹
                timestamp_checkbox = gr.Checkbox(
                    label="ç”Ÿæˆæ—¶é—´æˆ³ä¿¡æ¯",
                    value=False,
                )
                
                # è½¬å†™æŒ‰é’®
                transcribe_btn = gr.Button("ğŸ¯ å¼€å§‹è½¬å†™", variant="primary", size="lg")
                
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“ è½¬å†™ç»“æœ")
                
                # è½¬å†™æ–‡æœ¬è¾“å‡º
                output_text = gr.Markdown(
                    label="è½¬å†™æ–‡æœ¬",
                    value="ç­‰å¾…è½¬å†™...",
                )
                
                # æ—¶é—´æˆ³è¾“å‡º
                timestamp_output = gr.Markdown(
                    label="æ—¶é—´æˆ³ä¿¡æ¯",
                    value="",
                )
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown(
                """
                ### åŠŸèƒ½è¯´æ˜
                
                1. **é€‰æ‹©éŸ³é¢‘**ï¼šå¯ä»¥ä»ç¤ºä¾‹éŸ³é¢‘ä¸­é€‰æ‹©ï¼Œæˆ–ä¸Šä¼ è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶
                2. **è¯­è¨€è®¾ç½®**ï¼š
                   - è‡ªåŠ¨æ£€æµ‹ï¼šè®©æ¨¡å‹è‡ªåŠ¨è¯†åˆ«è¯­è¨€
                   - Chineseï¼šå¼ºåˆ¶ä½¿ç”¨ä¸­æ–‡è¯†åˆ«
                   - Englishï¼šå¼ºåˆ¶ä½¿ç”¨è‹±æ–‡è¯†åˆ«
                3. **ä¸Šä¸‹æ–‡æç¤ºè¯**ï¼šæä¾›ç›¸å…³è¯æ±‡å¯ä»¥æé«˜è¯†åˆ«å‡†ç¡®ç‡ï¼ˆå¦‚ï¼šäº¤æ˜“ åœæ»ï¼‰
                4. **æ—¶é—´æˆ³ä¿¡æ¯**ï¼šå‹¾é€‰åä¼šç”Ÿæˆæ¯ä¸ªè¯çš„å¼€å§‹å’Œç»“æŸæ—¶é—´
                
                ### æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
                
                - WAV, MP3, FLAC, OGG ç­‰å¸¸è§æ ¼å¼
                - å»ºè®®ä½¿ç”¨ 16kHz é‡‡æ ·ç‡çš„éŸ³é¢‘ä»¥è·å¾—æœ€ä½³æ•ˆæœ
                """
            )
        
        # äº‹ä»¶ç»‘å®š
        load_example_btn.click(
            fn=load_example_audio,
            inputs=[example_dropdown],
            outputs=[audio_input],
        )
        
        transcribe_btn.click(
            fn=transcribe_audio,
            inputs=[audio_input, language_select, context_input, timestamp_checkbox],
            outputs=[output_text, timestamp_output],
        )
    
    return demo


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Qwen3 ASR Web æœåŠ¡å¯åŠ¨ä¸­...")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç¤ºä¾‹éŸ³é¢‘
    init_examples()
    
    # åˆå§‹åŒ–æ¨¡å‹
    init_model()
    
    # åˆ›å»ºå¹¶å¯åŠ¨ UI
    demo = create_ui()
    
    print("\n" + "=" * 60)
    print("âœ“ æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
    print("=" * 60)
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
    )


if __name__ == "__main__":
    main()
