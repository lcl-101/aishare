import os
import torch
from PIL import Image
from diffusers import QwenImageEditPlusPipeline
import gradio as gr

# æ¨¡å‹è·¯å¾„
MODEL_PATH = "./checkpoints/Qwen-Image-Edit-2511"

# å…¨å±€å˜é‡å­˜å‚¨ pipeline
pipeline = None

# ç¤ºä¾‹æç¤ºè¯
EXAMPLE_PROMPTS = {
    "character_consistency": [
        {
            "name": "ğŸ„ åœ£è¯èŠ‚ç¾å°‘å¥³",
            "prompt": "ç”Ÿæˆåœ£è¯èŠ‚ä¸»é¢˜ï¼Œä¸€ä½çº¯æ¬²æ°”è´¨çš„ç¾å°‘å¥³ï¼Œå›¾ä¸­äººè„¸ä¸å˜ã€‚æ¾æ•£çš„åŒéº»èŠ±è¾«æ¾æ•£ä½æ‰ï¼ˆéº»èŠ±è¾«ä¸Šæœ‰å¸ƒè‰ºå½©çƒè£…é¥°ï¼‰ï¼Œå°‘å¥³æ°”è´¨ï¼Œæ— è¾œçœ¼ç¥ï¼Œå¤´æˆ´åœ£è¯æ ‘é€ å‹å‘é¥°ï¼Œå°å‹é”¥å½¢åœ£è¯æ ‘æ•´é½åœ°å›ºå®šåœ¨å¤´é¡¶ï¼Œé¡¶éƒ¨æ˜¯é‡‘è‰²äº”è§’æ˜Ÿï¼Œæ ‘èº«è£…é¥°ç€å½©è‰²ç¯ä¸²ã€é‡‘è‰²é“ƒé“›ã€è´è¶ç»“ã€çº¢è“é‡‘å°çƒï¼Œå¸ƒç½®ç²¾è‡´é¥±æ»¡ï¼›å†·ç™½çš®ï¼Œç™½å«©å«©çš„çš®è‚¤å¦‚ç¼ç‰èˆ¬å«©æ»‘ï¼Œçº¯æ¬²æœ¦èƒ§æ»¤é•œï¼Œçº¢æ£•ç³»çœ¼å½±è‡ªç„¶æ™•æŸ“ï¼ŒåŒæ‰‹æ‹¿ç€åœ£è¯è€äººç©å¶ï¼Œåœ£è¯æ°›å›´æ‹‰æ»¡ï¼Œåº†ç¥æ„Ÿçœ¼ç¥å’Œè¡¨æƒ…ï¼Œè½»è½»æ­ªå¤´ï¼Œä¿çš®åˆå¥½çœ‹çš„åŠ¨ä½œï¼Œå¯çˆ±ä¸æ€§æ„Ÿå¹¶å­˜ï¼Œåå·®ï¼›è“¬æ¾å¾®ä¹±å‘ä¸ä¸å¤´é¡¶åœ£è¯æ ‘è‡ªç„¶èåˆï¼›ç©¿æ¯›ç»’çº¢è‰²ä¸Šè¡£ï¼Œè´¨æ„ŸæŸ”è½¯è“¬æ¾ï¼›æš–ç™½èƒŒæ™¯ã€æ£šæ‹æŸ”å…‰ã€ä½å¯¹æ¯”åº¦ã€ä½é¥±å’Œåº¦ã€ç»†è…»èƒ¶ç‰‡é¢—ç²’ã€è½»å¾®è‰²æ•£å…‰æ™•ã€èƒ¶ç‰‡æŸ”å…‰æ„Ÿã€æ¸©æš–æ²»æ„ˆæ°›å›´ã€ç‹¬ç‰¹è§†è§’ï¼Œéå¸¸è§„æ„å›¾ï¼Œ70mmèƒ¶ç‰‡äººåƒé£æ ¼ç»¿è‰²æ¶‚é¸¦æè¾¹äººç‰©è½®å»“ï¼Œæè¾¹å‘¨å›´ç©ºç™½å¤„è¿˜æœ‰å„ç§åœ£è¯èŠ‚å…ƒç´ çš„å¯çˆ±æ¶‚é¸¦ï¼Œå……æ»¡ç«¥è¶£å’Œåœ£è¯æ°›å›´çš„æ‰‹ç»˜æ‹¼è´´æ„Ÿã€‚äººç‰©è½®å»“è§å…‰çº¢ç»¿é‡‘è‰²è™šçº¿æ³¢ç‚¹åŒ…è£¹ï¼Œå†™æ»¡äº†\"MERRY CHRISMAS\"å¯çˆ±å­—ä½“ï¼Œä¸­æ™¯"
        },
        {
            "name": "ğŸ“¸ å››å®«æ ¼è¡¨æƒ…åŒ…",
            "prompt": "ç”Ÿæˆä¸€å¼ å››å®«æ ¼å›¾ç‰‡ã€‚ä»¥ä¸‹è¦æ±‚ï¼šäººç‰©ï¼šå‚è€ƒå›¾äººç‰©åˆ†å››ä¸ªç”»é¢å‘ˆç°ä¸åŒåŠ¨ä½œè¡¨æƒ…ã€‚å·¦ä¸Šï¼šåŒæ‰‹ä¸¾è¿‡å¤´é¡¶æ¯”åŒ\"V\"ï¼Œçœ¼ç›å¤§çã€å˜´å·´å¼ å¼€ï¼Œéœ²å‡ºæƒŠè®¶æ´»æ³¼çš„ç¥æ€ã€‚å³ä¸Šï¼šåŒæ‰‹æ‰˜ä½è„¸é¢Šï¼ŒåŒçœ¼å¾®é—­ã€å˜´å·´å˜Ÿèµ·ï¼Œè„¸é¢Šå¸¦çº¢æ™•ï¼Œå‘ˆç°å¯çˆ±å¨‡æ†¨æ„Ÿã€‚å·¦ä¸‹ï¼šå¤´å¾®ä¾§ï¼Œä¸€åªçœ¼ç›winkï¼ŒèˆŒå¤´åå‡ºï¼Œå•æ‰‹æ¯”\"V\"ï¼Œä¿çš®ææ€ªã€‚å³ä¸‹ï¼šåŒè‡‚äº¤å‰åœ¨èƒ¸å‰ï¼Œçœ‰å¤´å¾®çš±ã€å˜´å·´å˜Ÿèµ·ï¼Œå‘ˆç°å°å‚²å¨‡ç¥æ€ã€‚æœé¥°ï¼šæ ¹æ®å‚è€ƒå›¾ä¸å˜ã€‚èƒŒæ™¯ä¸é£æ ¼ï¼šå……æ»¡ç–¯ç‹‚åŠ¨ç‰©åŸç­‰å¯çˆ±å¡é€šå…ƒç´ çš„å½©è‰²èƒŒæ™¯ï¼Œæ•´ä½“ä¸ºäºŒæ¬¡å…ƒåŠ¨æ¼«é£æ ¼ï¼Œç”»é¢è‰²å½©é²œè‰³ã€é£æ ¼ç”œç¾æ²»æ„ˆï¼Œæ¯å¹…å°å›¾éƒ½æœ‰ç²¾è‡´çš„å¡é€šè¾¹æ¡†è£…é¥°ï¼Œå……æ»¡ç«¥è¶£æ„Ÿã€‚"
        },
        {
            "name": "ğŸ¨ çœŸäººä¸å¡é€šå£ç”»åˆå½±",
            "prompt": "ç”Ÿæˆç«–ç‰ˆ3:4ç”»é¢æ¯”ä¾‹çš„\"çœŸäººä¸å…¶å¯¹åº”å¡é€šå£ç”»åˆå½±\"åœºæ™¯å›¾åƒï¼šå°†ä¸Šä¼ çš„çœŸå®äººç‰©ç…§ç‰‡ä»¥åŸæ ·ä¿ç•™æœè£…ã€å‘å‹ã€å¦†å®¹ç½®äºç”»é¢å·¦ä¾§/å‰æ–¹ã€‚åœ¨çœŸäººèƒŒåå¢™é¢ç»˜åˆ¶1:1å¯¹åº”å¡é€šå£ç”»ï¼Œåšæ¶‚è´¨æ„Ÿä¸”é‡‡ç”¨åŠ¨æ¼«é£æ ¼å¤§çœ¼ã€æŸ”å’Œè½®å»“äº”å®˜ï¼Œå®Œæ•´å¤åˆ»å‘å‹ã€æœè£…åŠé…é¥°ç»†èŠ‚å¦‚è€³ç¯ã€é¡¹é“¾ç­‰ï¼Œè‰²å½©é¥±å’Œåº¦é«˜å¹¶å¸¦æœ‰æ¶‚é¸¦å¼ç¬”è§¦æ•ˆæœã€‚å¢™é¢æ·»åŠ å½©è‰²æ¶‚é¸¦çˆ±å¿ƒã€ç¬‘è„¸ã€å‡ ä½•å›¾æ¡ˆå…ƒç´ ï¼Œåœ°é¢ç‚¹ç¼€é£æº…é¢œæ–™è£…é¥°ç»†èŠ‚ï¼Œå£ç”»åŒºåŸŸèå…¥å¦‚\"2026å‘è´¢\"çš„ä¸­æ–‡å­—å…ƒç´ ï¼Œå­—ä½“é£æ ¼å¥‘åˆæ¶‚é¸¦ç¾å­¦ã€‚ç¡®ä¿çœŸäººä¸å£ç”»æ¯”ä¾‹ã€è§’åº¦è‡ªç„¶è¡”æ¥ï¼Œå…‰ç…§æ–¹å‘ç»Ÿä¸€ç¬¦åˆåœºæ™¯é€»è¾‘ï¼Œä¿æŒæ•´ä½“è‰²å½©é£æ ¼ä¸€è‡´ï¼Œå‘ˆç°ç”ŸåŠ¨ã€è¿è´¯ä¸”è§†è§‰å’Œè°æ•ˆæœ"
        },
        {
            "name": "ğŸ® åƒç´ æ‹¼è±†æˆå“",
            "prompt": "ç”Ÿæˆä¸€ä¸ªæ‰‹æ‹¿ç€å‹åˆ¶å¥½çš„è¾¹ç¼˜ä¸è§„åˆ™çš„å¹³é¢åƒç´ æ‹¼è±†æˆå“ç…§ç‰‡ï¼Œæ‹¼è±†çš„å†…å®¹æ˜¯å‚è€ƒå›¾ä¸­çš„åƒç´ Qç‰ˆå½¢è±¡ï¼Œæ‹¼è±†æ‰å¹³æ²¡æœ‰å‡¸èµ·ï¼Œä¿æŒå‚è€ƒå›¾ä¸»ä½“ç‰¹å¾ä¸å˜ï¼ŒèƒŒæ™¯æ˜¯å·¥ä½œå°å°é¢"
        }
    ],
    "multi_person": [
        {
            "name": "ğŸ¤« åŒäººå˜˜æ‰‹åŠ¿",
            "prompt": "ä¸¤ä¸ªäººï¼Œä¸€èµ·åšä¸€ä¸ª'å˜˜'çš„æ‰‹åŠ¿ã€‚"
        },
    ],
    "lora": [
        {
            "name": "ğŸ’¡ æŸ”å…‰é‡ç…§æ˜",
            "prompt": "æŸ”å…‰,ä½¿ç”¨æŸ”å’Œå…‰çº¿å¯¹å›¾ç‰‡è¿›è¡Œé‡æ–°ç…§æ˜"
        },
        {
            "name": "ğŸ”„ é•œå¤´å·¦æ—‹30åº¦",
            "prompt": "å°†é•œå¤´å‘å·¦æ—‹è½¬30åº¦"
        }
    ],
    "industrial_design": [
        {
            "name": "ğŸª– å¤´ç›”å˜é“¶ç°è‰²",
            "prompt": "æŠŠå¤´ç›”å˜æˆé“¶ç°è‰²"
        }
    ]
}

def load_model():
    """åŠ è½½æ¨¡å‹"""
    global pipeline
    if pipeline is None:
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        pipeline = QwenImageEditPlusPipeline.from_pretrained(
            MODEL_PATH, 
            torch_dtype=torch.bfloat16
        )
        pipeline.to('cuda')
        pipeline.set_progress_bar_config(disable=None)
        print("æ¨¡å‹åŠ è½½å®Œæˆ!")
    return pipeline

def generate_image(
    image1, 
    image2, 
    prompt, 
    negative_prompt,
    seed,
    true_cfg_scale,
    guidance_scale,
    num_inference_steps,
    num_images_per_prompt
):
    """ç”Ÿæˆå›¾ç‰‡"""
    global pipeline
    
    if pipeline is None:
        load_model()
    
    # å¤„ç†è¾“å…¥å›¾ç‰‡
    images = []
    if image1 is not None:
        images.append(Image.fromarray(image1).convert("RGB"))
    if image2 is not None:
        images.append(Image.fromarray(image2).convert("RGB"))
    
    if len(images) == 0:
        raise gr.Error("è¯·è‡³å°‘ä¸Šä¼ ä¸€å¼ å›¾ç‰‡!")
    
    if not prompt or prompt.strip() == "":
        raise gr.Error("è¯·è¾“å…¥æç¤ºè¯!")
    
    # è®¾ç½®éšæœºç§å­
    generator = torch.manual_seed(seed)
    
    # æ„å»ºè¾“å…¥å‚æ•°
    inputs = {
        "image": images if len(images) > 1 else images[0],
        "prompt": prompt,
        "generator": generator,
        "true_cfg_scale": true_cfg_scale,
        "negative_prompt": negative_prompt if negative_prompt else " ",
        "num_inference_steps": num_inference_steps,
        "guidance_scale": guidance_scale,
        "num_images_per_prompt": num_images_per_prompt,
    }
    
    # ç”Ÿæˆå›¾ç‰‡
    with torch.inference_mode():
        output = pipeline(**inputs)
        output_images = output.images
    
    return output_images

def create_tab_content(tab_name, example_prompts=None):
    """åˆ›å»ºé€šç”¨çš„Tabå†…å®¹"""
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“· è¾“å…¥å›¾ç‰‡")
            image1_input = gr.Image(label="å›¾ç‰‡ 1 (å¿…éœ€)", type="numpy")
            image2_input = gr.Image(label="å›¾ç‰‡ 2 (å¯é€‰)", type="numpy")
            
            gr.Markdown("### âœï¸ æç¤ºè¯")
            prompt_input = gr.Textbox(
                label="æç¤ºè¯ (Prompt)",
                placeholder="æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡æ•ˆæœ...",
                lines=5
            )
            
            # å¦‚æœæœ‰ç¤ºä¾‹æç¤ºè¯ï¼Œæ·»åŠ ä¸‹æ‹‰é€‰æ‹©
            if example_prompts:
                prompt_choices = ["-- é€‰æ‹©ç¤ºä¾‹æç¤ºè¯ --"] + [p["name"] for p in example_prompts]
                prompt_dropdown = gr.Dropdown(
                    choices=prompt_choices,
                    label="ğŸ“ ç¤ºä¾‹æç¤ºè¯æ¨¡æ¿",
                    value="-- é€‰æ‹©ç¤ºä¾‹æç¤ºè¯ --"
                )
                
                def update_prompt(selected):
                    if selected == "-- é€‰æ‹©ç¤ºä¾‹æç¤ºè¯ --":
                        return ""
                    for p in example_prompts:
                        if p["name"] == selected:
                            return p["prompt"]
                    return ""
                
                prompt_dropdown.change(
                    fn=update_prompt,
                    inputs=[prompt_dropdown],
                    outputs=[prompt_input]
                )
            
            negative_prompt_input = gr.Textbox(
                label="è´Ÿé¢æç¤ºè¯ (Negative Prompt)",
                placeholder="æè¿°ä½ ä¸æƒ³è¦çš„å†…å®¹...",
                lines=2,
                value=" "
            )
            
            gr.Markdown("### âš™ï¸ å‚æ•°è®¾ç½®")
            with gr.Row():
                seed_input = gr.Number(label="éšæœºç§å­", value=0, precision=0)
                num_images_input = gr.Slider(
                    label="ç”Ÿæˆæ•°é‡", 
                    minimum=1, 
                    maximum=4, 
                    step=1, 
                    value=1
                )
            
            with gr.Row():
                true_cfg_scale_input = gr.Slider(
                    label="True CFG Scale", 
                    minimum=1.0, 
                    maximum=10.0, 
                    step=0.5, 
                    value=4.0
                )
                guidance_scale_input = gr.Slider(
                    label="Guidance Scale", 
                    minimum=0.0, 
                    maximum=5.0, 
                    step=0.1, 
                    value=1.0
                )
            
            num_steps_input = gr.Slider(
                label="æ¨ç†æ­¥æ•° (Inference Steps)", 
                minimum=10, 
                maximum=100, 
                step=5, 
                value=40
            )
            
            generate_btn = gr.Button("ğŸš€ ç”Ÿæˆå›¾ç‰‡", variant="primary", size="lg")
        
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ–¼ï¸ ç”Ÿæˆç»“æœ")
            output_gallery = gr.Gallery(
                label="ç”Ÿæˆçš„å›¾ç‰‡",
                show_label=False,
                columns=1,
                rows=1,
                height=None,
                object_fit="scale-down",
                preview=True
            )
    
    # ç»‘å®šç”ŸæˆæŒ‰é’®äº‹ä»¶
    generate_btn.click(
        fn=generate_image,
        inputs=[
            image1_input,
            image2_input,
            prompt_input,
            negative_prompt_input,
            seed_input,
            true_cfg_scale_input,
            guidance_scale_input,
            num_steps_input,
            num_images_input
        ],
        outputs=output_gallery
    )
    
    return image1_input, image2_input, prompt_input, output_gallery

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="Qwen Image Edit 2511", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¨ Qwen Image Edit 2511
    
    åŸºäº Qwen-Image-Edit-2511 æ¨¡å‹çš„å›¾ç‰‡ç¼–è¾‘å·¥å…·ã€‚ä¸Šä¼ 1-2å¼ å›¾ç‰‡ï¼Œè¾“å…¥æç¤ºè¯ï¼Œå³å¯ç”Ÿæˆæ–°å›¾ç‰‡ã€‚
    """)
    
    with gr.Tabs():
        # Tab 1: è§’è‰²ä¸€è‡´æ€§å¢å¼º
        with gr.TabItem("ğŸ­ è§’è‰²ä¸€è‡´æ€§å¢å¼º"):
            gr.Markdown("""
            ### åŠŸèƒ½è¯´æ˜
            ä¿æŒäººç‰©è§’è‰²çš„ä¸€è‡´æ€§ï¼Œæ”¯æŒç”ŸæˆåŒä¸€è§’è‰²çš„ä¸åŒåœºæ™¯ã€è¡¨æƒ…ã€åŠ¨ä½œç­‰å˜åŒ–ã€‚
            ä¸Šä¼ å‚è€ƒäººç‰©å›¾ç‰‡ï¼Œé€‰æ‹©æˆ–è¾“å…¥æç¤ºè¯ï¼Œç”Ÿæˆä¿æŒè§’è‰²ç‰¹å¾çš„æ–°å›¾ç‰‡ã€‚
            """)
            create_tab_content("character_consistency", EXAMPLE_PROMPTS["character_consistency"])
        
        # Tab 2: å¤šäººåˆç…§ä¸€è‡´æ€§
        with gr.TabItem("ğŸ‘¥ å¤šäººåˆç…§ä¸€è‡´æ€§"):
            gr.Markdown("""
            ### åŠŸèƒ½è¯´æ˜
            æ”¯æŒå¤šäººåˆç…§åœºæ™¯ï¼Œä¿æŒæ¯ä¸ªäººç‰©çš„ç‰¹å¾ä¸€è‡´æ€§ã€‚
            ä¸Šä¼ å¤šå¼ äººç‰©å‚è€ƒå›¾ï¼Œç”Ÿæˆè‡ªç„¶çš„å¤šäººåˆç…§æ•ˆæœã€‚
            """)
            create_tab_content("multi_person", EXAMPLE_PROMPTS["multi_person"])
        
        # Tab 3: å†…ç½® LoRA
        with gr.TabItem("ğŸ”§ å†…ç½® LoRA"):
            gr.Markdown("""
            ### åŠŸèƒ½è¯´æ˜
            æœ¬æ¨¡å‹å·²å†…ç½®é›†æˆç¤¾åŒºæµè¡Œçš„ LoRA èƒ½åŠ›ï¼ŒåŒ…æ‹¬**å…‰ç…§å¢å¼º**ã€**è§†è§’å˜æ¢**ç­‰ï¼Œæ— éœ€é¢å¤–åŠ è½½ï¼Œé€šè¿‡æç¤ºè¯å³å¯ç›´æ¥ä½¿ç”¨ã€‚
            
            - ğŸ’¡ **å…‰ç…§å¢å¼º**: çœŸå®å…‰ç…§æ§åˆ¶ï¼Œå¯è°ƒæ•´å›¾ç‰‡å…‰çº¿æ•ˆæœ
            - ğŸ¬ **è§†è§’å˜æ¢**: ç”Ÿæˆæ–°çš„è§†è§’/é•œå¤´è§’åº¦ï¼Œå¦‚å¹³ç§»ã€æ—‹è½¬ç­‰
            """)
            create_tab_content("lora", EXAMPLE_PROMPTS["lora"])
        
        # Tab 4: å·¥ä¸šè®¾è®¡åº”ç”¨
        with gr.TabItem("ğŸ­ å·¥ä¸šè®¾è®¡åº”ç”¨"):
            gr.Markdown("""
            ### åŠŸèƒ½è¯´æ˜
            é€‚ç”¨äºå·¥ä¸šè®¾è®¡åœºæ™¯ï¼Œæ”¯æŒäº§å“æ¸²æŸ“ã€æè´¨å˜æ¢ã€è®¾è®¡è¿­ä»£ç­‰åº”ç”¨ã€‚
            ä¸Šä¼ äº§å“è®¾è®¡å›¾ï¼Œç”Ÿæˆä¸åŒæè´¨ã€é¢œè‰²ã€åœºæ™¯çš„æ•ˆæœå›¾ã€‚
            """)
            create_tab_content("industrial_design", EXAMPLE_PROMPTS["industrial_design"])

if __name__ == "__main__":
    # é¢„åŠ è½½æ¨¡å‹
    print("æ­£åœ¨é¢„åŠ è½½æ¨¡å‹...")
    load_model()
    print("å¯åŠ¨ Gradio æœåŠ¡...")
    
    # å¯åŠ¨ Gradio æœåŠ¡
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
