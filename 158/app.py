import gradio as gr
import os
import sys
import time
import tempfile
from typing import Any, Union
import numpy as np
import torch
import trimesh
from huggingface_hub import snapshot_download
from PIL import Image
from accelerate.utils import set_seed

# Add the project root to the Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.utils.data_utils import get_colored_mesh_composition
from src.utils.render_utils import render_views_around_mesh, render_normal_views_around_mesh, make_grid_for_images_or_videos, export_renderings
from src.pipelines.pipeline_partcrafter import PartCrafterPipeline
from src.utils.image_utils import prepare_image
from src.models.briarmbg import BriaRMBG

# Global variables to store loaded models
pipe = None
rmbg_net = None
models_loaded = False

def load_models():
    """åŠ è½½æ¨¡å‹ï¼ˆå¦‚æœå°šæœªåŠ è½½ï¼‰"""
    global pipe, rmbg_net, models_loaded
    
    if models_loaded:
        # å¦‚æœæ¨¡å‹å·²åŠ è½½ï¼Œä¹Ÿæ˜¾ç¤ºå½“å‰VRAMä½¿ç”¨æƒ…å†µ
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
            memory_allocated = torch.cuda.memory_allocated(0) / 1024**3  # GB
            memory_reserved = torch.cuda.memory_reserved(0) / 1024**3  # GB
            return f"âœ… æ¨¡å‹å·²åŠ è½½ï¼è®¾å¤‡ï¼šcuda\nğŸ’¾ VRAM: {memory_allocated:.1f}GB / {gpu_memory:.1f}GB (å·²åˆ†é…)\nğŸ“Š ç¼“å­˜: {memory_reserved:.1f}GB (å·²é¢„ç•™)"
        else:
            return "âœ… æ¨¡å‹å·²åŠ è½½ï¼è®¾å¤‡ï¼šcpu"
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.float16 if device == "cuda" else torch.float32
    
    try:
        # æ˜¾ç¤ºåŠ è½½å‰çš„VRAMçŠ¶æ€
        if device == "cuda":
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
            initial_memory = torch.cuda.memory_allocated(0) / 1024**3  # GB
            
        # ä¸‹è½½é¢„è®­ç»ƒæƒé‡
        partcrafter_weights_dir = "pretrained_weights/PartCrafter"
        rmbg_weights_dir = "pretrained_weights/RMBG-1.4"
        
        snapshot_download(repo_id="wgsxm/PartCrafter", local_dir=partcrafter_weights_dir)
        snapshot_download(repo_id="briaai/RMBG-1.4", local_dir=rmbg_weights_dir)
        
        # åˆå§‹åŒ–æ¨¡å‹
        rmbg_net = BriaRMBG.from_pretrained(rmbg_weights_dir).to(device)
        rmbg_net.eval()
        
        pipe = PartCrafterPipeline.from_pretrained(partcrafter_weights_dir).to(device, dtype)
        
        models_loaded = True
        
        # æ˜¾ç¤ºåŠ è½½åçš„VRAMçŠ¶æ€
        if device == "cuda":
            final_memory = torch.cuda.memory_allocated(0) / 1024**3  # GB
            memory_reserved = torch.cuda.memory_reserved(0) / 1024**3  # GB
            model_memory = final_memory - initial_memory
            
            return f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼è®¾å¤‡ï¼š{device}\nğŸ’¾ VRAM: {final_memory:.1f}GB / {gpu_memory:.1f}GB (å·²åˆ†é…)\nğŸ“Š ç¼“å­˜: {memory_reserved:.1f}GB (å·²é¢„ç•™)\nğŸš€ æ¨¡å‹å ç”¨: {model_memory:.1f}GB"
        else:
            return f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼è®¾å¤‡ï¼š{device}"
        
    except Exception as e:
        return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}"

@torch.no_grad()
def run_partcrafter(
    image_input: Image.Image,
    num_parts: int,
    seed: int,
    num_tokens: int = 1024,
    num_inference_steps: int = 50,
    guidance_scale: float = 7.0,
    use_rmbg: bool = False,
    progress=gr.Progress()
):
    """è¿è¡ŒPartCrafteræ¨ç†"""
    global pipe, rmbg_net, models_loaded
    
    if not models_loaded:
        return None, None, None, "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹ï¼"
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.float16 if device == "cuda" else torch.float32
    
    try:
        progress(0.1, desc="æ­£åœ¨é¢„å¤„ç†å›¾åƒ...")
        
        # é¢„å¤„ç†å›¾åƒ
        if use_rmbg:
            # ä¸ºRMBGåˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                image_input.save(tmp_file.name)
                img_pil = prepare_image(tmp_file.name, bg_color=np.array([1.0, 1.0, 1.0]), rmbg_net=rmbg_net)
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.unlink(tmp_file.name)
        else:
            img_pil = image_input
        
        progress(0.2, desc="æ­£åœ¨å‡†å¤‡ç”Ÿæˆ...")
        set_seed(seed)
        
        progress(0.3, desc="æ­£åœ¨ç”Ÿæˆ3Déƒ¨ä»¶...")
        start_time = time.time()
        
        outputs = pipe(
            image=[img_pil] * num_parts,
            attention_kwargs={"num_parts": num_parts},
            num_tokens=num_tokens,
            generator=torch.Generator(device=pipe.device).manual_seed(seed),
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            max_num_expanded_coords=int(1e9),
            use_flash_decoder=False,
        ).meshes
        
        end_time = time.time()
        generation_time = f"â±ï¸ ç”Ÿæˆè€—æ—¶ï¼š{end_time - start_time:.2f} ç§’"
        
        progress(0.8, desc="æ­£åœ¨å¤„ç†ç½‘æ ¼...")
        
        # å¤„ç†ç©ºç½‘æ ¼
        for i in range(len(outputs)):
            if outputs[i] is None:
                outputs[i] = trimesh.Trimesh(vertices=[[0, 0, 0]], faces=[[0, 0, 0]])
        
        # åˆ›å»ºåˆå¹¶ç½‘æ ¼
        merged_mesh = get_colored_mesh_composition(outputs)
        
        progress(0.9, desc="æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
        output_dir = tempfile.mkdtemp(prefix="partcrafter_")
        
        # ä¿å­˜å„ä¸ªéƒ¨ä»¶
        part_files = []
        for i, mesh in enumerate(outputs):
            part_file = os.path.join(output_dir, f"part_{i:02d}.glb")
            mesh.export(part_file)
            part_files.append(part_file)
        
        # ä¿å­˜åˆå¹¶å¯¹è±¡
        object_file = os.path.join(output_dir, "object.glb")
        merged_mesh.export(object_file)
        
        # å°è¯•æ¸²æŸ“
        rendered_gif = None
        try:
            progress(0.95, desc="æ­£åœ¨æ¸²æŸ“é¢„è§ˆ...")
            
            num_views = 36
            radius = 4
            fps = 18
            
            rendered_images = render_views_around_mesh(
                merged_mesh,
                num_views=num_views,
                radius=radius,
            )
            
            # ä¿å­˜æ¸²æŸ“ä¸ºGIF
            gif_file = os.path.join(output_dir, "rendering.gif")
            export_renderings(rendered_images, gif_file, fps=fps)
            rendered_gif = gif_file
            
        except Exception as render_e:
            print(f"æ¸²æŸ“å¤±è´¥ï¼š{render_e}")
            rendered_gif = None
        
        progress(1.0, desc="å®Œæˆï¼")
        
        success_message = f"âœ… æˆåŠŸç”Ÿæˆ {num_parts} ä¸ªéƒ¨ä»¶ï¼\n{generation_time}"
        
        return object_file, part_files, rendered_gif, success_message
        
    except Exception as e:
        return None, None, None, f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™ï¼š{str(e)}"

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    with gr.Blocks(
        title="PartCrafter ä¸­æ–‡ç•Œé¢", 
        theme=gr.themes.Soft(),
        css="""
        .container { max-width: 1200px; margin: auto; }
        .header { text-align: center; margin-bottom: 2rem; }
        .model-status { padding: 1rem; border-radius: 8px; margin: 1rem 0; }
        """
    ) as demo:
        
        gr.Markdown("""
        # ğŸ› ï¸ PartCrafter ä¸­æ–‡ç•Œé¢
        
        **ä»å•å¼ å›¾ç‰‡ç”Ÿæˆå¯åˆ†ç¦»éƒ¨ä»¶çš„3Då¯¹è±¡ï¼**
        
        ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ï¼ŒPartCrafterå°†æŠŠå®ƒåˆ†è§£æˆå¤šä¸ªå¯ä»¥ç»„è£…åœ¨ä¸€èµ·çš„3Déƒ¨ä»¶ã€‚
        """, elem_classes=["header"])
        
        # æ¨¡å‹åŠ è½½éƒ¨åˆ†
        with gr.Row():
            with gr.Column(scale=1):
                load_btn = gr.Button("ğŸ”„ åŠ è½½æ¨¡å‹", variant="primary", size="lg")
                model_status = gr.Textbox(
                    label="æ¨¡å‹çŠ¶æ€", 
                    value="ğŸŸ¡ æ¨¡å‹æœªåŠ è½½ã€‚ç‚¹å‡»'åŠ è½½æ¨¡å‹'å¼€å§‹åŠ è½½ã€‚",
                    interactive=False,
                    elem_classes=["model-status"]
                )
        
        gr.Markdown("---")
        
        # ä¸»ç•Œé¢
        with gr.Row():
            # è¾“å…¥åˆ—
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“¤ è¾“å…¥")
                
                input_image = gr.Image(
                    label="ä¸Šä¼ å›¾ç‰‡",
                    type="pil",
                    height=300
                )
                
                with gr.Group():
                    gr.Markdown("### âš™ï¸ ç”Ÿæˆè®¾ç½®")
                    
                    num_parts = gr.Slider(
                        minimum=1,
                        maximum=16,
                        value=3,
                        step=1,
                        label="éƒ¨ä»¶æ•°é‡",
                        info="å°†å¯¹è±¡åˆ†è§£æˆå¤šå°‘ä¸ªéƒ¨ä»¶"
                    )
                    
                    seed = gr.Number(
                        value=42,
                        label="éšæœºç§å­",
                        info="ç”¨äºç”Ÿæˆå¯é‡ç°ç»“æœçš„éšæœºç§å­"
                    )
                    
                    with gr.Accordion("ğŸ”§ é«˜çº§è®¾ç½®", open=False):
                        num_tokens = gr.Slider(
                            minimum=256,
                            maximum=2048,
                            value=1024,
                            step=256,
                            label="ä»¤ç‰Œæ•°é‡",
                            info="æ•°å€¼è¶Šé«˜ = ç»†èŠ‚è¶Šå¤šï¼ˆé€Ÿåº¦è¶Šæ…¢ï¼‰"
                        )
                        
                        num_inference_steps = gr.Slider(
                            minimum=10,
                            maximum=100,
                            value=50,
                            step=10,
                            label="æ¨ç†æ­¥æ•°",
                            info="æ­¥æ•°è¶Šå¤š = è´¨é‡è¶Šå¥½ï¼ˆé€Ÿåº¦è¶Šæ…¢ï¼‰"
                        )
                        
                        guidance_scale = gr.Slider(
                            minimum=1.0,
                            maximum=15.0,
                            value=7.0,
                            step=0.5,
                            label="å¼•å¯¼å¼ºåº¦",
                            info="å¤šå¤§ç¨‹åº¦ä¸Šéµå¾ªè¾“å…¥å›¾åƒ"
                        )
                        
                        use_rmbg = gr.Checkbox(
                            label="æ˜¾å¼å»èƒŒæ™¯å¤„ç†",
                            value=False,
                            info="å¯¹å¤æ‚èƒŒæ™¯å›¾åƒæ¨èå¼€å¯ï¼Œç®€å•èƒŒæ™¯å¯å…³é—­"
                        )
                
                generate_btn = gr.Button("ğŸš€ ç”Ÿæˆ3Déƒ¨ä»¶", variant="primary", size="lg")
        
            # è¾“å‡ºåˆ—
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“¥ è¾“å‡º")
                
                status_output = gr.Textbox(
                    label="çŠ¶æ€",
                    value="å‡†å¤‡ç”Ÿæˆï¼",
                    interactive=False
                )
                
                with gr.Tab("ğŸ¬ é¢„è§ˆ"):
                    rendered_output = gr.Image(
                        label="360Â° æ—‹è½¬é¢„è§ˆ",
                        type="filepath",
                        height=300
                    )
                
                with gr.Tab("ğŸ“ ä¸‹è½½"):
                    object_output = gr.File(
                        label="å®Œæ•´å¯¹è±¡ (object.glb)",
                        file_types=[".glb"]
                    )
                    
                    parts_output = gr.File(
                        label="å„ä¸ªéƒ¨ä»¶",
                        file_count="multiple",
                        file_types=[".glb"]
                    )
        
        # ç¤ºä¾‹å›¾ç‰‡
        gr.Markdown("## ğŸ¯ è¯•è¯•è¿™äº›ç¤ºä¾‹")
        
        example_images = [
            ["assets/images/np3_2f6ab901c5a84ed6bbdf85a67b22a2ee.png", 3, 42],
            ["assets/images/np4_2444ea17f3a448b1bb7e2a74b276f015.png", 4, 123],
            ["assets/images/np5_23ae06bb5cf84e13ae973721fa5f5625.png", 5, 456],
        ]
        
        # æ£€æŸ¥ç¤ºä¾‹å›¾ç‰‡æ˜¯å¦å­˜åœ¨
        available_examples = []
        for img_path, parts, seed_val in example_images:
            if os.path.exists(img_path):
                available_examples.append([img_path, parts, seed_val])
        
        if available_examples:
            gr.Examples(
                examples=available_examples,
                inputs=[input_image, num_parts, seed],
                label="ç‚¹å‡»ç¤ºä¾‹åŠ è½½"
            )
        
        # äº‹ä»¶å¤„ç†
        load_btn.click(
            fn=load_models,
            outputs=[model_status]
        )
        
        generate_btn.click(
            fn=run_partcrafter,
            inputs=[
                input_image, num_parts, seed, num_tokens, 
                num_inference_steps, guidance_scale, use_rmbg
            ],
            outputs=[object_output, parts_output, rendered_output, status_output]
        )
        
        # é¡µè„š
        gr.Markdown("""
        ---
        
        ğŸ’¡ **ä½¿ç”¨æŠ€å·§ï¼š**
        - å»ºè®®ä»3-5ä¸ªéƒ¨ä»¶å¼€å§‹ï¼Œæ•ˆæœæœ€ä½³
        - æ›´é«˜çš„è´¨é‡è®¾ç½®éœ€è¦æ›´é•¿æ—¶é—´ä½†äº§ç”Ÿæ›´å¥½çš„ç»“æœ  
        - å¯¹äºå¤æ‚èƒŒæ™¯çš„å›¾åƒä½¿ç”¨èƒŒæ™¯ç§»é™¤åŠŸèƒ½
        - ç”Ÿæˆçš„.glbæ–‡ä»¶å¯ä»¥åœ¨Blenderã€Unityæˆ–ä»»ä½•3DæŸ¥çœ‹å™¨ä¸­æ‰“å¼€
        
        ğŸ¥ **ä¸“ä¸ºYouTubeåˆ›ä½œè€…ä¼˜åŒ–ï¼š** è¿™ä¸ªå·¥å…·éå¸¸é€‚åˆå±•ç¤ºAIé©±åŠ¨çš„3Dç”ŸæˆæŠ€æœ¯ï¼
        """)
    
    return demo

if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_interface()
    
    # å¯åŠ¨ï¼Œè®¾ç½®share=Trueå¯è·å¾—å…¬å¼€URLç”¨äºYouTubeæ¼”ç¤º
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,
        share=False,  # è®¾ä¸ºTrueå¯è·å¾—å…¬å¼€URL
        debug=True
    )
