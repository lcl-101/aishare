import torch
from transformers import LightOnOcrForConditionalGeneration, LightOnOcrProcessor
import gradio as gr
import os
import urllib.request
from PIL import Image

# ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡
EXAMPLE_IMAGE_URL = "https://huggingface.co/datasets/hf-internal-testing/fixtures_ocr/resolve/main/SROIE-receipt.jpeg"
EXAMPLE_IMAGE_PATH = "example_image.jpeg"

def download_example_image():
    """ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡åˆ°æœ¬åœ°"""
    if not os.path.exists(EXAMPLE_IMAGE_PATH):
        print(f"æ­£åœ¨ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡...")
        try:
            urllib.request.urlretrieve(EXAMPLE_IMAGE_URL, EXAMPLE_IMAGE_PATH)
            print(f"ç¤ºä¾‹å›¾ç‰‡å·²ä¸‹è½½åˆ°: {EXAMPLE_IMAGE_PATH}")
        except Exception as e:
            print(f"ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡å¤±è´¥: {e}")
    else:
        print(f"ç¤ºä¾‹å›¾ç‰‡å·²å­˜åœ¨: {EXAMPLE_IMAGE_PATH}")

# åˆå§‹åŒ–è®¾å¤‡å’Œæ•°æ®ç±»å‹
device = "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"
dtype = torch.float32 if device == "mps" else torch.bfloat16

print(f"ä½¿ç”¨è®¾å¤‡: {device}")
print(f"ä½¿ç”¨æ•°æ®ç±»å‹: {dtype}")

# åŠ è½½æœ¬åœ°æ¨¡å‹
MODEL_PATH = "checkpoints/LightOnOCR-2-1B"
print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH}")
model = LightOnOcrForConditionalGeneration.from_pretrained(MODEL_PATH, torch_dtype=dtype).to(device)
processor = LightOnOcrProcessor.from_pretrained(MODEL_PATH)
print("æ¨¡å‹åŠ è½½å®Œæˆ")

def ocr_inference(image, prompt, max_tokens):
    """
    å¯¹å›¾ç‰‡è¿›è¡Œ OCR è¯†åˆ«
    
    Args:
        image: PIL Image æˆ–å›¾ç‰‡è·¯å¾„
        prompt: ç”¨æˆ·æç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°é‡
    
    Returns:
        è¯†åˆ«çš„æ–‡æœ¬ç»“æœ
    """
    if image is None:
        return "è¯·ä¸Šä¼ å›¾ç‰‡æˆ–é€‰æ‹©ç¤ºä¾‹å›¾ç‰‡"
    
    try:
        # å¦‚æœæ˜¯è·¯å¾„å­—ç¬¦ä¸²ï¼ŒåŠ è½½å›¾ç‰‡
        if isinstance(image, str):
            image = Image.open(image)
        
        # ä¿å­˜ä¸´æ—¶å›¾ç‰‡å¹¶è·å–è·¯å¾„
        temp_image_path = "/tmp/temp_ocr_image.png"
        image.save(temp_image_path)
        
        # æ„å»ºå¯¹è¯æ ¼å¼ï¼Œä½¿ç”¨æœ¬åœ°æ–‡ä»¶è·¯å¾„
        content = [{"type": "image", "url": temp_image_path}]
        
        # å¦‚æœæœ‰æç¤ºè¯ï¼Œæ·»åŠ åˆ°å†…å®¹ä¸­
        if prompt and prompt.strip():
            content.append({"type": "text", "text": prompt.strip()})
        
        conversation = [{"role": "user", "content": content}]
        
        # åº”ç”¨èŠå¤©æ¨¡æ¿å¹¶å¤„ç†è¾“å…¥
        inputs = processor.apply_chat_template(
            conversation,
            add_generation_prompt=True,
            tokenize=True,
            return_dict=True,
            return_tensors="pt",
        )
        
        # å°†è¾“å…¥ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
        inputs = {k: v.to(device=device, dtype=dtype) if v.is_floating_point() else v.to(device) for k, v in inputs.items()}
        
        # ç”Ÿæˆè¾“å‡º
        output_ids = model.generate(**inputs, max_new_tokens=int(max_tokens))
        generated_ids = output_ids[0, inputs["input_ids"].shape[1]:]
        output_text = processor.decode(generated_ids, skip_special_tokens=True)
        
        return output_text
        
    except Exception as e:
        return f"è¯†åˆ«è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"

# ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡
download_example_image()

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="LightOnOCR-2 æ–‡å­—è¯†åˆ«") as demo:
    # YouTube é¢‘é“ä¿¡æ¯
    gr.Markdown(
        """
        # LightOnOCR-2 æ–‡å­—è¯†åˆ«ç³»ç»Ÿ
        
        ### ğŸ“º æ¬¢è¿å…³æ³¨ [AI æŠ€æœ¯åˆ†äº«é¢‘é“](https://www.youtube.com/@rongyikanshijie-ai)
        
        ---
        """
    )
    
    gr.Markdown(
        """
        ## ä½¿ç”¨è¯´æ˜
        
        æœ¬ç³»ç»Ÿä½¿ç”¨ LightOnOCR-2-1B æ¨¡å‹è¿›è¡Œå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰ã€‚ä¸Šä¼ å›¾ç‰‡æˆ–é€‰æ‹©ç¤ºä¾‹å›¾ç‰‡ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ã€‚
        """
    )
    
    with gr.Row():
        with gr.Column(scale=1):
            # å›¾ç‰‡è¾“å…¥
            image_input = gr.Image(
                label="ä¸Šä¼ å›¾ç‰‡",
                type="pil",
                sources=["upload", "clipboard"]
            )
            
            # æç¤ºè¯è¾“å…¥
            prompt_input = gr.Textbox(
                label="æç¤ºè¯ï¼ˆå¯é€‰ï¼‰",
                placeholder="ä¾‹å¦‚ï¼šConvert to markdown / Extract text / Describe the image",
                lines=2,
                value=""
            )
            
            # ç¤ºä¾‹æç¤ºè¯
            gr.Markdown("**å¸¸ç”¨æç¤ºè¯ç¤ºä¾‹ï¼š**")
            with gr.Row():
                example_prompts = [
                    gr.Button("Convert to markdown", size="sm"),
                    gr.Button("Extract all text", size="sm"),
                    gr.Button("Read this document", size="sm"),
                ]
            
            # å‚æ•°è®¾ç½®
            max_tokens_slider = gr.Slider(
                minimum=128,
                maximum=2048,
                value=1024,
                step=128,
                label="æœ€å¤§ç”Ÿæˆ Token æ•°é‡",
                info="æ§åˆ¶è¾“å‡ºæ–‡æœ¬çš„æœ€å¤§é•¿åº¦"
            )
            
            # è¯†åˆ«æŒ‰é’®
            submit_btn = gr.Button("å¼€å§‹è¯†åˆ«", variant="primary", size="lg")
            
            # æ¸…é™¤æŒ‰é’®
            clear_btn = gr.Button("æ¸…é™¤", size="sm")
            
        with gr.Column(scale=1):
            # è¾“å‡ºæ–‡æœ¬æ¡†
            output_text = gr.Textbox(
                label="è¯†åˆ«ç»“æœ",
                lines=20,
                placeholder="è¯†åˆ«ç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º..."
            )
    
    # ç¤ºä¾‹å›¾ç‰‡
    gr.Markdown("### ğŸ“· ç¤ºä¾‹å›¾ç‰‡")
    gr.Examples(
        examples=[[EXAMPLE_IMAGE_PATH, "", 1024]] if os.path.exists(EXAMPLE_IMAGE_PATH) else [],
        inputs=[image_input, prompt_input, max_tokens_slider],
        outputs=output_text,
        fn=ocr_inference,
        cache_examples=False,
        label="ç‚¹å‡»åŠ è½½ç¤ºä¾‹"
    )
    
    # ç»‘å®šç¤ºä¾‹æç¤ºè¯æŒ‰é’®äº‹ä»¶
    example_prompts[0].click(fn=lambda: "Convert to markdown", outputs=prompt_input)
    example_prompts[1].click(fn=lambda: "Extract all text", outputs=prompt_input)
    example_prompts[2].click(fn=lambda: "Read this document", outputs=prompt_input)
    
    # é¡µè„šä¿¡æ¯
    gr.Markdown(
        """
        ---
        
        **æ¨¡å‹ä¿¡æ¯**: LightOnOCR-2-1B | **è®¾å¤‡**: {} | **ç²¾åº¦**: {}
        """.format(device, dtype)
    )
    
    # äº‹ä»¶ç»‘å®š
    submit_btn.click(
        fn=ocr_inference,
        inputs=[image_input, prompt_input, max_tokens_slider],
        outputs=output_text
    )
    
    clear_btn.click(
        fn=lambda: (None, "", ""),
        inputs=None,
        outputs=[image_input, prompt_input, output_text]
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        theme=gr.themes.Soft()
    )
