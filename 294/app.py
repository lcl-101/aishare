import gradio as gr
import torch
import torchaudio
import numpy as np
from transformers import AutoModelForCausalLM
from megatron.tokenizer import build_tokenizer
from mucodec.generate_1rvq import Tango
import os


class Args:
    def __init__(self):
        pass


class SongPrepModel:
    def __init__(self, model_path, codec_path, vocal_file, tokenizer="Qwen2Tokenizer", extra_vocab_size=16384):
        print("æ­£åœ¨åŠ è½½éŸ³é¢‘ç¼–è§£ç å™¨...")
        self.tango = Tango(model_path=codec_path)
        
        print("æ­£åœ¨åŠ è½½è¯­è¨€æ¨¡å‹...")
        args = Args()
        args.vocab_file = vocal_file
        args.load = model_path
        args.extra_vocab_size = extra_vocab_size
        args.patch_tokenizer_type = tokenizer

        self.tokenizer = build_tokenizer(args)
        self.text_offset = len(self.tokenizer.tokenizer.get_vocab())
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True,
            torch_dtype=torch.bfloat16,
        ).to("cuda")
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")

    def process_audio(self, audio_path):
        """å¤„ç†éŸ³é¢‘æ–‡ä»¶å¹¶è¿”å›æ­Œè¯å’Œç»“æ„åˆ†æç»“æœ"""
        if audio_path is None:
            return "è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
        
        try:
            # åŠ è½½éŸ³é¢‘
            src_wave, fs = torchaudio.load(audio_path)
            
            # é‡é‡‡æ ·åˆ° 48kHz
            if fs != 48000:
                src_wave = torchaudio.functional.resample(src_wave, fs, 48000)
            
            # éŸ³é¢‘ç¼–ç 
            code = self.tango.sound2code(src_wave)
            
            # æ¨¡å‹æ¨ç†
            audio = np.array(code[0][0].to("cpu")).astype(np.int32) + self.text_offset
            sentence_ids = [self.tokenizer.sep_token_id] + audio.tolist() + [self.tokenizer.tokenizer.sep_token_id]
            
            prompt = torch.LongTensor(sentence_ids).to("cuda").unsqueeze(0)
            generate_ids = self.model.generate(
                prompt, 
                do_sample=True, 
                top_p=0.1,
                temperature=0.1, 
                num_return_sequences=1,
                eos_token_id=self.tokenizer.eos_token_id, 
                pad_token_id=self.tokenizer.pad_token_id,
                max_length=8192,
            ).squeeze(0).cpu().numpy()

            # è§£æè¾“å‡º
            indices = (generate_ids == self.tokenizer.sep_token_id).nonzero()[0]
            assert len(indices) >= 2, indices
            start = indices[1] + 1
            if len(indices) == 2:
                end = -1
            else:
                end = indices[2] - 1
            
            result = self.tokenizer.detokenize(generate_ids[start:end])
            return result
            
        except Exception as e:
            return f"å¤„ç†å‡ºé”™: {str(e)}"


# å…¨å±€æ¨¡å‹å®ä¾‹
model = None


def load_model():
    """åŠ è½½æ¨¡å‹"""
    global model
    if model is None:
        model_path = "checkpoints/SongPrep-7B/"
        codec_path = "checkpoints/SongPrep-7B/mucodec.safetensors"
        vocal_file = "conf/vocab_type.yaml"
        model = SongPrepModel(model_path, codec_path, vocal_file)
    return model


def process_audio(audio_path):
    """å¤„ç†ä¸Šä¼ çš„éŸ³é¢‘"""
    if audio_path is None:
        return "è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
    
    m = load_model()
    result = m.process_audio(audio_path)
    return result


def format_result(result):
    """æ ¼å¼åŒ–è¾“å‡ºç»“æœï¼Œä½¿å…¶æ›´æ˜“è¯»"""
    if result.startswith("è¯·å…ˆ") or result.startswith("å¤„ç†å‡ºé”™"):
        return result
    
    # å°†åˆ†å·åˆ†éš”çš„ç‰‡æ®µæ¢è¡Œæ˜¾ç¤º
    segments = result.split(";")
    formatted = []
    for seg in segments:
        seg = seg.strip()
        if seg:
            formatted.append(seg)
    
    return "\n\n".join(formatted)


def analyze_audio(audio_path):
    """åˆ†æéŸ³é¢‘å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœ"""
    raw_result = process_audio(audio_path)
    formatted_result = format_result(raw_result)
    return raw_result, formatted_result


# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="SongPrep - æ­Œæ›²ç»“æ„åˆ†æä¸æ­Œè¯è¯†åˆ«", theme=gr.themes.Soft()) as demo:
    # YouTube é¢‘é“ä¿¡æ¯
    gr.HTML("""
    <div style="text-align: center; padding: 15px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 20px;">
        <h3 style="color: white; margin: 0;">
            ğŸ“º æ¬¢è¿è®¿é—®æˆ‘çš„ YouTube é¢‘é“: 
            <a href="https://www.youtube.com/@rongyikanshijie-ai" target="_blank" style="color: #ffeb3b; text-decoration: none;">
                AI æŠ€æœ¯åˆ†äº«é¢‘é“
            </a>
        </h3>
        <p style="color: #e0e0e0; margin: 5px 0 0 0; font-size: 14px;">
            ç‚¹å‡»ä¸Šæ–¹é“¾æ¥è®¢é˜…é¢‘é“ï¼Œè·å–æ›´å¤š AI æŠ€æœ¯æ•™ç¨‹ï¼
        </p>
    </div>
    """)
    
    # æ ‡é¢˜
    gr.Markdown("""
    # ğŸµ SongPrep - æ­Œæ›²ç»“æ„åˆ†æä¸æ­Œè¯è¯†åˆ«
    
    **SongPrep** æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ­Œæ›²é¢„å¤„ç†æ¨¡å‹ï¼Œèƒ½å¤Ÿåˆ†æå®Œæ•´æ­Œæ›²çš„ç»“æ„å¹¶è¯†åˆ«æ­Œè¯ï¼ŒåŒæ—¶æä¾›ç²¾ç¡®çš„æ—¶é—´æˆ³ï¼Œæ— éœ€é¢å¤–çš„éŸ³æºåˆ†ç¦»ã€‚
    
    ### ä½¿ç”¨è¯´æ˜
    1. ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ WAVã€MP3 ç­‰æ ¼å¼ï¼‰
    2. ç‚¹å‡»ã€Œå¼€å§‹åˆ†æã€æŒ‰é’®
    3. ç­‰å¾…æ¨¡å‹å¤„ç†ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦åŠ è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰
    4. æŸ¥çœ‹åˆ†æç»“æœ
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            # éŸ³é¢‘ä¸Šä¼ 
            audio_input = gr.Audio(
                label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶",
                type="filepath",
                sources=["upload", "microphone"]
            )
            
            # åˆ†ææŒ‰é’®
            analyze_btn = gr.Button("ğŸ¯ å¼€å§‹åˆ†æ", variant="primary", size="lg")
            
            # ç¤ºä¾‹è¯´æ˜
            gr.Markdown("""
            ### è¾“å‡ºæ ¼å¼è¯´æ˜
            ```
            [structure][start:end]lyric ; [structure][start:end]lyric
            ```
            - **structure**: æ­Œæ›²ç»“æ„æ ‡ç­¾
            - **start:end**: ç‰‡æ®µçš„èµ·æ­¢æ—¶é—´
            - **lyric**: è¯†åˆ«çš„æ­Œè¯ï¼Œå¥å­ç”¨ `.` åˆ†éš”
            
            ### ç»“æ„æ ‡ç­¾å«ä¹‰
            | æ ‡ç­¾ | ä¸­æ–‡å«ä¹‰ |
            |------|----------|
            | intro | å‰å¥ |
            | verse | ä¸»æ­Œ |
            | chorus | å‰¯æ­Œ |
            | bridge | æ¡¥æ®µ |
            | inst | é—´å¥ï¼ˆçº¯éŸ³ä¹ï¼‰|
            | outro | å°¾å¥ |
            | pre-chorus | é¢„å‰¯æ­Œ |
            | interlude | æ’æ›² |
            """)
        
        with gr.Column(scale=1):
            # æ ¼å¼åŒ–ç»“æœ
            formatted_output = gr.Textbox(
                label="åˆ†æç»“æœï¼ˆæ ¼å¼åŒ–ï¼‰",
                lines=15,
                placeholder="åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ..."
            )
            
            # åŸå§‹ç»“æœ
            raw_output = gr.Textbox(
                label="åŸå§‹è¾“å‡º",
                lines=5,
                placeholder="åŸå§‹è¾“å‡ºå°†æ˜¾ç¤ºåœ¨è¿™é‡Œ..."
            )
    
    # ç»‘å®šäº‹ä»¶
    analyze_btn.click(
        fn=analyze_audio,
        inputs=[audio_input],
        outputs=[raw_output, formatted_output]
    )
    
    # åº•éƒ¨ä¿¡æ¯
    gr.Markdown("""
    ---
    ### å…³äºæ¨¡å‹
    - **æ¨¡å‹**: SongPrep-7B
    - **å‚æ•°é‡**: 7B
    - **æ”¯æŒè¯­è¨€**: ä¸­æ–‡ã€è‹±æ–‡
    - **è®ºæ–‡**: [arXiv:2509.17404](https://arxiv.org/abs/2509.17404)
    - **æ¨¡å‹æƒé‡**: [Hugging Face](https://huggingface.co/waytan22/SongPrep-7B)
    """)


if __name__ == "__main__":
    # é¢„åŠ è½½æ¨¡å‹
    print("æ­£åœ¨é¢„åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
    load_model()
    print("æ¨¡å‹åŠ è½½å®Œæˆï¼Œå¯åŠ¨ Web æœåŠ¡...")
    
    # å¯åŠ¨æœåŠ¡
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
