#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTubeè§†é¢‘æ‰¹é‡ä¸‹è½½å’Œåˆ†æ - ä¼˜åŒ–è§‚ç‚¹æå–ç‰ˆæœ¬
ä¸“é—¨ä¸ºYouTubeå†…å®¹åˆ›ä½œè€…è®¾è®¡ï¼Œæå–å¯ç”¨äºå†…å®¹åˆ›ä½œçš„è§‚ç‚¹åº“

ä¸»è¦æ”¹è¿›ï¼š
1. ä¼˜åŒ–æœ€ç»ˆç»¼åˆæ€»ç»“çš„æç¤ºè¯ï¼Œæ›´é€‚åˆå†…å®¹åˆ›ä½œ
2. æŒ‰ç…§è§‚ç‚¹ä»·å€¼å’Œåˆ›ä½œç”¨é€”åˆ†ç±»æ•´ç†
3. çªå‡ºäº‰è®®ç‚¹å’Œç‹¬ç‰¹è§è§£
4. æä¾›å…·ä½“çš„åˆ›ä½œå»ºè®®
"""

import asyncio
import json
import os
import re
import requests
import time
from pathlib import Path
from urllib.parse import quote_plus, urljoin
import yt_dlp
from crawl4ai import AsyncWebCrawler


class YouTubeAnalyzer:
    def __init__(self, downloads_dir="downloads", summaries_dir="summaries"):
        self.downloads_dir = Path(downloads_dir)
        self.summaries_dir = Path(summaries_dir)
        self.downloads_dir.mkdir(exist_ok=True)
        self.summaries_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ– ollamaï¼ˆä¸ M4-3 ä¿æŒä¸€è‡´ï¼‰
        try:
            import ollama
            self.ollama = ollama
        except ImportError:
            import sys, subprocess
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'ollama'])
            import ollama
            self.ollama = ollama
        
        # Whisper æœåŠ¡é…ç½®
        self.whisper_url = "http://127.0.0.1:8080/transcribe/"
        
        # cookies æ–‡ä»¶è·¯å¾„
        self.cookies_file = "/workspace/ytdlp/cookies.txt"
        
    def clean_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦"""
        # ç§»é™¤æˆ–æ›¿æ¢ä¸èƒ½ç”¨äºæ–‡ä»¶åçš„å­—ç¬¦
        filename = re.sub(r'[<>:"/\\|?*]', '', filename)
        filename = re.sub(r'[^\w\s-]', '', filename)
        filename = re.sub(r'[-\s]+', '-', filename)
        return filename.strip('-')
    
    async def search_youtube_videos(self, keyword, max_videos=20):
        """ä½¿ç”¨ crawl4ai æœç´¢ YouTube è§†é¢‘"""
        print(f"ğŸ” æœç´¢å…³é”®è¯: {keyword}")
        
        search_url = f"https://www.youtube.com/results?search_query={quote_plus(keyword)}"
        
        async with AsyncWebCrawler(verbose=True) as crawler:
            # å¢åŠ æ»šåŠ¨æ¬¡æ•°å’Œç­‰å¾…æ—¶é—´ï¼Œè·å–æ›´å¤šè§†é¢‘
            js_code = """
            for(let i = 0; i < 8; i++) {
                window.scrollTo(0, document.body.scrollHeight);
                await new Promise(resolve => setTimeout(resolve, 2000));
            }
            """
            
            result = await crawler.arun(
                url=search_url,
                js_code=js_code,
                wait_for="css:ytd-video-renderer",
                delay_before_return_html=3.0
            )
            
            if result.success:
                videos = self._parse_search_results(result.html)
                print(f"âœ… æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
                return videos[:max_videos]
            else:
                print(f"âŒ æœç´¢å¤±è´¥: {result.error_message}")
                return []
    
    def _parse_search_results(self, html):
        """è§£ææœç´¢ç»“æœé¡µé¢"""
        videos = []
        
        # å¤šç§è§£ææ–¹æ³•
        patterns = [
            # æ–¹æ³•1: JSON æ•°æ®è§£æ
            r'"videoId":"([^"]+)".*?"title":{"runs":\[{"text":"([^"]+)"}.*?"viewCountText":{"simpleText":"([^"]+)"}',
            # æ–¹æ³•2: ç›´æ¥ä»HTMLè§£æ
            r'watch\?v=([a-zA-Z0-9_-]{11})',
        ]
        
        video_data = []
        
        # é¦–å…ˆå°è¯•æå–è§†é¢‘ID
        video_ids = set()
        for pattern in [r'watch\?v=([a-zA-Z0-9_-]{11})', r'"videoId":"([a-zA-Z0-9_-]{11})"']:
            matches = re.findall(pattern, html)
            video_ids.update(matches)
        
        print(f"å‘ç° {len(video_ids)} ä¸ªå”¯ä¸€è§†é¢‘ID")
        
        # å°è¯•é€šè¿‡å¤šç§æ–¹å¼è·å–è§†é¢‘ä¿¡æ¯
        for video_id in list(video_ids)[:30]:  # é™åˆ¶æ•°é‡é¿å…è¿‡å¤š
            video_info = self._extract_video_info(html, video_id)
            if video_info:
                video_data.append(video_info)
        
        # å¦‚æœé€šè¿‡HTMLè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ä¿¡æ¯
        if not video_data:
            for video_id in list(video_ids)[:20]:
                video_data.append({
                    'video_id': video_id,
                    'title': f'è§†é¢‘_{video_id}',  # å ä½æ ‡é¢˜
                    'view_count': 'æœªçŸ¥',
                    'url': f'https://www.youtube.com/watch?v={video_id}'
                })
        
        return video_data
    
    def _extract_video_info(self, html, video_id):
        """ä»HTMLä¸­æå–ç‰¹å®šè§†é¢‘çš„ä¿¡æ¯"""
        try:
            # å¤šç§titleæå–æ–¹æ³•
            title_patterns = [
                rf'"videoId":"{re.escape(video_id)}".*?"title":{{"runs":\[{{"text":"([^"]+)"}}',
                rf'"videoId":"{re.escape(video_id)}".*?"title":{{"simpleText":"([^"]+)"}}',
                rf'watch\?v={re.escape(video_id)}[^>]*aria-label="([^"]*)"',
            ]
            
            title = None
            for pattern in title_patterns:
                match = re.search(pattern, html, re.DOTALL)
                if match:
                    title = match.group(1)
                    break
            
            if not title:
                title = f"è§†é¢‘_{video_id}"
            
            # æ’­æ”¾é‡æå–
            view_patterns = [
                rf'"videoId":"{re.escape(video_id)}".*?"viewCountText":{{"simpleText":"([^"]+)"}}',
                rf'"videoId":"{re.escape(video_id)}".*?"shortViewCountText":{{"simpleText":"([^"]+)"}}',
            ]
            
            view_count = "æœªçŸ¥"
            for pattern in view_patterns:
                match = re.search(pattern, html, re.DOTALL)
                if match:
                    view_count = match.group(1)
                    break
            
            return {
                'video_id': video_id,
                'title': title,
                'view_count': view_count,
                'url': f'https://www.youtube.com/watch?v={video_id}'
            }
            
        except Exception as e:
            print(f"è§£æè§†é¢‘ {video_id} ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return None

    def filter_videos_with_llm(self, videos, keyword, target_count=8):
        """ä½¿ç”¨ LLM ç­›é€‰æœ€ç›¸å…³çš„è§†é¢‘"""
        print(f"ğŸ¤– ä½¿ç”¨ LLM ç­›é€‰æœ€ç›¸å…³çš„ {target_count} ä¸ªè§†é¢‘...")
        
        # æµ‹è¯• ollama è¿æ¥
        try:
            print("ğŸ” æµ‹è¯• ollama è¿æ¥...")
            test_response = self.ollama.chat(
                model='qwen3:32b',
                messages=[{"role": "user", "content": "æµ‹è¯•è¿æ¥ï¼Œè¯·å›å¤'è¿æ¥æ­£å¸¸'"}]
            )
            print(f"âœ… ollama è¿æ¥æ­£å¸¸")
        except Exception as e:
            print(f"âŒ ollama è¿æ¥å¤±è´¥: {e}")
            print("ä½¿ç”¨å¤‡ç”¨ç­›é€‰æ–¹æ³•...")
            return videos[:target_count]
        
        # æ„å»ºè§†é¢‘åˆ—è¡¨æ–‡æœ¬
        videos_text = ""
        for i, video in enumerate(videos, 1):
            videos_text += f"{i}. {video['title']} (æ’­æ”¾é‡: {video['view_count']})\n"
        
        prompt = f"""
è¯·ä»ä»¥ä¸‹å…³äº"{keyword}"çš„YouTubeè§†é¢‘ä¸­ï¼Œé€‰å‡ºæœ€é€‚åˆåšæ·±åº¦åˆ†æçš„ {target_count} ä¸ªè§†é¢‘ã€‚

é€‰æ‹©æ ‡å‡†ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰ï¼š
1. å½±è¯„ã€è§£æã€æ·±åº¦åˆ†æç±»å†…å®¹ï¼ˆæœ€é‡è¦ï¼‰
2. å‰§æƒ…è®¨è®ºã€è§’è‰²åˆ†æã€ç»†èŠ‚è§£è¯»
3. å¹•åèŠ±çµ®ã€åˆ¶ä½œåˆ†æã€å½©è›‹å‘ç°
4. è§‚ä¼—ååº”ã€è¯„è®ºåˆ†æ
5. æ’­æ”¾é‡ç›¸å¯¹è¾ƒé«˜çš„è§†é¢‘

é¿å…é€‰æ‹©ï¼š
- çº¯æ¬è¿ã€æ— è§£è¯´çš„è§†é¢‘
- æ ‡é¢˜å…šã€è¹­çƒ­åº¦çš„ä½è´¨é‡å†…å®¹
- è¿‡äºç®€çŸ­çš„å¿«é€Ÿè¯„è®º

è§†é¢‘åˆ—è¡¨ï¼š
{videos_text}

è¯·åªè¿”å›é€‰ä¸­çš„è§†é¢‘åºå·ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ï¼š1,3,5,7,9,12,15,18

é€‰æ‹©çš„åºå·ï¼š"""

        try:
            print("ğŸ”„ æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œè§†é¢‘ç­›é€‰...")
            response = self.ollama.chat(
                model='qwen3:32b',
                messages=[{"role": "user", "content": prompt}]
            )
            
            # è§£æå›å¤ï¼Œæå–åºå·
            response_text = response['message']['content'].strip()
            print(f"LLM å›å¤: {response_text}")
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ•°å­—
            numbers = re.findall(r'\d+', response_text)
            selected_indices = [int(num) - 1 for num in numbers if int(num) <= len(videos)]  # è½¬æ¢ä¸º0ç´¢å¼•
            
            # ç¡®ä¿ä¸è¶…è¿‡ç›®æ ‡æ•°é‡
            selected_indices = selected_indices[:target_count]
            
            selected_videos = [videos[i] for i in selected_indices if i < len(videos)]
            
            print(f"âœ… ç­›é€‰å‡º {len(selected_videos)} ä¸ªç›¸å…³è§†é¢‘")
            for video in selected_videos:
                print(f"  - {video['title']}")
            
            return selected_videos
            
        except Exception as e:
            print(f"âŒ LLM ç­›é€‰å¤±è´¥: {e}")
            print("ä½¿ç”¨å¤‡ç”¨ç­›é€‰æ–¹æ³•...")
            # å¤‡ç”¨æ–¹æ³•ï¼šé€‰æ‹©å‰å‡ ä¸ªè§†é¢‘
            return videos[:target_count]

    def download_video_with_subtitles(self, video_info):
        """ä¸‹è½½è§†é¢‘çš„å­—å¹•å’ŒéŸ³é¢‘"""
        video_id = video_info['video_id']
        title = self.clean_filename(video_info['title'])
        
        # ä¸ºæ¯ä¸ªè§†é¢‘åˆ›å»ºå•ç‹¬çš„ç›®å½•
        video_dir = self.downloads_dir / f"{video_id}_{title}"
        video_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ“¥ ä¸‹è½½è§†é¢‘: {title}")
        
        ydl_opts = {
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': ['zh-Hans', 'zh', 'en'],
            'format': 'bestaudio/best',
            'outtmpl': str(video_dir / f'{video_id}_{title}.%(ext)s'),
            'extract_flat': False,
        }
        
        # å¦‚æœ cookies æ–‡ä»¶å­˜åœ¨ï¼Œä½¿ç”¨å®ƒ
        if os.path.exists(self.cookies_file):
            ydl_opts['cookiefile'] = self.cookies_file
            print(f"ä½¿ç”¨ cookies æ–‡ä»¶: {self.cookies_file}")
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([video_info['url']])
            
            print(f"âœ… ä¸‹è½½å®Œæˆ: {title}")
            return video_dir
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥ {title}: {e}")
            return None

    def transcribe_audio(self, video_dir, video_id, title):
        """ä½¿ç”¨ Whisper HTTP æœåŠ¡è½¬å†™éŸ³é¢‘"""
        print(f"ğŸ™ï¸ è½¬å†™éŸ³é¢‘: {title}")
        
        # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶
        audio_files = list(video_dir.glob(f"{video_id}_*.mp3")) + \
                     list(video_dir.glob(f"{video_id}_*.m4a")) + \
                     list(video_dir.glob(f"{video_id}_*.webm"))
        
        if not audio_files:
            print(f"âŒ æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {title}")
            return None
        
        audio_file = audio_files[0]
        
        try:
            import subprocess
            
            # ä½¿ç”¨ curl è°ƒç”¨ whisper HTTP æœåŠ¡ï¼ˆä¸ M4-3 ä¿æŒä¸€è‡´ï¼‰
            print(f"ğŸµ ä½¿ç”¨éŸ³é¢‘æ–‡ä»¶: {audio_file}")
            print("â³ æ­£åœ¨è°ƒç”¨ whisper HTTP æœåŠ¡ ...")
            
            curl_cmd = [
                "curl", "-X", "POST", self.whisper_url,
                "-F", f"audio_file=@{str(audio_file)};type=audio/mpeg",
                "-F", "model_name=large-v3",
                "-F", "language=zh",
                "--connect-timeout", "30",    # è¿æ¥è¶…æ—¶30ç§’
                "--max-time", "900"           # æ€»è¶…æ—¶15åˆ†é’Ÿï¼ˆ900ç§’ï¼‰
            ]
            
            result = subprocess.run(curl_cmd, capture_output=True, check=True)
            response_text = result.stdout.decode("utf-8")
            
            try:
                # è§£æ JSON å“åº”
                response_data = json.loads(response_text)
                
                if response_data.get("success"):
                    # ä¼˜å…ˆä½¿ç”¨ srt_subtitlesï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ full_text
                    if "srt_subtitles" in response_data:
                        srt_content = response_data["srt_subtitles"]
                        # ç®€å•å¤„ç† SRT æ ¼å¼ï¼Œæå–æ–‡æœ¬
                        import re
                        lines = srt_content.splitlines()
                        text_lines = []
                        for line in lines:
                            # è·³è¿‡åºå·å’Œæ—¶é—´è½´
                            if re.match(r"^\d+$", line) or re.match(r"^\d{2}:\d{2}:\d{2},\d{3} --> ", line) or line.strip() == '':
                                continue
                            text_lines.append(line.strip())
                        transcription = ' '.join(text_lines)
                    else:
                        transcription = response_data.get("full_text", "")
                else:
                    print("âŒ Whisper æœåŠ¡è¿”å›é”™è¯¯")
                    return None
                    
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯ JSONï¼Œå°è¯•ç›´æ¥ä½œä¸º SRT å¤„ç†ï¼ˆå‘åå…¼å®¹ï¼‰
                print("âš ï¸ å“åº”ä¸æ˜¯ JSON æ ¼å¼ï¼Œå°è¯•ç›´æ¥è§£æä¸º SRT")
                import re
                lines = response_text.splitlines()
                text_lines = []
                for line in lines:
                    if re.match(r"^\d+$", line) or re.match(r"^\d{2}:\d{2}:\d{2},\d{3} --> ", line) or line.strip() == '':
                        continue
                    text_lines.append(line.strip())
                transcription = ' '.join(text_lines)
            
            if transcription:
                # ä¿å­˜è½¬å†™ç»“æœ
                transcription_file = video_dir / f"{video_id}_transcription.txt"
                with open(transcription_file, 'w', encoding='utf-8') as f:
                    f.write("=== éŸ³é¢‘è½¬å†™æ–‡æœ¬ ===\n")
                    f.write(f"éŸ³é¢‘æ–‡ä»¶: {audio_file.name}\n")
                    f.write("=" * 50 + "\n")
                    f.write(transcription)
                
                print(f"âœ… è½¬å†™å®Œæˆ: {title}")
                print(f"ğŸ’¾ è½¬å†™æ–‡æœ¬å·²ä¿å­˜åˆ°: {transcription_file}")
                return transcription
            else:
                print(f"âŒ è½¬å†™ç»“æœä¸ºç©º: {title}")
                return None
                
        except subprocess.CalledProcessError as e:
            error_msg = e.stderr.decode('utf-8') if e.stderr else ''
            if 'timed out' in error_msg or 'timeout' in error_msg.lower():
                print("â° Whisper è½¬å†™è¶…æ—¶ï¼ˆ15åˆ†é’Ÿï¼‰")
                print("ğŸ’¡ å»ºè®®ï¼šæ­¤éŸ³é¢‘å¯èƒ½è¾ƒé•¿ï¼Œå¯ä»¥ç¨åæ‰‹åŠ¨é‡è¯•")
            else:
                print("âŒ Whisper HTTP è½¬å†™å¤±è´¥")
                print(f"é”™è¯¯è¾“å‡º: {error_msg}")
                print(f"æ ‡å‡†è¾“å‡º: {e.stdout.decode('utf-8') if e.stdout else 'æ— '}")
            return None
        except Exception as e:
            print(f"âŒ è½¬å†™å¤±è´¥ {title}: {e}")
            return None
            return None

    def extract_text_from_subtitle(self, video_dir, video_id):
        """ä»å­—å¹•æ–‡ä»¶æå–æ–‡æœ¬"""
        # æŸ¥æ‰¾å­—å¹•æ–‡ä»¶
        subtitle_files = list(video_dir.glob(f"{video_id}_*.vtt")) + \
                        list(video_dir.glob(f"{video_id}_*.srt"))
        
        if not subtitle_files:
            return None
        
        subtitle_file = subtitle_files[0]
        
        try:
            with open(subtitle_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–å­—å¹•æ–‡æœ¬ï¼ˆç§»é™¤æ—¶é—´æˆ³ç­‰ï¼‰
            lines = content.split('\n')
            text_lines = []
            
            for line in lines:
                line = line.strip()
                # è·³è¿‡æ—¶é—´æˆ³è¡Œå’Œç©ºè¡Œ
                if line and not re.match(r'^\d+$', line) and not re.match(r'^\d{2}:\d{2}:\d{2}', line) and line != 'WEBVTT':
                    text_lines.append(line)
            
            subtitle_text = '\n'.join(text_lines)
            
            # ä¿å­˜æå–çš„å­—å¹•æ–‡æœ¬
            if subtitle_text:
                subtitle_text_file = video_dir / f"{video_id}_subtitle_text.txt"
                with open(subtitle_text_file, 'w', encoding='utf-8') as f:
                    f.write(subtitle_text)
                return subtitle_text
            
        except Exception as e:
            print(f"å­—å¹•æ–‡æœ¬æå–å¤±è´¥: {e}")
            
        return None

    def summarize_content(self, content, title):
        """ä½¿ç”¨ LLM å¯¹å†…å®¹è¿›è¡Œæ€»ç»“"""
        print(f"ğŸ“ ç”Ÿæˆæ‘˜è¦: {title}")
        
        prompt = f"""
è¯·å¯¹ä»¥ä¸‹è§†é¢‘å†…å®¹è¿›è¡Œè¯¦ç»†æ€»ç»“ã€‚è§†é¢‘æ ‡é¢˜ï¼š{title}

æ€»ç»“è¦æ±‚ï¼š
1. æå–ä¸»è¦è§‚ç‚¹å’Œè®ºè¿°
2. è®°å½•é‡è¦çš„ç»†èŠ‚å’Œæ•°æ®
3. è¯†åˆ«ç‹¬ç‰¹çš„è§è§£å’Œåˆ†æè§’åº¦
4. ä¿ç•™æœ‰ä»·å€¼çš„äº‰è®®ç‚¹å’Œè®¨è®ºç‚¹
5. æ•´ç†å¯ç”¨äºå†…å®¹åˆ›ä½œçš„ç´ æ

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

## ä¸»è¦è§‚ç‚¹
- [æ ¸å¿ƒè§‚ç‚¹1]
- [æ ¸å¿ƒè§‚ç‚¹2]
...

## é‡è¦ç»†èŠ‚
- [ç»†èŠ‚1]
- [ç»†èŠ‚2]
...

## ç‹¬ç‰¹è§è§£
- [è§è§£1]
- [è§è§£2]
...

## äº‰è®®è®¨è®ºç‚¹
- [äº‰è®®ç‚¹1]
- [äº‰è®®ç‚¹2]
...

## å…¶ä»–æœ‰ä»·å€¼ä¿¡æ¯
- [ä¿¡æ¯1]
- [ä¿¡æ¯2]
...

è§†é¢‘å†…å®¹ï¼š
{content}
"""

        try:
            response = self.ollama.chat(
                model='qwen3:32b',
                messages=[{"role": "user", "content": prompt}]
            )
            
            summary = response['message']['content']
            print(f"âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆ: {title}")
            return summary
            
        except Exception as e:
            print(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥ {title}: {e}")
            return None

    def save_summary(self, summary, video_dir, video_id, title):
        """ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶"""
        if summary:
            summary_file = video_dir / f"{video_id}_summary.txt"
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(f"è§†é¢‘æ ‡é¢˜: {title}\n")
                f.write("=" * 50 + "\n")
                f.write(summary)
            print(f"ğŸ’¾ æ‘˜è¦å·²ä¿å­˜: {summary_file}")

    def create_final_summary(self, keyword, processed_videos):
        """åˆ›å»ºæœ€ç»ˆçš„ç»¼åˆæ€»ç»“ - ä¸“ä¸ºYouTubeå†…å®¹åˆ›ä½œä¼˜åŒ–"""
        print(f"ğŸ“š ç”Ÿæˆæœ€ç»ˆç»¼åˆæ€»ç»“...")
        
        # æ”¶é›†æ‰€æœ‰æ‘˜è¦
        all_summaries = []
        sources_info = []
        
        for i, (video_info, video_dir) in enumerate(processed_videos, 1):
            if video_dir:
                summary_file = video_dir / f"{video_info['video_id']}_summary.txt"
                if summary_file.exists():
                    with open(summary_file, 'r', encoding='utf-8') as f:
                        summary_content = f.read()
                        all_summaries.append(f"=== è§†é¢‘{i} ===\n{summary_content}")
                        
                        # æ”¶é›†æ¥æºä¿¡æ¯
                        sources_info.append({
                            'index': i,
                            'title': video_info['title'],
                            'video_id': video_info['video_id'],
                            'url': video_info['url'],
                            'view_count': video_info.get('view_count', 'æœªçŸ¥')
                        })
        
        if not all_summaries:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ‘˜è¦æ–‡ä»¶")
            return
        
        # ç”Ÿæˆæ¥æºè§†é¢‘åˆ—è¡¨
        sources_text = f"## ğŸ“¹ æ¥æºè§†é¢‘åˆ—è¡¨\n\n"
        for source in sources_info:
            sources_text += f"**è§†é¢‘{source['index']}**: {source['title']}\n"
            sources_text += f"- è§†é¢‘ID: {source['video_id']}\n"
            sources_text += f"- æ’­æ”¾é‡: {source['view_count']}\n"
            sources_text += f"- é“¾æ¥: {source['url']}\n\n"
        
        sources_text += "\n" + "="*50 + "\n\n"
        
        # åˆå¹¶æ‰€æœ‰æ‘˜è¦
        combined_text = sources_text + "\n" + "="*50 + "\n\n".join(all_summaries)
        
        # é’ˆå¯¹å†…å®¹åˆ›ä½œä¼˜åŒ–çš„æç¤ºè¯
        final_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„YouTubeå†…å®¹ç­–åˆ’å¸ˆï¼Œè¯·ä»ä»¥ä¸‹å…³äº"{keyword}"çš„å¤šä¸ªè§†é¢‘æ€»ç»“ä¸­ï¼Œæå–æ‰€æœ‰å¯ç”¨äºå†…å®¹åˆ›ä½œçš„è§‚ç‚¹ã€è§è§£å’Œç´ æã€‚

æ ¸å¿ƒç›®æ ‡ï¼šä¸ºYouTubeåˆ›ä½œè€…æä¾›å®Œæ•´çš„è§‚ç‚¹åº“å’Œåˆ›ä½œç´ æï¼Œå¸®åŠ©åˆ¶ä½œæœ‰æ·±åº¦çš„åŸåˆ›å†…å®¹ã€‚

ä»»åŠ¡è¦æ±‚ï¼š
- æå–æ‰€æœ‰ç‹¬ç‰¹è§‚ç‚¹ï¼Œä¸è¦é—æ¼ä»»ä½•æœ‰ä»·å€¼çš„è§è§£
- æ¯ä¸ªè§‚ç‚¹å¿…é¡»æ ‡æ³¨æ¥æºè§†é¢‘åºå·ï¼Œå¦‚ (æ¥æºï¼šè§†é¢‘1)ã€(æ¥æºï¼šè§†é¢‘3,5)
- è¯†åˆ«äº‰è®®æ€§è§‚ç‚¹ï¼Œè¿™äº›æ˜¯å¼•å‘è®¨è®ºçš„ç»ä½³ç´ æ
- æå–å…·ä½“çš„ç»†èŠ‚ã€æ•°æ®ã€æ¡ˆä¾‹ï¼Œå¢å¼ºå†…å®¹è¯´æœåŠ›
- æŒ–æ˜å¯ä»¥å»¶ä¼¸è®¨è®ºçš„è¯é¢˜ç‚¹

è¾“å‡ºæ ¼å¼ï¼š

## ğŸ¬ **ä¸»æµè§‚ç‚¹ä¸å…±è¯†**
ï¼ˆå¤§éƒ¨åˆ†è§†é¢‘è®¤åŒçš„è§‚ç‚¹ï¼Œé€‚åˆä½œä¸ºè§†é¢‘åŸºè°ƒï¼‰
- [å…·ä½“è§‚ç‚¹æè¿°] (æ¥æºï¼šè§†é¢‘X)
- [å…·ä½“è§‚ç‚¹æè¿°] (æ¥æºï¼šè§†é¢‘X,Y)

## âš¡ **äº‰è®®è§‚ç‚¹ä¸åˆ†æ­§**
ï¼ˆæœ‰äº‰è®®çš„è¯é¢˜ï¼Œé€‚åˆåˆ¶ä½œè®¨è®ºç±»å†…å®¹ï¼‰
- [äº‰è®®ç‚¹]ï¼šæ­£æ–¹è§‚ç‚¹ vs åæ–¹è§‚ç‚¹ (æ¥æºï¼šè§†é¢‘X vs è§†é¢‘Y)
- [äº‰è®®ç‚¹]ï¼š[å…·ä½“äº‰è®®å†…å®¹] (æ¥æºï¼šè§†é¢‘X)

## ğŸ’ **ç‹¬ç‰¹è§è§£ä¸æ·±åº¦åˆ†æ**
ï¼ˆåˆ«äººæ²¡è¯´è¿‡çš„è§‚ç‚¹ï¼Œé€‚åˆä½œä¸ºè§†é¢‘äº®ç‚¹ï¼‰
- [ç‹¬ç‰¹è§‚ç‚¹æˆ–æ·±åº¦åˆ†æ] (æ¥æºï¼šè§†é¢‘X)

## ğŸ” **å…³é”®ç»†èŠ‚ä¸æ•°æ®**
ï¼ˆå…·ä½“çš„äº‹å®ã€æ•°æ®ã€æ¡ˆä¾‹ï¼Œå¢å¼ºå†…å®¹å¯ä¿¡åº¦ï¼‰
- [å…·ä½“ç»†èŠ‚/æ•°æ®/æ¡ˆä¾‹] (æ¥æºï¼šè§†é¢‘X)

## ğŸ¯ **å»¶ä¼¸è¯é¢˜æœºä¼š**
ï¼ˆåŸºäºæ”¶é›†çš„è§‚ç‚¹ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ¢è®¨çš„æ–¹å‘ï¼‰
- è¯é¢˜ï¼š[åŸºäºXXè§‚ç‚¹çš„å»¶ä¼¸è®¨è®ºæ–¹å‘] (ç´ ææ¥æºï¼šè§†é¢‘X)

## ğŸ“º **åˆ›ä½œå»ºè®®**
1. **æ¨èè§†é¢‘è§’åº¦**ï¼š[åŸºäºè§‚ç‚¹åˆ†æçš„åˆ›ä½œå»ºè®®]
2. **é¿å…é›·åŒº**ï¼š[éœ€è¦è°¨æ…å¤„ç†çš„æ•æ„Ÿè¯é¢˜]
3. **äº®ç‚¹ç´ æ**ï¼š[æœ€æœ‰å¸å¼•åŠ›çš„è®¨è®ºç‚¹]

è§†é¢‘æ€»ç»“å†…å®¹ï¼š
â€”â€”â€”
{combined_text}
â€”â€”â€”
/no_think
        """
        
        try:
            response = self.ollama.chat(
                model='qwen3:32b',
                messages=[{"role": "user", "content": final_prompt}]
            )
            
            final_summary = response['message']['content']
            
            # ä¿å­˜æœ€ç»ˆæ€»ç»“ï¼ˆåŒ…å«æ¥æºä¿¡æ¯ï¼‰
            final_file = self.summaries_dir / f"final_summary_{keyword}.txt"
            with open(final_file, 'w', encoding='utf-8') as f:
                f.write(f"å…³é”®è¯: {keyword}\n")
                f.write("=" * 50 + "\n")
                
                # å…ˆå†™å…¥æ¥æºè§†é¢‘åˆ—è¡¨
                f.write(sources_text)
                f.write("\n")
                
                # å†™å…¥æœ€ç»ˆæ€»ç»“
                f.write("## ğŸ¯ **YouTubeå†…å®¹åˆ›ä½œç´ æåº“**\n\n")
                f.write(final_summary)
            
            print(f"âœ… æœ€ç»ˆæ€»ç»“å·²ä¿å­˜: {final_file}")
            print(f"ğŸ“‹ åŒ…å« {len(sources_info)} ä¸ªæ¥æºè§†é¢‘çš„è§‚ç‚¹åˆ†æ")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæœ€ç»ˆæ€»ç»“å¤±è´¥: {e}")

    async def process_videos(self, keyword, max_videos=20, target_videos=8):
        """å¤„ç†è§†é¢‘çš„å®Œæ•´æµç¨‹"""
        print(f"ğŸš€ å¼€å§‹å¤„ç†å…³é”®è¯: {keyword}")
        
        # 1. æœç´¢è§†é¢‘
        videos = await self.search_youtube_videos(keyword, max_videos)
        if not videos:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°è§†é¢‘")
            return
        
        # 2. LLM ç­›é€‰
        selected_videos = self.filter_videos_with_llm(videos, keyword, target_videos)
        if not selected_videos:
            print("âŒ æ²¡æœ‰ç­›é€‰å‡ºåˆé€‚çš„è§†é¢‘")
            return
        
        print(f"\nğŸ“¥ å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(selected_videos)} ä¸ªè§†é¢‘...")
        
        # 3. æ‰¹é‡ä¸‹è½½
        downloaded_videos = []
        for i, video_info in enumerate(selected_videos, 1):
            print(f"\n--- ä¸‹è½½è¿›åº¦: {i}/{len(selected_videos)} ---")
            try:
                video_dir = self.download_video_with_subtitles(video_info)
                downloaded_videos.append((video_info, video_dir))
            except Exception as e:
                print(f"âŒ ä¸‹è½½è§†é¢‘å¤±è´¥: {video_info['title']}: {e}")
                downloaded_videos.append((video_info, None))
        
        print(f"\nğŸ™ï¸ å¼€å§‹æ‰¹é‡è½¬å†™å’Œæ‘˜è¦...")
        
        # 4. æ‰¹é‡è½¬å†™å’Œæ‘˜è¦
        processed_videos = []
        for i, (video_info, video_dir) in enumerate(downloaded_videos, 1):
            if video_dir is None:
                print(f"è·³è¿‡å¤±è´¥çš„è§†é¢‘: {video_info['title']}")
                processed_videos.append((video_info, None))
                continue
                
            print(f"\n--- å¤„ç†è¿›åº¦: {i}/{len(downloaded_videos)} ---")
            
            try:
                video_id = video_info['video_id']
                title = video_info['title']
                
                # è·å–æ–‡æœ¬å†…å®¹ï¼ˆå­—å¹•ä¼˜å…ˆï¼Œç„¶åè½¬å†™ï¼‰
                content = self.extract_text_from_subtitle(video_dir, video_id)
                if not content:
                    content = self.transcribe_audio(video_dir, video_id, title)
                
                if content:
                    # ç”Ÿæˆæ‘˜è¦
                    summary = self.summarize_content(content, title)
                    self.save_summary(summary, video_dir, video_id, title)
                    processed_videos.append((video_info, video_dir))
                else:
                    print(f"âŒ æ— æ³•è·å–è§†é¢‘å†…å®¹: {title}")
                    processed_videos.append((video_info, None))
                    
            except Exception as e:
                print(f"âŒ å¤„ç†è§†é¢‘å¤±è´¥: {video_info['title']}: {e}")
                processed_videos.append((video_info, None))
        
        # 5. ç”Ÿæˆæœ€ç»ˆç»¼åˆæ€»ç»“
        self.create_final_summary(keyword, processed_videos)
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼å…³é”®è¯: {keyword}")
        print(f"ğŸ“Š æ€»è§†é¢‘æ•°: {len(selected_videos)}")
        print(f"ğŸ“¥ æˆåŠŸä¸‹è½½: {len([v for v in processed_videos if v[1] is not None])}")
        print(f"ğŸ“ å·²ç”Ÿæˆæ‘˜è¦å’Œæœ€ç»ˆæ€»ç»“")


async def main():
    """ä¸»å‡½æ•°"""
    analyzer = YouTubeAnalyzer()
    
    # å¯ä»¥æ‰¹é‡å¤„ç†å¤šä¸ªå…³é”®è¯
    keywords = ["é±¿é±¼æ¸¸æˆ3"]  # å¯ä»¥æ·»åŠ æ›´å¤šå…³é”®è¯
    
    for keyword in keywords:
        try:
            await analyzer.process_videos(
                keyword=keyword,
                max_videos=25,   # æœç´¢æ›´å¤šè§†é¢‘
                target_videos=8  # ç­›é€‰å‡º8ä¸ªæœ€ç›¸å…³çš„
            )
            print(f"âœ… å…³é”®è¯ '{keyword}' å¤„ç†å®Œæˆ\n")
        except Exception as e:
            print(f"âŒ å¤„ç†å…³é”®è¯ '{keyword}' æ—¶å‡ºé”™: {e}\n")


if __name__ == "__main__":
    asyncio.run(main())
