import asyncio
import json
import os
import re
import subprocess
import yt_dlp
from pathlib import Path
from typing import List, Dict, Optional

# æ£€æŸ¥å¹¶å®‰è£… crawl4ai
try:
    from crawl4ai import AsyncWebCrawler
except ImportError:
    import sys, subprocess
    print("ğŸ“¦ æ­£åœ¨å®‰è£… crawl4ai...")
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'crawl4ai'])
    from crawl4ai import AsyncWebCrawler

class YouTubeVideoAnalyzer:
    def __init__(self, download_dir="downloads", summaries_dir="summaries"):
        self.download_dir = Path(download_dir)
        self.summaries_dir = Path(summaries_dir)
        self.download_dir.mkdir(exist_ok=True)
        self.summaries_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ– ollama
        try:
            import ollama
            self.ollama = ollama
        except ImportError:
            import sys, subprocess
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'ollama'])
            import ollama
            self.ollama = ollama
    
    def get_parent_cookies(self):
        """è·å– cookies æ–‡ä»¶è·¯å¾„"""
        return os.path.join(os.path.dirname(os.path.dirname(__file__)), 'cookies.txt')

    async def search_youtube_videos(self, keyword: str, max_videos: int = 100) -> List[Dict]:
        """æœç´¢ YouTube è§†é¢‘å¹¶è§£æç»“æœ"""
        search_url = f"https://www.youtube.com/results?search_query={keyword}"
        
        async with AsyncWebCrawler() as crawler:
            # ä½¿ç”¨ JavaScript æ¥æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹
            js_code = """
            async function loadMoreVideos() {
                let videos = [];
                let lastHeight = 0;
                let scrollAttempts = 0;
                const maxScrolls = 10; // æœ€å¤šæ»šåŠ¨10æ¬¡
                
                while (scrollAttempts < maxScrolls) {
                    // æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
                    window.scrollTo(0, document.body.scrollHeight);
                    
                    // ç­‰å¾…å†…å®¹åŠ è½½
                    await new Promise(resolve => setTimeout(resolve, 2000));
                    
                    let newHeight = document.body.scrollHeight;
                    
                    // å¦‚æœé¡µé¢é«˜åº¦æ²¡æœ‰å˜åŒ–ï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šå†…å®¹äº†
                    if (newHeight === lastHeight) {
                        scrollAttempts++;
                    } else {
                        scrollAttempts = 0; // é‡ç½®è®¡æ•°
                    }
                    
                    lastHeight = newHeight;
                    
                    // æ£€æŸ¥å½“å‰é¡µé¢çš„è§†é¢‘æ•°é‡
                    const videoElements = document.querySelectorAll('ytd-video-renderer, ytd-compact-video-renderer');
                    if (videoElements.length >= 80) { // è·å–è¶³å¤Ÿçš„è§†é¢‘å°±åœæ­¢
                        break;
                    }
                }
                
                return document.documentElement.outerHTML;
            }
            
            return await loadMoreVideos();
            """
            
            result = await crawler.arun(
                url=search_url,
                js_code=js_code,
                wait_for="css:ytd-video-renderer"
            )
            html_content = result.html
        
        # è§£æè§†é¢‘ä¿¡æ¯
        videos = self._parse_video_info(html_content)
        
        print(f"ä»æœç´¢ç»“æœä¸­è§£æåˆ° {len(videos)} ä¸ªè§†é¢‘")
        
        # è¿”å›æ‰€æœ‰è§£æåˆ°çš„è§†é¢‘ï¼Œä¸åœ¨è¿™é‡Œè¿‡æ»¤
        return videos[:max_videos]  # æœ€å¤šè¿”å›æŒ‡å®šæ•°é‡

    def _parse_video_info(self, html_content: str) -> List[Dict]:
        """ä» HTML ä¸­è§£æè§†é¢‘ä¿¡æ¯"""
        videos = []
        
        # å¤šç§æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼æ¥æå–è§†é¢‘ä¿¡æ¯
        patterns = [
            # æ¨¡å¼1: æ ‡å‡†çš„æœç´¢ç»“æœæ ¼å¼
            r'"videoId":"([^"]+)".*?"title":{"runs":\[{"text":"([^"]+)"}.*?"viewCountText":{"simpleText":"([^"]+)"}',
            # æ¨¡å¼2: å¦ä¸€ç§å¯èƒ½çš„æ ¼å¼
            r'"videoId":"([^"]+)".*?"title":{"accessibility":{"accessibilityData":{"label":"([^"]+)"}}.*?"viewCountText":{"simpleText":"([^"]+)"}',
            # æ¨¡å¼3: ç®€åŒ–æ¨¡å¼
            r'"videoId":"([^"]+)".*?"text":"([^"]+)".*?"viewCountText".*?"simpleText":"([^"]+)"',
        ]
        
        # å°è¯•æ‰€æœ‰æ¨¡å¼
        all_matches = []
        for pattern in patterns:
            matches = re.findall(pattern, html_content, re.DOTALL)
            all_matches.extend(matches)
        
        # å»é‡å¤„ç†
        seen_video_ids = set()
        for match in all_matches:
            if len(match) >= 3:
                video_id, title, view_text = match[0], match[1], match[2]
                
                # å»é‡
                if video_id in seen_video_ids:
                    continue
                seen_video_ids.add(video_id)
                
                # æ¸…ç†æ ‡é¢˜ä¸­å¯èƒ½çš„HTMLæ ‡ç­¾å’Œç‰¹æ®Šå­—ç¬¦
                title = re.sub(r'<[^>]+>', '', title)
                title = title.replace('&quot;', '"').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
                
                view_count = self._parse_view_count(view_text)
                
                video_info = {
                    'video_id': video_id,
                    'title': title,
                    'url': f'https://www.youtube.com/watch?v={video_id}',
                    'view_count': view_count,
                    'view_text': view_text
                }
                videos.append(video_info)
        
        # å¦‚æœæ­£åˆ™è¡¨è¾¾å¼å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(videos) < 10:
            print("âš ï¸ æ­£åˆ™è¡¨è¾¾å¼è§£æç»“æœè¾ƒå°‘ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
            backup_videos = self._parse_video_info_backup(html_content)
            videos.extend(backup_videos)
            
            # å†æ¬¡å»é‡
            unique_videos = {}
            for video in videos:
                if video['video_id'] not in unique_videos:
                    unique_videos[video['video_id']] = video
            videos = list(unique_videos.values())
        
        return videos
    
    def _parse_video_info_backup(self, html_content: str) -> List[Dict]:
        """å¤‡ç”¨çš„è§†é¢‘ä¿¡æ¯è§£ææ–¹æ³•"""
        videos = []
        
        # æŸ¥æ‰¾æ‰€æœ‰çš„videoId
        video_ids = re.findall(r'"videoId":"([^"]+)"', html_content)
        
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ ‡é¢˜
        titles = re.findall(r'"title":{"runs":\[{"text":"([^"]+)"}', html_content)
        titles.extend(re.findall(r'"text":"([^"]+(?:é±¿é±¼æ¸¸æˆ|squid game)[^"]*)"', html_content, re.IGNORECASE))
        
        # æŸ¥æ‰¾è§‚çœ‹æ¬¡æ•°
        view_counts = re.findall(r'"viewCountText":{"simpleText":"([^"]+)"}', html_content)
        
        # å°è¯•åŒ¹é…
        min_length = min(len(video_ids), len(titles), len(view_counts))
        for i in range(min_length):
            video_info = {
                'video_id': video_ids[i],
                'title': titles[i],
                'url': f'https://www.youtube.com/watch?v={video_ids[i]}',
                'view_count': self._parse_view_count(view_counts[i]),
                'view_text': view_counts[i]
            }
            videos.append(video_info)
        
        return videos

    def _parse_view_count(self, view_text: str) -> int:
        """è§£æè§‚çœ‹æ¬¡æ•°æ–‡æœ¬ä¸ºæ•°å­—"""
        # ç§»é™¤é€—å·å’Œç©ºæ ¼
        view_text = view_text.replace(',', '').replace(' ', '').lower()
        
        # æå–æ•°å­—
        number_match = re.search(r'(\d+(?:\.\d+)?)', view_text)
        if not number_match:
            return 0
        
        number = float(number_match.group(1))
        
        # å¤„ç†å•ä½ (ä¸‡, k, m, ç­‰)
        if 'ä¸‡' in view_text:
            number *= 10000
        elif 'k' in view_text:
            number *= 1000
        elif 'm' in view_text:
            number *= 1000000
        elif 'b' in view_text:
            number *= 1000000000
        
        return int(number)

    def download_video_info(self, video_url: str) -> Dict:
        """ä½¿ç”¨ yt-dlp è·å–è§†é¢‘ä¿¡æ¯"""
        ydl_opts = {
            'cookiefile': self.get_parent_cookies(),
            'quiet': True,
            'no_warnings': False,
            'extract_flat': False,
            'extractor_args': {
                'youtube': {
                    'player_client': ['tv_embedded', 'web'],
                }
            }
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            try:
                info = ydl.extract_info(video_url, download=False)
                return info
            except Exception as e:
                print(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
                return {}

    def download_video_with_subtitles(self, video_url: str, video_id: str, video_title: str = "") -> Dict:
        """ä¸‹è½½è§†é¢‘å’Œå­—å¹•"""
        # åˆ›å»ºä»¥è§†é¢‘æ ‡é¢˜å‘½åçš„ç›®å½•
        safe_title = self._clean_filename(video_title) if video_title else video_id
        output_path = self.download_dir / f"{video_id}_{safe_title}"
        output_path.mkdir(exist_ok=True)
        
        # å°è¯•ä¸‹è½½å­—å¹•
        subtitle_opts = {
            'cookiefile': self.get_parent_cookies(),
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': ['zh-Hans', 'zh', 'en'],
            'subtitlesformat': 'srt',
            'skip_download': True,
            'outtmpl': str(output_path / '%(title)s.%(ext)s'),
            'extractor_args': {
                'youtube': {
                    'player_client': ['tv_embedded', 'web'],
                }
            }
        }
        
        subtitle_downloaded = False
        subtitle_file = None
        
        with yt_dlp.YoutubeDL(subtitle_opts) as ydl:
            try:
                ydl.download([video_url])
                # æŸ¥æ‰¾ä¸‹è½½çš„å­—å¹•æ–‡ä»¶ (SRT æˆ– VTT)
                for ext in ['*.srt', '*.vtt']:
                    for file in output_path.glob(ext):
                        subtitle_file = file
                        subtitle_downloaded = True
                        break
                    if subtitle_downloaded:
                        break
            except Exception as e:
                print(f"ä¸‹è½½å­—å¹•å¤±è´¥: {e}")
        
        # å¦‚æœæ²¡æœ‰å­—å¹•ï¼Œä¸‹è½½éŸ³é¢‘
        audio_file = None
        if not subtitle_downloaded:
            audio_opts = {
                'cookiefile': self.get_parent_cookies(),
                'format': 'bestaudio/best',
                'outtmpl': str(output_path / '%(title)s.%(ext)s'),
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'mp3',
                    'preferredquality': '192',
                }],
                'extractor_args': {
                    'youtube': {
                        'player_client': ['tv_embedded', 'web'],
                    }
                }
            }
            
            with yt_dlp.YoutubeDL(audio_opts) as ydl:
                try:
                    ydl.download([video_url])
                    # æŸ¥æ‰¾ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶
                    for file in output_path.glob("*.mp3"):
                        audio_file = file
                        break
                except Exception as e:
                    print(f"ä¸‹è½½éŸ³é¢‘å¤±è´¥: {e}")
        
        return {
            'subtitle_file': subtitle_file,
            'audio_file': audio_file,
            'subtitle_downloaded': subtitle_downloaded,
            'output_path': output_path  # è¿”å›è¾“å‡ºç›®å½•è·¯å¾„
        }

    def extract_text_from_subtitle(self, subtitle_file: Path) -> str:
        """ä»å­—å¹•æ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
        try:
            with open(subtitle_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åˆ¤æ–­æ˜¯ VTT è¿˜æ˜¯ SRT æ ¼å¼
            if subtitle_file.suffix.lower() == '.srt':
                text_content = self._srt_to_text(content)
            else:
                text_content = self._vtt_to_text(content)
            
            # ä¿å­˜æå–çš„å­—å¹•æ–‡æœ¬åˆ°è§†é¢‘ç›®å½•
            subtitle_text_file = subtitle_file.parent / "subtitle_text.txt"
            with open(subtitle_text_file, 'w', encoding='utf-8') as f:
                f.write("=== å­—å¹•æ–‡æœ¬ ===\n")
                f.write(f"å­—å¹•æ–‡ä»¶: {subtitle_file.name}\n")
                f.write("=" * 50 + "\n")
                f.write(text_content)
            print(f"ğŸ’¾ å­—å¹•æ–‡æœ¬å·²ä¿å­˜åˆ°: {subtitle_text_file}")
            
            return text_content
                
        except Exception as e:
            print(f"æå–å­—å¹•æ–‡æœ¬å¤±è´¥: {e}")
            return ""
    
    def _srt_to_text(self, srt_content: str) -> str:
        """å¤„ç† SRT æ ¼å¼å­—å¹•"""
        import re
        lines = srt_content.splitlines()
        text_lines = []
        for line in lines:
            # è·³è¿‡åºå·å’Œæ—¶é—´è½´
            if re.match(r"^\d+$", line):
                continue
            if re.match(r"^\d{2}:\d{2}:\d{2},\d{3} --> ", line):
                continue
            if line.strip() == '':
                continue
            text_lines.append(line.strip())
        # åˆå¹¶ä¸ºæ®µè½ï¼Œå»é‡ç›¸é‚»é‡å¤
        from itertools import groupby
        merged = [k for k, _ in groupby(text_lines)]
        return ' '.join(merged)
    
    def _vtt_to_text(self, vtt_content: str) -> str:
        """å¤„ç† VTT æ ¼å¼å­—å¹•"""
        lines = vtt_content.split('\n')
        text_lines = []
        
        for line in lines:
            line = line.strip()
            # è·³è¿‡æ—¶é—´æˆ³è¡Œå’Œç©ºè¡Œ
            if not line or '-->' in line or line.startswith('WEBVTT') or line.isdigit():
                continue
            # ç§»é™¤ HTML æ ‡ç­¾
            line = re.sub(r'<[^>]+>', '', line)
            if line:
                text_lines.append(line)
        
        return ' '.join(text_lines)

    def transcribe_audio(self, audio_file: Path) -> str:
        """ä½¿ç”¨æœ¬åœ° whisper HTTP æœåŠ¡è½¬å½•éŸ³é¢‘"""
        try:
            # ç›´æ¥ä½¿ç”¨ MP3 æ–‡ä»¶ï¼Œä¸éœ€è¦è½¬æ¢ä¸º WAV
            print(f"ï¿½ ä½¿ç”¨éŸ³é¢‘æ–‡ä»¶: {audio_file}")

            # è°ƒç”¨ whisper HTTP æ¥å£ï¼Œç›´æ¥ä½¿ç”¨ MP3
            print("â³ æ­£åœ¨è°ƒç”¨ whisper HTTP æœåŠ¡ ...")
            curl_cmd = [
                "curl", "-X", "POST", "http://127.0.0.1:8080/transcribe/",
                "-F", f"audio_file=@{str(audio_file)};type=audio/mpeg",
                "-F", "model_name=large-v3",
                "-F", "language=zh",
                "--connect-timeout", "30",    # è¿æ¥è¶…æ—¶30ç§’
                "--max-time", "900"           # æ€»è¶…æ—¶15åˆ†é’Ÿï¼ˆ900ç§’ï¼‰
            ]
            
            result = subprocess.run(curl_cmd, capture_output=True, check=True)
            # Whisper HTTP æœåŠ¡è¿”å› JSON æ ¼å¼
            response_text = result.stdout.decode("utf-8")
            
            try:
                # è§£æ JSON å“åº”
                response_data = json.loads(response_text)
                
                if response_data.get("success"):
                    # ä¼˜å…ˆä½¿ç”¨ srt_subtitlesï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ full_text
                    if "srt_subtitles" in response_data:
                        srt_content = response_data["srt_subtitles"]
                        transcribed_text = self._srt_to_text(srt_content)
                    else:
                        transcribed_text = response_data.get("full_text", "")
                else:
                    print("âŒ Whisper æœåŠ¡è¿”å›é”™è¯¯")
                    return ""
                    
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯ JSONï¼Œå°è¯•ç›´æ¥ä½œä¸º SRT å¤„ç†ï¼ˆå‘åå…¼å®¹ï¼‰
                print("âš ï¸ å“åº”ä¸æ˜¯ JSON æ ¼å¼ï¼Œå°è¯•ç›´æ¥è§£æä¸º SRT")
                transcribed_text = self._srt_to_text(response_text)
            
            # ä¿å­˜è½¬å†™æ–‡æœ¬åˆ°è§†é¢‘ç›®å½•
            transcript_file = audio_file.parent / "transcript.txt"
            with open(transcript_file, 'w', encoding='utf-8') as f:
                f.write("=== éŸ³é¢‘è½¬å†™æ–‡æœ¬ ===\n")
                f.write(f"éŸ³é¢‘æ–‡ä»¶: {audio_file.name}\n")
                f.write("=" * 50 + "\n")
                f.write(transcribed_text)
            print(f"ğŸ’¾ è½¬å†™æ–‡æœ¬å·²ä¿å­˜åˆ°: {transcript_file}")
            
            return transcribed_text
            
        except subprocess.CalledProcessError as e:
            error_msg = e.stderr.decode('utf-8') if e.stderr else ''
            if 'timed out' in error_msg or 'timeout' in error_msg.lower():
                print("â° Whisper è½¬å†™è¶…æ—¶ï¼ˆ15åˆ†é’Ÿï¼‰")
                print("ğŸ’¡ å»ºè®®ï¼šæ­¤éŸ³é¢‘å¯èƒ½è¾ƒé•¿ï¼Œå¯ä»¥ç¨åæ‰‹åŠ¨é‡è¯•")
            else:
                print("âŒ Whisper HTTP è½¬å†™å¤±è´¥")
                print(f"é”™è¯¯è¾“å‡º: {error_msg}")
                print(f"æ ‡å‡†è¾“å‡º: {e.stdout.decode('utf-8') if e.stdout else 'æ— '}")
            return ""
        except Exception as e:
            print(f"éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
            return ""

    def summarize_text(self, text: str, video_title: str) -> str:
        """ä½¿ç”¨ ollama qwen3:32b æ€»ç»“æ–‡æœ¬"""
        prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æå¸ˆï¼Œè¯·å¯¹ä¸‹åˆ—è§†é¢‘å†…å®¹è¿›è¡Œè¯¦ç»†æ€»ç»“ã€‚

è§†é¢‘æ ‡é¢˜ï¼š{video_title}

æ€»ç»“è¦æ±‚ï¼š
1. æå–ä¸»è¦è§‚ç‚¹å’Œè®ºè¿°
2. è®°å½•é‡è¦çš„ç»†èŠ‚å’Œæ•°æ®  
3. è¯†åˆ«ç‹¬ç‰¹çš„è§è§£å’Œåˆ†æè§’åº¦
4. ä¿ç•™æœ‰ä»·å€¼çš„äº‰è®®ç‚¹å’Œè®¨è®ºç‚¹
5. æ•´ç†å¯ç”¨äºå†…å®¹åˆ›ä½œçš„ç´ æ

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

## ğŸ¯ ä¸»è¦è§‚ç‚¹
- [æ ¸å¿ƒè§‚ç‚¹1]
- [æ ¸å¿ƒè§‚ç‚¹2]
...

## ï¿½ é‡è¦ç»†èŠ‚
- [ç»†èŠ‚1]
- [ç»†èŠ‚2]
...

## ğŸ’¡ ç‹¬ç‰¹è§è§£
- [è§è§£1]
- [è§è§£2]
...

## âš¡ äº‰è®®è®¨è®ºç‚¹
- [äº‰è®®ç‚¹1]
- [äº‰è®®ç‚¹2]
...

## ï¿½ å…¶ä»–æœ‰ä»·å€¼ä¿¡æ¯
- [ä¿¡æ¯1]
- [ä¿¡æ¯2]
...

âš ï¸ ä¸è¦åŠ å…¥ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œä¸è¦è¯´"æˆ‘è®¤ä¸º"æˆ–"å¯èƒ½"ï¼Œåªæ ¹æ®å†…å®¹åŸæ–‡æ€»ç»“ã€‚

è§†é¢‘å†…å®¹å¦‚ä¸‹ï¼š
â€”â€”â€”
{text}
â€”â€”â€”
/no_think
        """
        
        try:
            response = self.ollama.chat(
                model='qwen3:32b',
                messages=[{"role": "user", "content": prompt}]
            )
            return response['message']['content']
        except Exception as e:
            print(f"ollama æ€»ç»“å¤±è´¥: {e}")
            return f"æ€»ç»“å¤±è´¥: {e}"

    def save_summary(self, video_id: str, video_title: str, summary: str, output_path: Path = None):
        """ä¿å­˜æ€»ç»“åˆ°æ–‡ä»¶"""
        if output_path:
            # ä¿å­˜åˆ°è§†é¢‘ä¸“å±ç›®å½•
            summary_file = output_path / "summary.txt"
        else:
            # å…¼å®¹æ—§çš„ä¿å­˜æ–¹å¼
            safe_title = self._clean_filename(video_title)
            summary_file = self.summaries_dir / f"{video_id}_{safe_title[:50]}.txt"
        
        try:
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(f"è§†é¢‘æ ‡é¢˜: {video_title}\n")
                f.write(f"è§†é¢‘ID: {video_id}\n")
                f.write("=" * 50 + "\n")
                f.write(summary)
            print(f"ğŸ’¾ æ€»ç»“å·²ä¿å­˜åˆ°: {summary_file}")
        except Exception as e:
            print(f"ä¿å­˜æ€»ç»“å¤±è´¥: {e}")

    def create_final_summary(self, keyword: str) -> str:
        """å¯¹æ‰€æœ‰æ€»ç»“è¿›è¡Œæœ€ç»ˆæ±‡æ€»"""
        # è¯»å–æ‰€æœ‰æ€»ç»“æ–‡ä»¶ï¼ˆåŒ…æ‹¬æ–°çš„ç›®å½•ç»“æ„å’Œæ—§çš„æ–‡ä»¶ç»“æ„ï¼‰
        all_summaries = []
        video_sources = []  # è®°å½•è§†é¢‘æ¥æºä¿¡æ¯
        
        # è¯»å–æ–°ç»“æ„ï¼šä»å„ä¸ªè§†é¢‘ç›®å½•ä¸­çš„ summary.txt
        for video_dir in self.download_dir.glob("*"):
            if video_dir.is_dir():
                summary_file = video_dir / "summary.txt"
                if summary_file.exists():
                    try:
                        with open(summary_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                            all_summaries.append(content)
                            
                            # ä»æ–‡ä»¶å†…å®¹ä¸­æå–è§†é¢‘ä¿¡æ¯
                            lines = content.split('\n')
                            video_title = "æœªçŸ¥æ ‡é¢˜"
                            video_id = "æœªçŸ¥ID"
                            
                            for line in lines:
                                if line.startswith("è§†é¢‘æ ‡é¢˜:"):
                                    video_title = line.replace("è§†é¢‘æ ‡é¢˜:", "").strip()
                                elif line.startswith("è§†é¢‘ID:"):
                                    video_id = line.replace("è§†é¢‘ID:", "").strip()
                            
                            video_sources.append({
                                'title': video_title,
                                'id': video_id,
                                'url': f'https://www.youtube.com/watch?v={video_id}'
                            })
                            
                    except Exception as e:
                        print(f"è¯»å–æ€»ç»“æ–‡ä»¶å¤±è´¥: {e}")
        
        # è¯»å–æ—§ç»“æ„ï¼šä» summaries ç›®å½•ä¸­çš„æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
        for summary_file in self.summaries_dir.glob("*.txt"):
            if not summary_file.name.startswith("final_summary_"):
                try:
                    with open(summary_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        all_summaries.append(content)
                        
                        # ä»æ–‡ä»¶å†…å®¹ä¸­æå–è§†é¢‘ä¿¡æ¯
                        lines = content.split('\n')
                        video_title = "æœªçŸ¥æ ‡é¢˜"
                        video_id = "æœªçŸ¥ID"
                        
                        for line in lines:
                            if line.startswith("è§†é¢‘æ ‡é¢˜:"):
                                video_title = line.replace("è§†é¢‘æ ‡é¢˜:", "").strip()
                            elif line.startswith("è§†é¢‘ID:"):
                                video_id = line.replace("è§†é¢‘ID:", "").strip()
                        
                        video_sources.append({
                            'title': video_title,
                            'id': video_id,
                            'url': f'https://www.youtube.com/watch?v={video_id}'
                        })
                        
                except Exception as e:
                    print(f"è¯»å–æ€»ç»“æ–‡ä»¶å¤±è´¥: {e}")
        
        if not all_summaries:
            return "æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ€»ç»“æ–‡ä»¶"
        
        # ç”Ÿæˆæ¥æºåˆ—è¡¨
        sources_text = "\nğŸ“‹ åˆ†ææ¥æºè§†é¢‘ï¼š\n"
        for i, source in enumerate(video_sources, 1):
            sources_text += f"{i}. ã€Š{source['title']}ã€‹\n"
            sources_text += f"   è§†é¢‘ID: {source['id']} | URL: {source['url']}\n\n"
        
        combined_text = sources_text + "\n" + "="*50 + "\n\n".join(all_summaries)
        
        final_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„è§‚ç‚¹æå–ä¸“å®¶ï¼Œè¯·ä»ä»¥ä¸‹å…³äº"{keyword}"çš„å¤šä¸ªè§†é¢‘æ€»ç»“ä¸­ï¼Œæå–æ‰€æœ‰æœ‰ä»·å€¼çš„è§‚ç‚¹ã€è§è§£å’Œåˆ†æè§’åº¦ã€‚

ç›®æ ‡ï¼šä¸ºYouTubeå†…å®¹åˆ›ä½œè€…æä¾›ä¸°å¯Œçš„ç´ æåº“ï¼ŒåŒ…å«å„ç§ä¸åŒçš„è§‚ç‚¹ã€åˆ†æè§’åº¦ã€æœ‰è¶£ç»†èŠ‚å’Œåˆ›ä½œçµæ„Ÿã€‚

é‡è¦è¦æ±‚ï¼š
- é€ä¸€æå–æ¯ä¸ªè§†é¢‘ä¸­çš„ç‹¬ç‰¹è§‚ç‚¹å’Œè§è§£ï¼Œä¸è¦åˆå¹¶æˆ–æ¦‚æ‹¬
- ä¿æŒåŸå§‹è¡¨è¾¾çš„æ–°é¢–æ€§å’Œç‹¬ç‰¹æ€§
- å½“æåˆ°è§‚ç‚¹æ—¶ï¼Œå¿…é¡»æ ‡æ³¨æ¥æºè§†é¢‘åºå·ï¼Œå¦‚ (æ¥æºï¼šè§†é¢‘1)
- é‡ç‚¹å…³æ³¨å¯ç”¨äºå†…å®¹åˆ›ä½œçš„æœ‰è¶£è§’åº¦ã€äº‰è®®ç‚¹ã€ç»†èŠ‚å‘ç°

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

## ï¿½ è§’è‰²åˆ†æè§‚ç‚¹
ï¼ˆä»å„è§†é¢‘ä¸­æå–çš„å…³äºè§’è‰²çš„ä¸åŒè§£è¯»å’Œåˆ†æï¼‰

## ï¿½ğŸ¯ å‰§æƒ…è§£è¯»è§’åº¦  
ï¼ˆå„è§†é¢‘å¯¹å‰§æƒ…çš„ä¸åŒç†è§£ã€ç»†èŠ‚å‘ç°ã€é€»è¾‘åˆ†æï¼‰

## ğŸ”¥ äº‰è®®è¯é¢˜æ”¶é›†
ï¼ˆè§‚ä¼—äº‰è®®çš„ç„¦ç‚¹ã€ä¸åŒç«‹åœºã€æ‰¹è¯„å’Œèµç¾çš„å…·ä½“ç‚¹ï¼‰

## ğŸ’¡ åˆ›ä½œçµæ„Ÿç´ æ
ï¼ˆæœ‰è¶£çš„ç»†èŠ‚ã€å½©è›‹å‘ç°ã€å¹•åä¿¡æ¯ã€åˆ¶ä½œåˆ†æï¼‰

## ğŸ­ æ–‡åŒ–è§£è¯»è§†è§’
ï¼ˆç¤¾ä¼šæ„ä¹‰ã€éšå–»åˆ†æã€æ–‡åŒ–èƒŒæ™¯è§£è¯»ï¼‰

## ğŸ“Š è§‚ä¼—åå“æ•´ç†
ï¼ˆæ”¶è§†æ•°æ®ã€è§‚ä¼—è¯„ä»·ã€ç½‘ç»œè®¨è®ºçƒ­ç‚¹ï¼‰

## ï¿½ æœªæ¥å±•æœ›è§‚ç‚¹
ï¼ˆå¯¹ç»­é›†ã€è¡ç”Ÿã€å½±å“çš„å„ç§é¢„æµ‹å’ŒæœŸå¾…ï¼‰

æ³¨æ„ï¼šæ¯æ¡è§‚ç‚¹éƒ½è¦æ ‡æ³¨æ¥æºï¼Œä¿æŒè§‚ç‚¹çš„åŸå§‹æ€§å’Œå¤šæ ·æ€§ï¼Œé¿å…åŒè´¨åŒ–è¡¨è¾¾ã€‚

è§†é¢‘æ€»ç»“å†…å®¹ï¼š
â€”â€”â€”
{combined_text}
â€”â€”â€”
/no_think
        """
        
        try:
            response = self.ollama.chat(
                model='qwen3:32b',
                messages=[{"role": "user", "content": final_prompt}]
            )
            
            final_summary = response['message']['content']
            
            # ä¿å­˜æœ€ç»ˆæ€»ç»“ï¼ˆåŒ…å«æ¥æºä¿¡æ¯ï¼‰
            final_file = self.summaries_dir / f"final_summary_{keyword}.txt"
            with open(final_file, 'w', encoding='utf-8') as f:
                f.write(f"å…³é”®è¯: {keyword}\n")
                f.write("=" * 50 + "\n")
                
                # å…ˆå†™å…¥æ¥æºè§†é¢‘åˆ—è¡¨
                f.write(sources_text)
                f.write("\n" + "=" * 50 + "\n")
                f.write("ğŸ” ç»¼åˆåˆ†ææŠ¥å‘Š\n")
                f.write("=" * 50 + "\n")
                f.write(final_summary)
            
            print(f"æœ€ç»ˆæ€»ç»“å·²ä¿å­˜åˆ°: {final_file}")
            return final_summary
            
        except Exception as e:
            print(f"åˆ›å»ºæœ€ç»ˆæ€»ç»“å¤±è´¥: {e}")
            return f"æœ€ç»ˆæ€»ç»“å¤±è´¥: {e}"

    def filter_videos_with_llm(self, videos: List[Dict], keyword: str, top_n: int = 5) -> List[Dict]:
        """ä½¿ç”¨ LLM æ™ºèƒ½ç­›é€‰æœ€ç›¸å…³çš„è§†é¢‘"""
        if not videos:
            return []
        
        print(f"ğŸ¤– ä½¿ç”¨ LLM ç­›é€‰æœ€ç›¸å…³çš„ {top_n} ä¸ªè§†é¢‘...")
        
        # å‡†å¤‡è§†é¢‘ä¿¡æ¯ç»™ LLM åˆ†æ
        video_list_text = ""
        for i, video in enumerate(videos, 1):
            video_list_text += f"{i}. æ ‡é¢˜: {video['title']}\n"
            video_list_text += f"   è§‚çœ‹é‡: {video['view_text']} ({video['view_count']}æ¬¡)\n"
            video_list_text += f"   è§†é¢‘ID: {video['video_id']}\n\n"
        
        prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„å†…å®¹åˆ†æå¸ˆï¼Œè¯·ä»”ç»†åˆ†ææ¯ä¸ªè§†é¢‘æ ‡é¢˜ï¼Œä»ä»¥ä¸‹è§†é¢‘åˆ—è¡¨ä¸­ç­›é€‰å‡ºä¸å…³é”®è¯"{keyword}"æœ€ç›¸å…³ä¸”æœ€æœ‰ä»·å€¼çš„å‰{top_n}ä¸ªè§†é¢‘ã€‚

## ç­›é€‰æ ‡å‡†ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰ï¼š

### 1. ï¿½ å†…å®¹ç›¸å…³æ€§ï¼ˆæœ€é‡è¦ï¼‰
- æ ‡é¢˜ç›´æ¥æåˆ°"{keyword}"æˆ–ç›¸å…³è¯æ±‡
- æ¶‰åŠè¯¥ä¸»é¢˜çš„æ·±åº¦åˆ†æã€è§£è¯»ã€è¯„è®º
- åŒ…å«å‰§æƒ…åˆ†æã€è§’è‰²è§£è¯»ã€ç»†èŠ‚è§£æç­‰å†…å®¹

### 2. ğŸ“š å†…å®¹è´¨é‡åˆ¤æ–­
- **ä¼˜å…ˆé€‰æ‹©**ï¼š
  - æ·±åº¦è§£æç±»ï¼š"è§£æ"ã€"åˆ†æ"ã€"è§£è¯»"ã€"æ„ä¹‰"ã€"éšè—"
  - å®Œæ•´è¯„è®ºç±»ï¼š"ä¸€æ¬¡çœ‹æ‡‚"ã€"å…¨è§£æ"ã€"å®Œæ•´ç‰ˆ"ã€"ç»“å±€"
  - ä¸“ä¸šè¯„è®ºç±»ï¼šé¿å…è¿‡åº¦å¤¸å¼ çš„æ ‡é¢˜

- **é¿å…é€‰æ‹©**ï¼š
  - çº¯ç‰‡æ®µå‰ªè¾‘ï¼š"ç‰‡æ®µ"ã€"cut"ã€"å‰ªè¾‘"
  - æ ‡é¢˜å…šå†…å®¹ï¼šè¿‡å¤šæ„Ÿå¹å·ã€å¤¸å¼ è¯æ±‡
  - æ— å…³å†…å®¹ï¼šä¸"{keyword}"ä¸»é¢˜ä¸ç¬¦çš„è§†é¢‘

### 3. ğŸ” é¢˜æåˆ†ç±»
- å‰§æƒ…åˆ†æï¼šè§’è‰²å¿ƒç†ã€æƒ…èŠ‚é€»è¾‘ã€éšå–»å«ä¹‰
- ç»†èŠ‚å‘ç°ï¼šå½©è›‹ã€çº¿ç´¢ã€åˆ¶ä½œç»†èŠ‚
- æ–‡åŒ–è§£è¯»ï¼šç¤¾ä¼šæ„ä¹‰ã€èƒŒæ™¯åˆ†æ
- è§‚ä¼—åå“ï¼šè¯„è®ºã€è®¨è®ºã€äº‰è®®ç‚¹

## åˆ†æè¦æ±‚ï¼š
1. **é€ä¸ªåˆ†ææ¯ä¸ªæ ‡é¢˜çš„ç›¸å…³æ€§**
2. **ä¼˜å…ˆé€‰æ‹©å†…å®¹è´¨é‡é«˜ã€ä¸ä¸»é¢˜æœ€ç›¸å…³çš„è§†é¢‘**
3. **æ’­æ”¾é‡ä»…ä½œä¸ºæ¬¡è¦å‚è€ƒï¼Œä¸æ˜¯ä¸»è¦æ ‡å‡†**
4. **ç¡®ä¿é€‰æ‹©çš„è§†é¢‘èƒ½æä¾›ä¸åŒè§’åº¦çš„åˆ†æè§‚ç‚¹**

è¯·ä»”ç»†é˜…è¯»æ¯ä¸ªæ ‡é¢˜ï¼Œåˆ†æå…¶ä¸"{keyword}"çš„ç›¸å…³æ€§ï¼Œç„¶åè¿”å›æœ€ç›¸å…³çš„{top_n}ä¸ªè§†é¢‘åºå·ã€‚

åªè¿”å›åºå·ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ï¼š1,3,5,7,9

è§†é¢‘åˆ—è¡¨ï¼š
{video_list_text}

åˆ†æåé€‰æ‹©çš„åºå·ï¼š"""
        
        try:
            print("ğŸ”„ æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œè§†é¢‘ç­›é€‰...")
            response = self.ollama.chat(
                model='qwen3:32b',
                messages=[{"role": "user", "content": prompt}]
            )
            
            # è§£æ LLM çš„å›ç­”ï¼Œæå–è§†é¢‘åºå·
            response_text = response['message']['content'].strip()
            
            # å°è¯•å¤šç§æ–¹å¼è§£æè§†é¢‘åºå·
            video_ids = []
            
            # æ–¹æ³•1: æŸ¥æ‰¾æœ€åä¸€è¡ŒåŒ…å«æ•°å­—å’Œé€—å·çš„å†…å®¹ï¼ˆLLM çš„æœ€ç»ˆç­”æ¡ˆï¼‰
            lines = response_text.split('\n')
            for line in reversed(lines):  # ä»æœ€åä¸€è¡Œå¼€å§‹æŸ¥æ‰¾
                line = line.strip()
                # å¯»æ‰¾åŒ…å«æ•°å­—å’Œé€—å·çš„è¡Œï¼Œè¿™é€šå¸¸æ˜¯æœ€ç»ˆç­”æ¡ˆ
                if ',' in line and re.search(r'\d+', line):
                    # æå–æ‰€æœ‰æ•°å­—
                    numbers = re.findall(r'\d+', line)
                    if len(numbers) >= 3:  # è‡³å°‘è¦æœ‰3ä¸ªæ•°å­—æ‰è®¤ä¸ºæ˜¯æœ‰æ•ˆç­”æ¡ˆ
                        video_ids = numbers
                        break
            
            # æ–¹æ³•2: æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„è¡Œ
            if not video_ids:
                for line in response_text.split('\n'):
                    if any(keyword in line for keyword in ['åºå·', 'é€‰æ‹©', 'ç­”æ¡ˆ', 'ç»“æœ']):
                        numbers = re.findall(r'\d+', line)
                        if numbers:
                            video_ids = numbers
                            break
            
            # æ–¹æ³•3: å¦‚æœå‰é¢æ–¹æ³•éƒ½å¤±è´¥ï¼ŒæŸ¥æ‰¾æ‰€æœ‰æ•°å­—ï¼ˆä½†é™åˆ¶æ•°é‡ï¼‰
            if not video_ids:
                all_numbers = re.findall(r'\d+', response_text)
                # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯åºå·çš„æ•°å­—ï¼ˆå¦‚å¹´ä»½ã€æ’­æ”¾é‡ç­‰ï¼‰
                valid_numbers = []
                for num in all_numbers:
                    num_int = int(num)
                    if 1 <= num_int <= len(videos):  # åªä¿ç•™æœ‰æ•ˆçš„è§†é¢‘åºå·èŒƒå›´
                        valid_numbers.append(num)
                video_ids = valid_numbers[:top_n * 2]  # æœ€å¤šå–top_nçš„2å€ï¼Œé¿å…è¿‡å¤š
            
            print(f"ğŸ” LLM å›ç­”: {response_text[:200]}...")
            print(f"ğŸ“ è§£æåˆ°çš„è§†é¢‘åºå·: {video_ids[:10]}...")  # åªæ˜¾ç¤ºå‰10ä¸ª
            
            if not video_ids:
                # å¦‚æœè§£æå¤±è´¥ï¼Œfallbackåˆ°æŒ‰æ’­æ”¾é‡æ’åºï¼ˆå»é‡ï¼‰
                print("âš ï¸ LLM ç­›é€‰å¤±è´¥ï¼Œä½¿ç”¨æ’­æ”¾é‡æ’åº")
                # å»é‡å¤„ç†
                unique_videos = {}
                for video in videos:
                    if video['video_id'] not in unique_videos:
                        unique_videos[video['video_id']] = video
                
                sorted_videos = sorted(unique_videos.values(), key=lambda x: x['view_count'], reverse=True)
                return sorted_videos[:top_n]
            
            # æ ¹æ®LLMé€‰æ‹©çš„åºå·ç­›é€‰è§†é¢‘ï¼Œå»é‡å¤„ç†
            selected_videos = []
            seen_video_ids = set()  # ç”¨äºå»é‡
            
            for num_str in video_ids:
                try:
                    index = int(num_str) - 1  # è½¬æ¢ä¸º0ç´¢å¼•
                    if 0 <= index < len(videos):
                        video = videos[index]
                        # æ£€æŸ¥æ˜¯å¦å·²ç»é€‰æ‹©è¿‡è¿™ä¸ªè§†é¢‘
                        if video['video_id'] not in seen_video_ids:
                            selected_videos.append(video)
                            seen_video_ids.add(video['video_id'])
                            
                            if len(selected_videos) >= top_n:
                                break
                except ValueError:
                    continue
            
            # å¦‚æœé€‰æ‹©çš„è§†é¢‘ä¸å¤Ÿï¼Œç”¨æ’­æ”¾é‡é«˜çš„è§†é¢‘è¡¥å……
            if len(selected_videos) < top_n:
                print(f"âš ï¸ LLM é€‰æ‹©çš„è§†é¢‘ä¸å¤Ÿ({len(selected_videos)})ï¼Œç”¨é«˜æ’­æ”¾é‡è§†é¢‘è¡¥å……...")
                remaining_videos = [v for v in videos if v['video_id'] not in seen_video_ids]
                sorted_remaining = sorted(remaining_videos, key=lambda x: x['view_count'], reverse=True)
                
                for video in sorted_remaining:
                    if len(selected_videos) >= top_n:
                        break
                    selected_videos.append(video)
                    seen_video_ids.add(video['video_id'])
            
            print(f"ğŸ¤– LLM ç­›é€‰å®Œæˆï¼Œé€‰æ‹©äº† {len(selected_videos)} ä¸ªè§†é¢‘")
            for i, video in enumerate(selected_videos, 1):
                print(f"  {i}. {video['title']} ({video['view_text']})")
            
            return selected_videos
            
        except Exception as e:
            print(f"âŒ LLM ç­›é€‰å¤±è´¥: {e}")
            # fallbackåˆ°æŒ‰æ’­æ”¾é‡æ’åºï¼ˆå»é‡ï¼‰
            unique_videos = {}
            for video in videos:
                if video['video_id'] not in unique_videos:
                    unique_videos[video['video_id']] = video
            
            sorted_videos = sorted(unique_videos.values(), key=lambda x: x['view_count'], reverse=True)
            return sorted_videos[:top_n]

    async def process_videos(self, keyword: str, max_videos: int = 5):
        """å¤„ç†æ•´ä¸ªæµç¨‹ - ä¼˜åŒ–ä¸ºå…ˆæ‰¹é‡ä¸‹è½½ï¼Œå†æ‰¹é‡å¤„ç†"""
        print(f"ğŸ” å¼€å§‹æœç´¢å…³é”®è¯: {keyword}")
        
        # 1. æœç´¢è§†é¢‘ï¼Œè·å–100ä¸ªå€™é€‰è§†é¢‘
        print("ğŸ“Š ç¬¬ä¸€æ­¥ï¼šé‡‡é›†å€™é€‰è§†é¢‘...")
        all_videos = await self.search_youtube_videos(keyword, max_videos=100)
        
        if not all_videos:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘")
            return
        
        # 2. ä½¿ç”¨ LLM æ™ºèƒ½ç­›é€‰æœ€ç›¸å…³çš„å‰5ä¸ªè§†é¢‘
        print("ğŸ¤– ç¬¬äºŒæ­¥ï¼šLLM æ™ºèƒ½ç­›é€‰æœ€ç›¸å…³è§†é¢‘...")
        selected_videos = self.filter_videos_with_llm(all_videos, keyword, top_n=max_videos)
        
        if not selected_videos:
            print("âŒ ç­›é€‰åæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„è§†é¢‘")
            return
        
        print(f"âœ… æœ€ç»ˆé€‰æ‹©å¤„ç† {len(selected_videos)} ä¸ªè§†é¢‘")
        
        # æ˜¾ç¤ºé€‰ä¸­çš„è§†é¢‘åˆ—è¡¨
        print("\nğŸ“‹ é€‰ä¸­çš„è§†é¢‘åˆ—è¡¨ï¼š")
        for i, video in enumerate(selected_videos, 1):
            print(f"  {i}. {video['title']}")
            print(f"     è§‚çœ‹é‡: {video['view_text']} | ID: {video['video_id']}")
        
        # 3. é˜¶æ®µä¸€ï¼šæ‰¹é‡ä¸‹è½½æ‰€æœ‰è§†é¢‘çš„å­—å¹•/éŸ³é¢‘
        print(f"\n{'='*60}")
        print("ğŸ¯ é˜¶æ®µä¸€ï¼šæ‰¹é‡ä¸‹è½½å­—å¹•å’ŒéŸ³é¢‘")
        print(f"{'='*60}")
        
        download_results = []
        for i, video in enumerate(selected_videos, 1):
            print(f"\nï¿½ ä¸‹è½½ç¬¬ {i}/{len(selected_videos)} ä¸ªè§†é¢‘")
            print(f"æ ‡é¢˜: {video['title']}")
            
            # ä¸‹è½½è§†é¢‘ä¿¡æ¯
            video_info = self.download_video_info(video['url'])
            if not video_info:
                print("âŒ æ— æ³•è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼Œè·³è¿‡")
                download_results.append({
                    'video': video,
                    'success': False,
                    'reason': 'æ— æ³•è·å–è§†é¢‘ä¿¡æ¯'
                })
                continue
            
            # ä¸‹è½½å­—å¹•æˆ–éŸ³é¢‘
            download_result = self.download_video_with_subtitles(video['url'], video['video_id'], video['title'])
            
            if download_result['subtitle_downloaded'] or download_result['audio_file']:
                print("âœ… ä¸‹è½½æˆåŠŸ")
                download_results.append({
                    'video': video,
                    'success': True,
                    'download_result': download_result
                })
            else:
                print("âŒ ä¸‹è½½å¤±è´¥")
                download_results.append({
                    'video': video,
                    'success': False,
                    'reason': 'å­—å¹•å’ŒéŸ³é¢‘éƒ½ä¸‹è½½å¤±è´¥'
                })
        
        # ç»Ÿè®¡ä¸‹è½½ç»“æœ
        successful_downloads = [r for r in download_results if r['success']]
        print(f"\nğŸ“Š ä¸‹è½½é˜¶æ®µå®Œæˆ: {len(successful_downloads)}/{len(selected_videos)} ä¸ªè§†é¢‘ä¸‹è½½æˆåŠŸ")
        
        if not successful_downloads:
            print("âŒ æ²¡æœ‰æˆåŠŸä¸‹è½½ä»»ä½•è§†é¢‘å†…å®¹ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
            return
        
        # 4. é˜¶æ®µäºŒï¼šæ‰¹é‡è½¬å†™å’Œæ‘˜è¦
        print(f"\n{'='*60}")
        print("ğŸ¯ é˜¶æ®µäºŒï¼šæ‰¹é‡è½¬å†™å’Œæ‘˜è¦")
        print(f"{'='*60}")
        
        successful_count = 0
        for i, result in enumerate(successful_downloads, 1):
            video = result['video']
            download_result = result['download_result']
            
            print(f"\nğŸ“ å¤„ç†ç¬¬ {i}/{len(successful_downloads)} ä¸ªè§†é¢‘")
            print(f"æ ‡é¢˜: {video['title']}")
            
            # æå–æ–‡æœ¬
            text_content = ""
            if download_result['subtitle_downloaded'] and download_result['subtitle_file']:
                print("ğŸ“ ä½¿ç”¨å­—å¹•è¿›è¡Œæ€»ç»“")
                text_content = self.extract_text_from_subtitle(download_result['subtitle_file'])
            elif download_result['audio_file']:
                print("ğŸ”Š ä½¿ç”¨éŸ³é¢‘è½¬å½•è¿›è¡Œæ€»ç»“")
                text_content = self.transcribe_audio(download_result['audio_file'])
            
            if not text_content:
                print("âŒ æ— æ³•æå–æ–‡æœ¬å†…å®¹ï¼Œè·³è¿‡")
                continue
            
            print(f"ğŸ“Š æå–çš„æ–‡æœ¬é•¿åº¦: {len(text_content)} å­—ç¬¦")
            
            # ç”Ÿæˆæ€»ç»“
            print("ğŸ¤– æ­£åœ¨ç”Ÿæˆæ€»ç»“...")
            summary = self.summarize_text(text_content, video['title'])
            
            # ä¿å­˜æ€»ç»“åˆ°è§†é¢‘ç›®å½•
            self.save_summary(video['video_id'], video['title'], summary, download_result['output_path'])
            successful_count += 1
            
            print(f"âœ… è§†é¢‘ {i} å¤„ç†å®Œæˆ")
        
        # 5. ç”Ÿæˆæœ€ç»ˆæ€»ç»“
        if successful_count > 0:
            print(f"\nğŸ¯ å¤„ç†å®Œæˆç»Ÿè®¡:")
            print(f"   ğŸ“¥ ä¸‹è½½æˆåŠŸ: {len(successful_downloads)}/{len(selected_videos)} ä¸ªè§†é¢‘")
            print(f"   ğŸ“ æ‘˜è¦æˆåŠŸ: {successful_count}/{len(successful_downloads)} ä¸ªè§†é¢‘")
            print("ğŸ“‹ ç”Ÿæˆæœ€ç»ˆç»¼åˆæ€»ç»“...")
            final_summary = self.create_final_summary(keyword)
            print("\n" + "="*60)
            print("=== æœ€ç»ˆç»¼åˆæ€»ç»“ ===")
            print("="*60)
            print(final_summary)
        else:
            print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•è§†é¢‘ï¼Œæ— æ³•ç”Ÿæˆæœ€ç»ˆæ€»ç»“")

    def _clean_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
        # ç§»é™¤æˆ–æ›¿æ¢æ–‡ä»¶ç³»ç»Ÿä¸å…è®¸çš„å­—ç¬¦
        import re
        # æ›¿æ¢éæ³•å­—ç¬¦ä¸ºä¸‹åˆ’çº¿
        cleaned = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œç‚¹
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        # é™åˆ¶é•¿åº¦ï¼Œé¿å…è·¯å¾„è¿‡é•¿
        if len(cleaned) > 50:
            cleaned = cleaned[:50].rstrip()
        return cleaned

async def main():
    keyword = "é±¿é±¼æ¸¸æˆ3"
    analyzer = YouTubeVideoAnalyzer()
    await analyzer.process_videos(keyword, max_videos=5)

if __name__ == "__main__":
    asyncio.run(main())
