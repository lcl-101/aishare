import torch
import gradio as gr
from diffusers import Flux2KleinPipeline
import random
import time

# è®¾å¤‡å’Œæ•°æ®ç±»å‹é…ç½®
device = "cuda"
dtype = torch.bfloat16

# åŠ è½½æœ¬åœ°æ¨¡å‹
print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
pipe = Flux2KleinPipeline.from_pretrained(
    "checkpoints/FLUX.2-klein-9B", 
    torch_dtype=dtype
)
pipe.enable_model_cpu_offload()
print("æ¨¡å‹åŠ è½½å®Œæˆï¼")

# æ–‡ç”Ÿå›¾ç¤ºä¾‹æç¤ºè¯
txt2img_example_prompts = [
    "A cat holding a sign that says hello world",
    "A futuristic cityscape at sunset with flying cars",
    "A magical forest with glowing mushrooms and fireflies",
    "A steampunk robot reading a book in a cozy library",
    "A majestic dragon flying over snow-capped mountains",
    "An astronaut playing guitar on the moon",
    "A beautiful Japanese garden with cherry blossoms and a koi pond",
    "A cyberpunk street market at night with neon lights",
    "A cute corgi wearing a tiny crown sitting on a throne",
    "A watercolor painting of a Venice canal at sunrise",
]

# æ ¹æ®åŸå§‹æç¤ºè¯ç”Ÿæˆç›¸å…³çš„ç¼–è¾‘æç¤ºè¯
def get_related_edit_prompts(original_prompt):
    """æ ¹æ®åŸå§‹æç¤ºè¯ç”Ÿæˆç›¸å…³çš„ç¼–è¾‘æç¤ºè¯"""
    base_edits = [
        f"{original_prompt}, in the style of oil painting",
        f"{original_prompt}, in anime style",
        f"{original_prompt}, in watercolor style",
        f"{original_prompt}, at night with dramatic lighting",
        f"{original_prompt}, in cyberpunk style with neon colors",
        f"{original_prompt}, in vintage photograph style",
        f"{original_prompt}, in minimalist art style",
        f"{original_prompt}, with a dreamy, ethereal atmosphere",
    ]
    return base_edits

# å½“å‰ä¼šè¯çŠ¶æ€
current_state = {
    "original_prompt": "",
    "generated_image": None
}

def generate_image(prompt, height, width, guidance_scale, num_steps, seed):
    """æ–‡ç”Ÿå›¾å‡½æ•°"""
    if not prompt.strip():
        return None, "è¯·è¾“å…¥æç¤ºè¯ï¼", gr.update()
    
    try:
        if seed == -1:
            seed = random.randint(0, 2**32 - 1)
        
        generator = torch.Generator(device=device).manual_seed(seed)
        
        start_time = time.time()
        
        image = pipe(
            prompt=prompt,
            height=int(height),
            width=int(width),
            guidance_scale=guidance_scale,
            num_inference_steps=int(num_steps),
            generator=generator
        ).images[0]
        
        elapsed_time = time.time() - start_time
        
        # ä¿å­˜çŠ¶æ€
        current_state["original_prompt"] = prompt
        current_state["generated_image"] = image
        
        # ç”Ÿæˆç›¸å…³ç¼–è¾‘æç¤ºè¯
        related_prompts = get_related_edit_prompts(prompt)
        
        status_msg = f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼ä½¿ç”¨çš„ç§å­å€¼: {seed} | è€—æ—¶: {elapsed_time:.2f} ç§’"
        
        return image, status_msg, gr.update(choices=related_prompts, value=related_prompts[0])
    
    except Exception as e:
        return None, f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}", gr.update()

def send_to_edit(image):
    """å°†å›¾ç‰‡å‘é€åˆ°ç¼–è¾‘æ ‡ç­¾é¡µ"""
    if image is None:
        return None, "æ²¡æœ‰å¯å‘é€çš„å›¾ç‰‡ï¼"
    return image, "âœ… å›¾ç‰‡å·²å‘é€åˆ°ç¼–è¾‘æ ‡ç­¾é¡µï¼"

def edit_image(image, prompt, height, width, guidance_scale, num_steps, seed):
    """å›¾ç‰‡ç¼–è¾‘å‡½æ•° - åŸºäºæ–°æç¤ºè¯é‡æ–°ç”Ÿæˆ"""
    if not prompt.strip():
        return None, "è¯·è¾“å…¥ç¼–è¾‘æç¤ºè¯ï¼"
    
    try:
        if seed == -1:
            seed = random.randint(0, 2**32 - 1)
        
        generator = torch.Generator(device=device).manual_seed(seed)
        
        start_time = time.time()
        
        # ä½¿ç”¨æ–°çš„æç¤ºè¯ç”Ÿæˆå›¾ç‰‡
        edited_image = pipe(
            prompt=prompt,
            height=int(height),
            width=int(width),
            guidance_scale=guidance_scale,
            num_inference_steps=int(num_steps),
            generator=generator
        ).images[0]
        
        elapsed_time = time.time() - start_time
        
        status_msg = f"âœ… å›¾ç‰‡ç¼–è¾‘æˆåŠŸï¼ä½¿ç”¨çš„ç§å­å€¼: {seed} | è€—æ—¶: {elapsed_time:.2f} ç§’"
        
        return edited_image, status_msg
    
    except Exception as e:
        return None, f"âŒ ç¼–è¾‘å¤±è´¥: {str(e)}"

def use_example_prompt(example):
    """ä½¿ç”¨ç¤ºä¾‹æç¤ºè¯"""
    return example

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="FLUX.2-Klein å›¾åƒç”Ÿæˆå™¨", theme=gr.themes.Soft()) as demo:
    # é¡¶éƒ¨ YouTube é¢‘é“ä¿¡æ¯
    gr.HTML("""
        <div style="text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; margin-bottom: 20px;">
            <h1 style="color: white; margin: 0; font-size: 2em;">ğŸ¨ FLUX.2-Klein å›¾åƒç”Ÿæˆå™¨</h1>
            <p style="color: #f0f0f0; margin: 10px 0;">
                ğŸ“º <strong>AI æŠ€æœ¯åˆ†äº«é¢‘é“</strong> | 
                <a href="https://www.youtube.com/@rongyikanshijie-ai" target="_blank" style="color: #ffeb3b; text-decoration: none;">
                    ğŸ”— è®¢é˜…æˆ‘çš„ YouTube é¢‘é“
                </a>
            </p>
        </div>
    """)
    
    with gr.Tabs():
        # ç¬¬ä¸€ä¸ªæ ‡ç­¾é¡µï¼šæ–‡ç”Ÿå›¾
        with gr.TabItem("ğŸ–¼ï¸ æ–‡ç”Ÿå›¾"):
            with gr.Row():
                with gr.Column(scale=1):
                    txt2img_prompt = gr.Textbox(
                        label="æç¤ºè¯",
                        placeholder="è¯·è¾“å…¥æ‚¨æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡æè¿°...",
                        lines=3
                    )
                    
                    with gr.Row():
                        txt2img_height = gr.Slider(
                            minimum=256, maximum=2048, value=1024, step=64,
                            label="å›¾ç‰‡é«˜åº¦"
                        )
                        txt2img_width = gr.Slider(
                            minimum=256, maximum=2048, value=1024, step=64,
                            label="å›¾ç‰‡å®½åº¦"
                        )
                    
                    with gr.Row():
                        txt2img_guidance = gr.Slider(
                            minimum=0.0, maximum=10.0, value=1.0, step=0.1,
                            label="å¼•å¯¼ç³»æ•° (Guidance Scale)"
                        )
                        txt2img_steps = gr.Slider(
                            minimum=1, maximum=50, value=4, step=1,
                            label="æ¨ç†æ­¥æ•°"
                        )
                    
                    txt2img_seed = gr.Number(
                        label="éšæœºç§å­ (-1 è¡¨ç¤ºéšæœº)",
                        value=-1,
                        precision=0
                    )
                    
                    with gr.Row():
                        txt2img_generate_btn = gr.Button("ğŸ¨ ç”Ÿæˆå›¾ç‰‡", variant="primary", size="lg")
                        txt2img_send_btn = gr.Button("ğŸ“¤ å‘é€åˆ°ç¼–è¾‘", variant="secondary", size="lg")
                    
                    txt2img_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
                    
                    # ç¤ºä¾‹æç¤ºè¯
                    gr.Markdown("### ğŸ“ ç¤ºä¾‹æç¤ºè¯ (ç‚¹å‡»ä½¿ç”¨)")
                    txt2img_examples = gr.Examples(
                        examples=[[p] for p in txt2img_example_prompts],
                        inputs=[txt2img_prompt],
                        label=""
                    )
                
                with gr.Column(scale=1):
                    txt2img_output = gr.Image(label="ç”Ÿæˆçš„å›¾ç‰‡", type="pil")
        
        # ç¬¬äºŒä¸ªæ ‡ç­¾é¡µï¼šå›¾ç‰‡ç¼–è¾‘
        with gr.TabItem("âœï¸ å›¾ç‰‡ç¼–è¾‘"):
            with gr.Row():
                with gr.Column(scale=1):
                    edit_input_image = gr.Image(
                        label="å¾…ç¼–è¾‘çš„å›¾ç‰‡",
                        type="pil"
                    )
                    
                    edit_prompt = gr.Textbox(
                        label="ç¼–è¾‘æç¤ºè¯",
                        placeholder="è¯·è¾“å…¥ç¼–è¾‘æè¿°...",
                        lines=3
                    )
                    
                    # ç›¸å…³ç¼–è¾‘æç¤ºè¯ä¸‹æ‹‰èœå•
                    edit_related_prompts = gr.Dropdown(
                        label="ç›¸å…³ç¼–è¾‘æç¤ºè¯ (åŸºäºæ–‡ç”Ÿå›¾æç¤ºè¯)",
                        choices=[],
                        interactive=True
                    )
                    
                    with gr.Row():
                        edit_height = gr.Slider(
                            minimum=256, maximum=2048, value=1024, step=64,
                            label="å›¾ç‰‡é«˜åº¦"
                        )
                        edit_width = gr.Slider(
                            minimum=256, maximum=2048, value=1024, step=64,
                            label="å›¾ç‰‡å®½åº¦"
                        )
                    
                    with gr.Row():
                        edit_guidance = gr.Slider(
                            minimum=0.0, maximum=10.0, value=1.0, step=0.1,
                            label="å¼•å¯¼ç³»æ•° (Guidance Scale)"
                        )
                        edit_steps = gr.Slider(
                            minimum=1, maximum=50, value=4, step=1,
                            label="æ¨ç†æ­¥æ•°"
                        )
                    
                    edit_seed = gr.Number(
                        label="éšæœºç§å­ (-1 è¡¨ç¤ºéšæœº)",
                        value=-1,
                        precision=0
                    )
                    
                    edit_btn = gr.Button("âœ¨ åº”ç”¨ç¼–è¾‘", variant="primary", size="lg")
                    edit_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
                
                with gr.Column(scale=1):
                    edit_output = gr.Image(label="ç¼–è¾‘åçš„å›¾ç‰‡", type="pil")
    
    # åº•éƒ¨ä¿¡æ¯
    gr.HTML("""
        <div style="text-align: center; padding: 15px; margin-top: 20px; color: #666;">
            <p>ğŸ’¡ æç¤ºï¼šåœ¨ã€Œæ–‡ç”Ÿå›¾ã€æ ‡ç­¾é¡µç”Ÿæˆå›¾ç‰‡åï¼Œç‚¹å‡»ã€Œå‘é€åˆ°ç¼–è¾‘ã€å¯ä»¥å°†å›¾ç‰‡å‘é€åˆ°ç¼–è¾‘æ ‡ç­¾é¡µè¿›è¡Œè¿›ä¸€æ­¥ç¼–è¾‘ã€‚</p>
            <p>ğŸ“º æ›´å¤š AI æŠ€æœ¯å†…å®¹è¯·å…³æ³¨: <a href="https://www.youtube.com/@rongyikanshijie-ai" target="_blank">AI æŠ€æœ¯åˆ†äº«é¢‘é“</a></p>
        </div>
    """)
    
    # äº‹ä»¶ç»‘å®š
    txt2img_generate_btn.click(
        fn=generate_image,
        inputs=[txt2img_prompt, txt2img_height, txt2img_width, txt2img_guidance, txt2img_steps, txt2img_seed],
        outputs=[txt2img_output, txt2img_status, edit_related_prompts]
    )
    
    txt2img_send_btn.click(
        fn=send_to_edit,
        inputs=[txt2img_output],
        outputs=[edit_input_image, txt2img_status]
    )
    
    # é€‰æ‹©ç›¸å…³æç¤ºè¯æ—¶æ›´æ–°ç¼–è¾‘æç¤ºè¯
    edit_related_prompts.change(
        fn=lambda x: x,
        inputs=[edit_related_prompts],
        outputs=[edit_prompt]
    )
    
    edit_btn.click(
        fn=edit_image,
        inputs=[edit_input_image, edit_prompt, edit_height, edit_width, edit_guidance, edit_steps, edit_seed],
        outputs=[edit_output, edit_status]
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
