"""
SpotEdit Gradio Web åº”ç”¨
åŸºäº FLUX.1-Kontext å’Œ Qwen-Image-Edit æ¨¡å‹çš„å›¾åƒç¼–è¾‘å·¥å…·
"""

import os
import sys
import torch
import gradio as gr
from PIL import Image, ImageOps

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, ROOT_DIR)
# æ·»åŠ å­æ¨¡å—ç›®å½•åˆ°è·¯å¾„ï¼Œè§£å†³æ¨¡å—å†…éƒ¨çš„éç›¸å¯¹å¯¼å…¥é—®é¢˜
sys.path.insert(0, os.path.join(ROOT_DIR, "FLUX_kontext"))
sys.path.insert(0, os.path.join(ROOT_DIR, "Qwen_image_edit"))

from diffusers import FluxKontextPipeline, QwenImageEditPipeline
from diffusers.utils import load_image
from FLUX_kontext import generate as flux_generate, SpotEditConfig as FluxSpotEditConfig
from Qwen_image_edit import generate as qwen_generate, SpotEditConfig as QwenSpotEditConfig

# æ¨¡å‹è·¯å¾„é…ç½®
FLUX_MODEL_PATH = "./checkpoints/FLUX.1-Kontext-dev"
QWEN_MODEL_PATH = "./checkpoints/Qwen-Image-Edit"

# ç¤ºä¾‹å›¾ç‰‡è·¯å¾„
EXAMPLE_IMAGE_PATH = "./asset/dog.jpg"

# å…¨å±€å˜é‡å­˜å‚¨ç®¡é“
flux_pipe = None
qwen_pipe = None


def load_flux_model():
    """åŠ è½½ FLUX æ¨¡å‹"""
    global flux_pipe
    if flux_pipe is None:
        print("æ­£åœ¨åŠ è½½ FLUX.1-Kontext æ¨¡å‹...")
        flux_pipe = FluxKontextPipeline.from_pretrained(
            FLUX_MODEL_PATH, 
            torch_dtype=torch.bfloat16
        ).to('cuda')
        print("FLUX.1-Kontext æ¨¡å‹åŠ è½½å®Œæˆï¼")
    return flux_pipe


def load_qwen_model():
    """åŠ è½½ Qwen æ¨¡å‹"""
    global qwen_pipe
    if qwen_pipe is None:
        print("æ­£åœ¨åŠ è½½ Qwen-Image-Edit æ¨¡å‹...")
        qwen_pipe = QwenImageEditPipeline.from_pretrained(
            QWEN_MODEL_PATH,
            torch_dtype=torch.bfloat16
        ).to('cuda')
        print("Qwen-Image-Edit æ¨¡å‹åŠ è½½å®Œæˆï¼")
    return qwen_pipe


def flux_edit_image(
    image: Image.Image,
    prompt: str,
    threshold: float,
    num_inference_steps: int,
    guidance_scale: float,
):
    """ä½¿ç”¨ FLUX æ¨¡å‹ç¼–è¾‘å›¾åƒ"""
    if image is None:
        return None, "è¯·ä¸Šä¼ å›¾ç‰‡"
    
    if not prompt.strip():
        return None, "è¯·è¾“å…¥ç¼–è¾‘æç¤ºè¯"
    
    try:
        pipe = load_flux_model()
        
        # è°ƒæ•´å›¾åƒå¤§å°ï¼Œä¿ç•™çºµæ¨ªæ¯”ï¼ˆä¸­å¿ƒè£å‰ªå¹¶ç¼©æ”¾ï¼‰ï¼Œé¿å…å›¾ç‰‡è¢«æ‹‰ä¼¸å˜å½¢
        image = ImageOps.fit(image, (1024, 1024), method=Image.BICUBIC)
        
        # é…ç½®
        config = FluxSpotEditConfig(threshold=threshold)
        
        # ç”Ÿæˆ
        result = flux_generate(
            pipe,
            image=image,
            prompt=prompt,
            config=config,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
        )
        
        return result.images[0], "ç¼–è¾‘å®Œæˆï¼"
    except Exception as e:
        return None, f"é”™è¯¯: {str(e)}"


def qwen_edit_image(
    image: Image.Image,
    prompt: str,
    threshold: float,
    num_inference_steps: int,
):
    """ä½¿ç”¨ Qwen æ¨¡å‹ç¼–è¾‘å›¾åƒ"""
    if image is None:
        return None, "è¯·ä¸Šä¼ å›¾ç‰‡"
    
    if not prompt.strip():
        return None, "è¯·è¾“å…¥ç¼–è¾‘æç¤ºè¯"
    
    try:
        pipe = load_qwen_model()
        
        # è°ƒæ•´å›¾åƒå¤§å°ï¼Œä¿ç•™çºµæ¨ªæ¯”ï¼ˆä¸­å¿ƒè£å‰ªå¹¶ç¼©æ”¾ï¼‰ï¼Œé¿å…å›¾ç‰‡è¢«æ‹‰ä¼¸å˜å½¢
        image = ImageOps.fit(image, (1024, 1024), method=Image.BICUBIC)
        
        # é…ç½®
        config = QwenSpotEditConfig(threshold=threshold)
        
        # ç”Ÿæˆ
        result = qwen_generate(
            pipe,
            image=image,
            prompt=prompt,
            config=config,
            num_inference_steps=num_inference_steps,
        )
        
        return result.images[0], "ç¼–è¾‘å®Œæˆï¼"
    except Exception as e:
        return None, f"é”™è¯¯: {str(e)}"


# ç¤ºä¾‹æ•°æ®
flux_examples = [
    [EXAMPLE_IMAGE_PATH, "add a scarf to the dog", 0.2, 50, 7.5],
]

qwen_examples = [
    [EXAMPLE_IMAGE_PATH, "add a scarf to the dog", 0.15, 50],
]


# åˆ›å»º Gradio ç•Œé¢
def create_app():
    with gr.Blocks(
        title="SpotEdit - AI å›¾åƒç¼–è¾‘å·¥å…·",
        theme=gr.themes.Soft(),
        css="""
        .header-banner {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            text-align: center;
        }
        .header-banner h1 {
            color: white;
            margin: 0;
            font-size: 2em;
        }
        .header-banner a {
            color: #ffd700;
            text-decoration: none;
            font-weight: bold;
        }
        .header-banner a:hover {
            text-decoration: underline;
        }
        """
    ) as app:
        # é¡¶éƒ¨æ¨ªå¹… - YouTube é¢‘é“ä¿¡æ¯
        gr.HTML("""
        <div class="header-banner">
            <h1>ğŸ¨ SpotEdit - AI æ™ºèƒ½å›¾åƒç¼–è¾‘å·¥å…·</h1>
            <p style="color: white; margin: 10px 0;">
                ğŸ“º æ¬¢è¿è®¿é—®æˆ‘çš„ YouTube é¢‘é“: 
                <a href="https://www.youtube.com/@rongyikanshijie-ai" target="_blank">
                    AI æŠ€æœ¯åˆ†äº«é¢‘é“
                </a>
            </p>
            <p style="color: #e0e0e0; font-size: 0.9em;">
                åŸºäº FLUX.1-Kontext å’Œ Qwen-Image-Edit æ¨¡å‹çš„ç²¾å‡†å›¾åƒç¼–è¾‘
            </p>
        </div>
        """)
        
        with gr.Tabs():
            # FLUX æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸŒŸ FLUX.1-Kontext æ¨¡å‹"):
                gr.Markdown("""
                ### ä½¿ç”¨è¯´æ˜
                1. ä¸Šä¼ ä¸€å¼ å›¾ç‰‡
                2. è¾“å…¥ç¼–è¾‘æç¤ºè¯ï¼ˆæè¿°ä½ æƒ³è¦çš„ä¿®æ”¹ï¼‰
                3. è°ƒæ•´å‚æ•°ï¼ˆå¯é€‰ï¼‰
                4. ç‚¹å‡»"å¼€å§‹ç¼–è¾‘"æŒ‰é’®
                """)
                
                with gr.Row():
                    with gr.Column(scale=1):
                        flux_input_image = gr.Image(
                            label="è¾“å…¥å›¾ç‰‡",
                            type="pil",
                            height=400,
                        )
                        flux_prompt = gr.Textbox(
                            label="ç¼–è¾‘æç¤ºè¯",
                            placeholder="ä¾‹å¦‚: add a scarf to the dog",
                            lines=2,
                        )
                        
                        with gr.Accordion("é«˜çº§å‚æ•°", open=False):
                            flux_threshold = gr.Slider(
                                label="ç¼–è¾‘é˜ˆå€¼ (Threshold)",
                                minimum=0.05,
                                maximum=0.5,
                                value=0.2,
                                step=0.05,
                                info="æ§åˆ¶ç¼–è¾‘åŒºåŸŸçš„å¤§å°ï¼Œå€¼è¶Šå¤§ç¼–è¾‘èŒƒå›´è¶Šå°",
                            )
                            flux_steps = gr.Slider(
                                label="æ¨ç†æ­¥æ•° (Steps)",
                                minimum=10,
                                maximum=100,
                                value=50,
                                step=5,
                                info="æ­¥æ•°è¶Šå¤šè´¨é‡è¶Šé«˜ï¼Œä½†é€Ÿåº¦è¶Šæ…¢",
                            )
                            flux_guidance = gr.Slider(
                                label="å¼•å¯¼ç³»æ•° (Guidance Scale)",
                                minimum=1.0,
                                maximum=15.0,
                                value=7.5,
                                step=0.5,
                                info="æ§åˆ¶æç¤ºè¯çš„å½±å“å¼ºåº¦",
                            )
                        
                        flux_submit_btn = gr.Button(
                            "ğŸš€ å¼€å§‹ç¼–è¾‘",
                            variant="primary",
                            size="lg",
                        )
                    
                    with gr.Column(scale=1):
                        flux_output_image = gr.Image(
                            label="ç¼–è¾‘ç»“æœ",
                            type="pil",
                            height=400,
                        )
                        flux_status = gr.Textbox(
                            label="çŠ¶æ€",
                            interactive=False,
                        )
                
                # FLUX ç¤ºä¾‹
                gr.Examples(
                    examples=flux_examples,
                    inputs=[
                        flux_input_image,
                        flux_prompt,
                        flux_threshold,
                        flux_steps,
                        flux_guidance,
                    ],
                    outputs=[flux_output_image, flux_status],
                    fn=flux_edit_image,
                    cache_examples=False,
                    label="ç¤ºä¾‹",
                )
                
                # FLUX æŒ‰é’®ç‚¹å‡»äº‹ä»¶
                flux_submit_btn.click(
                    fn=flux_edit_image,
                    inputs=[
                        flux_input_image,
                        flux_prompt,
                        flux_threshold,
                        flux_steps,
                        flux_guidance,
                    ],
                    outputs=[flux_output_image, flux_status],
                )
            
            # Qwen æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ¯ Qwen-Image-Edit æ¨¡å‹"):
                gr.Markdown("""
                ### ä½¿ç”¨è¯´æ˜
                1. ä¸Šä¼ ä¸€å¼ å›¾ç‰‡
                2. è¾“å…¥ç¼–è¾‘æç¤ºè¯ï¼ˆæè¿°ä½ æƒ³è¦çš„ä¿®æ”¹ï¼‰
                3. è°ƒæ•´å‚æ•°ï¼ˆå¯é€‰ï¼‰
                4. ç‚¹å‡»"å¼€å§‹ç¼–è¾‘"æŒ‰é’®
                """)
                
                with gr.Row():
                    with gr.Column(scale=1):
                        qwen_input_image = gr.Image(
                            label="è¾“å…¥å›¾ç‰‡",
                            type="pil",
                            height=400,
                        )
                        qwen_prompt = gr.Textbox(
                            label="ç¼–è¾‘æç¤ºè¯",
                            placeholder="ä¾‹å¦‚: add a scarf to the dog",
                            lines=2,
                        )
                        
                        with gr.Accordion("é«˜çº§å‚æ•°", open=False):
                            qwen_threshold = gr.Slider(
                                label="ç¼–è¾‘é˜ˆå€¼ (Threshold)",
                                minimum=0.05,
                                maximum=0.5,
                                value=0.15,
                                step=0.05,
                                info="æ§åˆ¶ç¼–è¾‘åŒºåŸŸçš„å¤§å°ï¼Œå€¼è¶Šå¤§ç¼–è¾‘èŒƒå›´è¶Šå°",
                            )
                            qwen_steps = gr.Slider(
                                label="æ¨ç†æ­¥æ•° (Steps)",
                                minimum=10,
                                maximum=100,
                                value=50,
                                step=5,
                                info="æ­¥æ•°è¶Šå¤šè´¨é‡è¶Šé«˜ï¼Œä½†é€Ÿåº¦è¶Šæ…¢",
                            )
                        
                        qwen_submit_btn = gr.Button(
                            "ğŸš€ å¼€å§‹ç¼–è¾‘",
                            variant="primary",
                            size="lg",
                        )
                    
                    with gr.Column(scale=1):
                        qwen_output_image = gr.Image(
                            label="ç¼–è¾‘ç»“æœ",
                            type="pil",
                            height=400,
                        )
                        qwen_status = gr.Textbox(
                            label="çŠ¶æ€",
                            interactive=False,
                        )
                
                # Qwen ç¤ºä¾‹
                gr.Examples(
                    examples=qwen_examples,
                    inputs=[
                        qwen_input_image,
                        qwen_prompt,
                        qwen_threshold,
                        qwen_steps,
                    ],
                    outputs=[qwen_output_image, qwen_status],
                    fn=qwen_edit_image,
                    cache_examples=False,
                    label="ç¤ºä¾‹",
                )
                
                # Qwen æŒ‰é’®ç‚¹å‡»äº‹ä»¶
                qwen_submit_btn.click(
                    fn=qwen_edit_image,
                    inputs=[
                        qwen_input_image,
                        qwen_prompt,
                        qwen_threshold,
                        qwen_steps,
                    ],
                    outputs=[qwen_output_image, qwen_status],
                )
        
        # åº•éƒ¨ä¿¡æ¯
        gr.Markdown("""
        ---
        ### å…³äº
        - **FLUX.1-Kontext**: Black Forest Labs å‡ºå“çš„é«˜è´¨é‡å›¾åƒç¼–è¾‘æ¨¡å‹
        - **Qwen-Image-Edit**: é˜¿é‡Œå·´å·´é€šä¹‰åƒé—®å›¢é˜Ÿå‡ºå“çš„å›¾åƒç¼–è¾‘æ¨¡å‹
        - **SpotEdit**: ç²¾å‡†çš„å±€éƒ¨ç¼–è¾‘æŠ€æœ¯ï¼Œåªä¿®æ”¹éœ€è¦æ”¹å˜çš„åŒºåŸŸ
        
        ğŸ’¡ **æç¤º**: ç¼–è¾‘æç¤ºè¯ä½¿ç”¨è‹±æ–‡æ•ˆæœæ›´å¥½
        """)
    
    return app


if __name__ == "__main__":
    print("=" * 50)
    print("SpotEdit - AI æ™ºèƒ½å›¾åƒç¼–è¾‘å·¥å…·")
    print("=" * 50)
    print(f"FLUX æ¨¡å‹è·¯å¾„: {FLUX_MODEL_PATH}")
    print(f"Qwen æ¨¡å‹è·¯å¾„: {QWEN_MODEL_PATH}")
    print("=" * 50)
    
    # é¢„åŠ è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼Œå–æ¶ˆæ³¨é‡Šä»¥åœ¨å¯åŠ¨æ—¶åŠ è½½ï¼‰
    print("æ­£åœ¨é¢„åŠ è½½æ¨¡å‹...")
    load_flux_model()
    load_qwen_model()
    print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
    
    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    app = create_app()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
    )
