"""
M4-2: å®ç”¨æŠ€å·§ - æ–‡æœ¬æ ¼å¼åŒ–å¢å¼º (è¿­ä»£ç‰ˆ)

æœ¬è„šæœ¬åœ¨ M4-1 çš„åŸºç¡€ä¸Šï¼Œå¢åŠ äº†ä¸€æ­¥æ–‡æœ¬æ ¼å¼åŒ–å¤„ç†ï¼š
ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è‡ªåŠ¨ä¸ºä¸­è‹±æ–‡æ··åˆæ–‡æœ¬æ·»åŠ ç©ºæ ¼ï¼Œä»¥ä¼˜åŒ–æ’ç‰ˆã€‚
å¤„ç†æµç¨‹å˜ä¸ºï¼š è½¬å½• -> çƒ­è¯æ›¿æ¢ -> æ ¼å¼åŒ– -> ä¿å­˜ã€‚
"""
import os
import whisper
import datetime
import torch
import re  # <--- æ–°å¢ï¼šå¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—

# --- 1. è¾…åŠ©å‡½æ•°ï¼šè‡ªå®šä¹‰ SRT æ–‡ä»¶å†™å…¥ (ä¿æŒä¸å˜) ---
def generate_srt_file(segments, output_path):
    """æ ¹æ®å­—å¹•åˆ†æ®µä¿¡æ¯ï¼Œç”Ÿæˆæ ‡å‡† SRT æ–‡ä»¶ã€‚"""
    with open(output_path, 'w', encoding='utf-8') as srt_file:
        for i, segment in enumerate(segments):
            start_time = str(datetime.timedelta(seconds=segment['start']))
            end_time = str(datetime.timedelta(seconds=segment['end']))
            start_time = start_time if '.' in start_time else start_time + '.000000'
            end_time = end_time if '.' in end_time else end_time + '.000000'
            start_ms = start_time.split('.')[-1][:3]
            end_ms = end_time.split('.')[-1][:3]
            start_time_str = start_time.split('.')[0] + f',{start_ms}'
            end_time_str = end_time.split('.')[0] + f',{end_ms}'
            text = segment['text'].strip()
            srt_file.write(f"{i + 1}\n")
            srt_file.write(f"{start_time_str} --> {end_time_str}\n")
            srt_file.write(f"{text}\n\n")
    print(f"âœ”ï¸ SRT æ–‡ä»¶å·²ä¿å­˜åˆ°: {os.path.abspath(output_path)}")

# --- 2. æ ¸å¿ƒå‡½æ•°ï¼šæ–‡æœ¬åå¤„ç† (åˆ†æ­¥è¿›è¡Œ) ---
def apply_text_replacements(original_segments, replacement_map):
    """ç¬¬ä¸€æ­¥å¤„ç†ï¼šå¯¹åˆ†æ®µæ–‡æœ¬åº”ç”¨çƒ­è¯æ›¿æ¢è§„åˆ™ã€‚"""
    import copy
    processed_segments = copy.deepcopy(original_segments)
    
    print("\n>>> æ­¥éª¤ 3.1: æ­£åœ¨åº”ç”¨ã€çƒ­è¯æ›¿æ¢ã€‘è§„åˆ™...")
    for segment in processed_segments:
        for old_word, new_word in replacement_map.items():
            segment['text'] = segment['text'].replace(old_word, new_word)
    print("âœ”ï¸ çƒ­è¯æ›¿æ¢å®Œæˆã€‚")
    return processed_segments

# <--- æ–°å¢ï¼šæ ¼å¼åŒ–å¤„ç†å‡½æ•° ---
def apply_spacing_rules(segments_after_replacement):
    """ç¬¬äºŒæ­¥å¤„ç†ï¼šä¸ºä¸­è‹±æ–‡æ··åˆæ–‡æœ¬æ·»åŠ ç©ºæ ¼ã€‚"""
    print("\n>>> æ­¥éª¤ 3.2: æ­£åœ¨åº”ç”¨ã€æ ¼å¼åŒ–ã€‘è§„åˆ™ (ä¸­è‹±æ–‡åŠ ç©ºæ ¼)...")
    
    # æ¨¡å¼1ï¼šä¸­æ–‡ + è‹±æ–‡/æ•°å­— -> ä¸­æ–‡ + ç©ºæ ¼ + è‹±æ–‡/æ•°å­—
    # ä¿®æ”¹ï¼šåŒ¹é…ä»»æ„é•¿åº¦çš„è‹±æ–‡å•è¯ï¼ˆåŒ…æ‹¬å•ä¸ªå­—æ¯ï¼‰
    pattern1 = re.compile(r'([\u4e00-\u9fa5])([a-zA-Z0-9]+)')
    
    # æ¨¡å¼2ï¼šè‹±æ–‡/æ•°å­— + ä¸­æ–‡ -> è‹±æ–‡/æ•°å­— + ç©ºæ ¼ + ä¸­æ–‡  
    # ä¿®æ”¹ï¼šåŒ¹é…ä»»æ„é•¿åº¦çš„è‹±æ–‡å•è¯ï¼ˆåŒ…æ‹¬å•ä¸ªå­—æ¯ï¼‰
    pattern2 = re.compile(r'([a-zA-Z0-9]+)([\u4e00-\u9fa5])')
    
    for segment in segments_after_replacement:
        # å…ˆå¤„ç†ä¸­æ–‡åé¢è·Ÿè‹±æ–‡çš„æƒ…å†µ
        segment['text'] = pattern1.sub(r'\1 \2', segment['text'])
        # å†å¤„ç†è‹±æ–‡åé¢è·Ÿä¸­æ–‡çš„æƒ…å†µ
        segment['text'] = pattern2.sub(r'\1 \2', segment['text'])
        
    print("âœ”ï¸ æ ¼å¼åŒ–å®Œæˆã€‚")
    return segments_after_replacement
# <--- æ–°å¢ç»“æŸ ---

# --- 3. ä¸»æµç¨‹å‡½æ•° ---
def run_transcription_pipeline(model_name, media_path, language, replacement_map):
    """æ‰§è¡Œå®Œæ•´çš„è½¬å½•å’Œåå¤„ç†æµç¨‹ã€‚"""
    start_time = datetime.datetime.now()
    
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = script_dir
    model_path = os.path.join(script_dir, '..', 'models', f"{model_name}.pt")
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æœ¬åœ°æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ° -> {model_path}")
        return
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # --- æ­¥éª¤ 1 & 2: åŠ è½½ä¸è½¬å½• ---
    print(f">>> æ­¥éª¤ 1: æ­£åœ¨ä» '{model_path}' åŠ è½½ '{model_name}' æ¨¡å‹åˆ° {device}...")
    model = whisper.load_model(model_path, device=device)
    print(f"\n>>> æ­¥éª¤ 2: æ­£åœ¨è½¬å½•éŸ³é¢‘æ–‡ä»¶ '{media_path}'...")
    result = model.transcribe(media_path, language=language, verbose=True)
    print("âœ”ï¸ åŸå§‹è½¬å½•å®Œæˆã€‚")

    print("\n" + "="*25 + " åŸå§‹è½¬å½•æ–‡æœ¬ " + "="*25)
    print(result['text'])
    print("="*65)
    
    # --- æ­¥éª¤ 3: å¤šæ­¥åæœŸå¤„ç† ---
    # <--- ä¿®æ”¹ï¼šå°†å¤„ç†æµç¨‹ä¸²è”èµ·æ¥ ---
    segments_after_replacement = apply_text_replacements(result['segments'], replacement_map)
    final_processed_segments = apply_spacing_rules(segments_after_replacement)
    # <--- ä¿®æ”¹ç»“æŸ ---
    
    # --- æ¼”ç¤ºç‚¹ï¼šå±•ç¤ºæœ€ç»ˆå¤„ç†åç»“æœ ---
    processed_full_text = " ".join(s['text'].strip() for s in final_processed_segments)
    print("\n" + "="*25 + " æœ€ç»ˆå¤„ç†åæ–‡æœ¬ " + "="*25)
    print(processed_full_text)
    print("="*65)
    
    # --- æ­¥éª¤ 4: ä¿å­˜æ–‡ä»¶ ---
    print("\n>>> æ­¥éª¤ 4: æ­£åœ¨ä¿å­˜ç»“æœæ–‡ä»¶...")
    base_filename = os.path.splitext(os.path.basename(media_path))[0]
    
    # ä¿å­˜åŸå§‹æ–‡ä»¶ä»¥ä¾›å¯¹æ¯”
    original_srt_path = os.path.join(output_dir, f"{base_filename}_original.srt")
    generate_srt_file(result['segments'], original_srt_path)
    
    # ä¿å­˜æœ€ç»ˆå¤„ç†åçš„æ–‡ä»¶
    processed_srt_path = os.path.join(output_dir, f"{base_filename}_processed.srt")
    generate_srt_file(final_processed_segments, processed_srt_path)
    
    end_time = datetime.datetime.now()
    print(f'\nğŸ‰ å…¨éƒ¨æµç¨‹å®Œæˆ! æ€»è€—æ—¶: {end_time - start_time}')

# --- â€œæ§åˆ¶é¢æ¿â€ ---
if __name__ == "__main__":
    REPLACEMENT_MAP = {
        "ä¹Œç­å›¾": "Ubuntu",
        "å‰ç‰¹å“ˆå¸ƒ": "GitHub", # <--- æ–°å¢ä¸€ä¸ªä¾‹å­ç”¨äºæµ‹è¯•æ ¼å¼åŒ–
        "Moddy Talk": "MultiTalk",
        "å‘¢": "",
    }

    MODEL_NAME = "large-v3"
    MEDIA_FILE = "../audio/139.wav"
    LANGUAGE = "zh"

    script_dir = os.path.dirname(os.path.abspath(__file__))
    media_path_full = os.path.join(script_dir, MEDIA_FILE)
    
    run_transcription_pipeline(
        model_name=MODEL_NAME, 
        media_path=media_path_full, 
        language=LANGUAGE,
        replacement_map=REPLACEMENT_MAP
    )