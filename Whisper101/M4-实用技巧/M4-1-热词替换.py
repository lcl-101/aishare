"""
M4-1: å®ç”¨æŠ€å·§ - çƒ­è¯æ›¿æ¢ä¸é«˜çº§å¤„ç† (æ•™å­¦æ¼”ç¤ºç‰ˆ)

æœ¬è„šæœ¬ä¸ºæ•™å­¦æ¼”ç¤ºä¼˜åŒ–ï¼Œæ¸…æ™°åœ°å±•ç¤ºäº†ä»¥ä¸‹æµç¨‹ï¼š
1. ä½¿ç”¨ Whisper è¿›è¡ŒåŸºç¡€è½¬å½•ã€‚
2. åœ¨æ§åˆ¶å°å±•ç¤ºåŸå§‹è½¬å½•ç»“æœã€‚
3. å¯¹è½¬å½•ç»“æœåº”ç”¨è‡ªå®šä¹‰çš„æ–‡æœ¬æ›¿æ¢è§„åˆ™ã€‚
4. åœ¨æ§åˆ¶å°å±•ç¤ºå¤„ç†åçš„è½¬å½•ç»“æœï¼Œå½¢æˆç›´è§‚å¯¹æ¯”ã€‚
5. å°†åŸå§‹ç»“æœå’Œå¤„ç†åç»“æœåˆ†åˆ«ä¿å­˜ä¸º SRT æ–‡ä»¶ï¼Œä»¥ä¾¿åç»­åˆ†æã€‚
"""
import os
import whisper
import datetime
import torch

# --- 1. è¾…åŠ©å‡½æ•°ï¼šè‡ªå®šä¹‰ SRT æ–‡ä»¶å†™å…¥ ---
def generate_srt_file(segments, output_path):
    """æ ¹æ®å­—å¹•åˆ†æ®µä¿¡æ¯ï¼Œç”Ÿæˆæ ‡å‡† SRT æ–‡ä»¶ã€‚"""
    with open(output_path, 'w', encoding='utf-8') as srt_file:
        for i, segment in enumerate(segments):
            # ä½¿ç”¨ timedelta è¿›è¡Œç²¾ç¡®çš„æ—¶é—´æ ¼å¼åŒ–
            start_time = str(datetime.timedelta(seconds=segment['start']))
            end_time = str(datetime.timedelta(seconds=segment['end']))
            # ç¡®ä¿æ¯«ç§’éƒ¨åˆ†æ˜¯ä¸‰ä½æ•°
            start_time = start_time if '.' in start_time else start_time + '.000000'
            end_time = end_time if '.' in end_time else end_time + '.000000'
            start_ms = start_time.split('.')[-1][:3]
            end_ms = end_time.split('.')[-1][:3]
            start_time_str = start_time.split('.')[0] + f',{start_ms}'
            end_time_str = end_time.split('.')[0] + f',{end_ms}'

            text = segment['text'].strip()
            
            srt_file.write(f"{i + 1}\n")
            srt_file.write(f"{start_time_str} --> {end_time_str}\n")
            srt_file.write(f"{text}\n\n")
    print(f"âœ”ï¸ SRT æ–‡ä»¶å·²ä¿å­˜åˆ°: {os.path.abspath(output_path)}")

# --- 2. æ ¸å¿ƒå‡½æ•°ï¼šæ–‡æœ¬åå¤„ç† ---
def apply_text_replacements(original_segments, replacement_map):
    """å¯¹åˆ†æ®µæ–‡æœ¬åº”ç”¨æ›¿æ¢è§„åˆ™ã€‚"""
    import copy
    # åˆ›å»ºä¸€ä¸ªæ·±æ‹·è´ï¼Œä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    processed_segments = copy.deepcopy(original_segments)
    
    print("\n>>> æ­¥éª¤ 3: æ­£åœ¨å¯¹æ–‡æœ¬åº”ç”¨è‡ªå®šä¹‰æ›¿æ¢è§„åˆ™...")
    for segment in processed_segments:
        for old_word, new_word in replacement_map.items():
            segment['text'] = segment['text'].replace(old_word, new_word)
    print("âœ”ï¸ æ–‡æœ¬æ›¿æ¢å®Œæˆã€‚")
    return processed_segments

# --- 3. ä¸»æµç¨‹å‡½æ•° ---
def run_transcription_pipeline(model_name, media_path, language, replacement_map):
    """æ‰§è¡Œå®Œæ•´çš„è½¬å½•å’Œåå¤„ç†æµç¨‹ã€‚"""
    start_time = datetime.datetime.now()
    
    # --- ç¯å¢ƒå’Œè·¯å¾„å‡†å¤‡ ---
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = script_dir  # ä¿å­˜åˆ°å½“å‰ç›®å½•
    
    model_path = os.path.join(script_dir, '..', 'models', f"{model_name}.pt")
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æœ¬åœ°æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ° -> {model_path}")
        return

    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # --- æ­¥éª¤ 1: åŠ è½½ä¸è½¬å½• ---
    print(f">>> æ­¥éª¤ 1: æ­£åœ¨ä» '{model_path}' åŠ è½½ '{model_name}' æ¨¡å‹åˆ° {device}...")
    model = whisper.load_model(model_path, device=device)
    
    print(f"\n>>> æ­¥éª¤ 2: æ­£åœ¨è½¬å½•éŸ³é¢‘æ–‡ä»¶ '{media_path}'...")
    result = model.transcribe(media_path, language=language, verbose=True)
    print("âœ”ï¸ åŸå§‹è½¬å½•å®Œæˆã€‚")

    # --- æ¼”ç¤ºç‚¹ 1: å±•ç¤ºåŸå§‹ç»“æœ ---
    print("\n" + "="*25 + " åŸå§‹è½¬å½•æ–‡æœ¬ " + "="*25)
    print(result['text'])
    print("="*65)
    
    # --- æ­¥éª¤ 3: åæœŸå¤„ç† ---
    processed_segments = apply_text_replacements(result['segments'], replacement_map)
    
    # --- æ¼”ç¤ºç‚¹ 2: å±•ç¤ºå¤„ç†åç»“æœ ---
    processed_full_text = " ".join(s['text'].strip() for s in processed_segments)
    print("\n" + "="*25 + " å¤„ç†åè½¬å½•æ–‡æœ¬ " + "="*25)
    print(processed_full_text)
    print("="*65)
    
    # --- æ­¥éª¤ 4: ä¿å­˜æ–‡ä»¶ ---
    print("\n>>> æ­¥éª¤ 4: æ­£åœ¨ä¿å­˜ç»“æœæ–‡ä»¶...")
    base_filename = os.path.splitext(os.path.basename(media_path))[0]
    
    # ä¿å­˜åŸå§‹æ–‡ä»¶ä»¥ä¾›å¯¹æ¯”
    original_srt_path = os.path.join(output_dir, f"{base_filename}_original.srt")
    generate_srt_file(result['segments'], original_srt_path)
    
    # ä¿å­˜å¤„ç†åçš„æ–‡ä»¶
    processed_srt_path = os.path.join(output_dir, f"{base_filename}_processed.srt")
    generate_srt_file(processed_segments, processed_srt_path)
    
    end_time = datetime.datetime.now()
    print(f'\nğŸ‰ å…¨éƒ¨æµç¨‹å®Œæˆ! æ€»è€—æ—¶: {end_time - start_time}')

# --- â€œæ§åˆ¶é¢æ¿â€ï¼šåœ¨è¿™é‡Œä¿®æ”¹é…ç½® ---
if __name__ == "__main__":
    # 1. å®šä¹‰ä½ çš„çƒ­è¯å’Œæ›¿æ¢è§„åˆ™
    REPLACEMENT_MAP = {
        "ä¹Œç­å›¾": " Ubuntu",      # ä¸­è‹±æ–‡ä¹‹é—´åŠ ç©ºæ ¼
        "Moddy Talk": "MultiTalk",  # ä¿®æ­£é”™è¯¯è¯†åˆ«å¹¶åŠ ç©ºæ ¼
        "MultiTalk": " MultiTalk",   # ä¸­è‹±æ–‡ä¹‹é—´åŠ ç©ºæ ¼
        "å‘¢": "",       # åˆ é™¤å£æ°´è¯
    }

    # 2. æŒ‡å®šè¦ä½¿ç”¨çš„æ¨¡å‹å’ŒéŸ³é¢‘æ–‡ä»¶
    MODEL_NAME = "large-v3"
    MEDIA_FILE = "../audio/139.wav"
    LANGUAGE = "zh" # ä½¿ç”¨ ISO 639-1 è¯­è¨€ä»£ç 

    # 3. è¿è¡Œä¸»æµç¨‹
    script_dir = os.path.dirname(os.path.abspath(__file__))
    media_path_full = os.path.join(script_dir, MEDIA_FILE)
    
    run_transcription_pipeline(
        model_name=MODEL_NAME, 
        media_path=media_path_full, 
        language=LANGUAGE,
        replacement_map=REPLACEMENT_MAP
    )