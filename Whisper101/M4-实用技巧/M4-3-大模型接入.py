"""
M4-4: æ™ºèƒ½åå¤„ç† - åœé¡¿æ„ŸçŸ¥å¢å¼ºç‰ˆ (ç»ˆæç‰ˆ)

æœ¬è„šæœ¬æ˜¯ M4-3 çš„é‡å¤§å‡çº§ï¼Œå¼•å…¥äº†â€œåœé¡¿æ„ŸçŸ¥â€èƒ½åŠ›ï¼š
1.  **åˆ©ç”¨ Whisper åˆ†æ®µä¿¡æ¯**: å°† Whisper çš„ segments é—´çš„è‡ªç„¶åœé¡¿ä½œä¸ºå¼ºä¿¡å· ([P]) æä¾›ç»™ LLMã€‚
2.  **å…¨æ–° Prompt**: è®¾è®¡äº†ä¸“é—¨çš„ Promptï¼ŒæŒ‡å¯¼ LLM ç†è§£å¹¶åˆ©ç”¨ [P] æ ‡è®°ï¼Œå®ç°æ›´ç²¾å‡†ã€æ›´è‡ªç„¶çš„æ–­å¥ã€‚
3.  ä¿ç•™äº†ä¹‹å‰ç‰ˆæœ¬çš„æ‰€æœ‰ä¼˜ç‚¹ï¼šè¯¦ç»†çš„è€—æ—¶ç»Ÿè®¡ã€æ¸…æ™°çš„æµç¨‹ã€æ”¯æŒå¤šç§æ¨¡å‹åŠ è½½æ–¹å¼ç­‰ã€‚

ä¾èµ–å®‰è£…ï¼š
pip install ollama

ç¡®ä¿OllamaæœåŠ¡å·²å¯åŠ¨ï¼š
ollama serve

ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚éœ€è¦ï¼‰ï¼š
ollama pull qwen2.5:72b
"""
import os
import whisper
import datetime
import torch
import re
import ollama

# --- 1. æ–‡æœ¬å¤„ç†å‡½æ•° ---
def apply_replacements(text, replacement_map):
    """å¯¹å•ä¸ªæ–‡æœ¬ç‰‡æ®µåº”ç”¨çƒ­è¯æ›¿æ¢è§„åˆ™ã€‚"""
    for old_word, new_word in replacement_map.items():
        text = text.replace(old_word, new_word)
    return text

def add_spaces_around_english(text):
    """ä¸ºä¸­è‹±æ–‡æ··æ’æ–‡æœ¬è‡ªåŠ¨æ·»åŠ ç©ºæ ¼ã€‚"""
    pattern1 = re.compile(r'([\u4e00-\u9fa5])([a-zA-Z0-9]+)')
    pattern2 = re.compile(r'([a-zA-Z0-9]+)([\u4e00-\u9fa5])')
    text = pattern1.sub(r'\1 \2', text)
    text = pattern2.sub(r'\1 \2', text)
    return text

# <--- é‡ç‚¹ä¿®æ”¹ï¼šæ­¤å‡½æ•°ç°åœ¨æ¥æ”¶ segmentsï¼Œå¹¶ä½¿ç”¨å¸¦ [P] çš„ Prompt ---
def enhance_punctuation_with_llm(segments, llm_model_name):
    """
    ä½¿ç”¨ LLM ä¸ºæ–‡æœ¬æ™ºèƒ½æ·»åŠ æ ‡ç‚¹ï¼Œåˆ©ç”¨ Whisper çš„åˆ†æ®µä½œä¸ºåœé¡¿ä¿¡å·ã€‚
    """
    # 1. åœ¨ segment ä¹‹é—´æ’å…¥ [P] æ ‡è®°ä½œä¸ºåœé¡¿æç¤º
    # ["ä½ å¥½", "ä»Šå¤©å¤©æ°”ä¸é”™"] -> "ä½ å¥½[P]ä»Šå¤©å¤©æ°”ä¸é”™"
    text_with_pauses = "[P]".join([s['text'].strip() for s in segments if s['text'].strip()])

    if not text_with_pauses.strip():
        print("âš ï¸ æ–‡æœ¬å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ LLM å¤„ç†ã€‚")
        return "" # è¿”å›ç©ºå­—ç¬¦ä¸²

    # 2. æ„å»ºæ–°çš„ã€æ›´æ™ºèƒ½çš„ Prompt
    prompt = f"""# è§’è‰²
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„ä¸­æ–‡æ–‡æ¡ˆç¼–è¾‘ï¼Œèƒ½æ·±åˆ»ç†è§£è¯­éŸ³èŠ‚å¥å’Œä¹¦é¢è¡¨è¾¾çš„è½¬æ¢ã€‚

# ä»»åŠ¡
ä¸ºä¸‹é¢çš„åŸå§‹æ–‡æœ¬æ·»åŠ æ ‡ç‚¹ã€‚è¿™æ®µæ–‡æœ¬ç”±å¤šä¸ªè¯­éŸ³ç‰‡æ®µæ‹¼æ¥è€Œæˆï¼Œæˆ‘ä½¿ç”¨äº†ç‰¹æ®Šæ ‡è®° `[P]` æ¥è¡¨ç¤ºåŸå§‹è¯­éŸ³ä¸­çš„è‡ªç„¶åœé¡¿ç‚¹ã€‚

# æŒ‡å¯¼åŸåˆ™
1.  **å…³é”®æŒ‡ä»¤**: `[P]` æ ‡è®°å¤„æ˜¯å¼ºçƒˆçš„æ–­å¥æç¤ºã€‚ä½ åº”è¯¥åœ¨è¿™äº›ä½ç½®ä¼˜å…ˆè€ƒè™‘ä½¿ç”¨é€—å·ï¼ˆï¼Œï¼‰æˆ–å¥å·ï¼ˆã€‚ï¼‰ã€‚
2.  **å¥å†…å¾®è°ƒ**: å³ä½¿åœ¨æ²¡æœ‰ `[P]` æ ‡è®°çš„ç‰‡æ®µå†…éƒ¨ï¼Œå¦‚æœå¥å­è¿‡é•¿ï¼Œä½ ä¹Ÿå¯ä»¥æ ¹æ®é€»è¾‘æ·»åŠ é€—å·ã€‚
3.  **å¿ å®å†…å®¹**: ç»å¯¹ä¸å…è®¸å¢åˆ æˆ–æ”¹åŠ¨åŸæ–‡çš„ä»»ä½•æ±‰å­—æˆ–è‹±æ–‡å•è¯ã€‚
4.  **æœ€ç»ˆè¾“å‡º**: åœ¨æœ€ç»ˆç»“æœä¸­ï¼Œå¿…é¡»ç§»é™¤æ‰€æœ‰çš„ `[P]` æ ‡è®°ã€‚

# å¾…å¤„ç†æ–‡æœ¬
---
{text_with_pauses}
---

# è¾“å‡ºè¦æ±‚
ç›´æ¥è¾“å‡ºç»è¿‡ä½ ç²¾ç»†ç¼–è¾‘å’Œæ ‡ç‚¹ä¼˜åŒ–åçš„æœ€ç»ˆæ–‡æœ¬ï¼Œç¡®ä¿ä¸å« `[P]` æ ‡è®°ã€‚"""

    # 3. è°ƒç”¨ Ollama API
    try:
        print("   ğŸ”„ æ­£åœ¨å‘é€è¯·æ±‚åˆ° Ollama...")
        response = ollama.chat(
            model=llm_model_name,
            messages=[{'role': 'user', 'content': prompt}],
            options={'temperature': 0.2} # è¾ƒä½çš„æ¸©åº¦è®©è¾“å‡ºæ›´ç¨³å®š
        )
        punctuated_text = response['message']['content'].strip()
        print("   âœ… Ollama å¤„ç†å®Œæˆã€‚")
        return punctuated_text
    except Exception as e:
        print(f"âŒ è°ƒç”¨ Ollama API æ—¶å‡ºé”™: {e}")
        # å‡ºé”™æ—¶ï¼Œè¿”å›ä¸€ä¸ªä¸å¸¦æ ‡ç‚¹çš„ã€æ‹¼æ¥å¥½çš„æ–‡æœ¬ä½œä¸ºåå¤‡
        fallback_text = " ".join([s['text'].strip() for s in segments])
        print("   âš ï¸ å°†ä½¿ç”¨æœªå¤„ç†çš„åŸå§‹æ‹¼æ¥æ–‡æœ¬ç»§ç»­ã€‚")
        return fallback_text

def save_text_file(text, output_path):
    """å°†æ–‡æœ¬ä¿å­˜ä¸º TXT æ–‡ä»¶ã€‚"""
    with open(output_path, 'w', encoding='utf-8') as txt_file:
        txt_file.write(text)
    print(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜: {os.path.abspath(output_path)}")

# --- 2. ä¸»æµç¨‹å‡½æ•° ---
def run_transcription_pipeline(model_name, media_path, language, replacement_map, llm_model_name):
    """æ‰§è¡Œå®Œæ•´çš„è½¬å½•å’Œåå¤„ç†æµç¨‹ï¼Œæ¯ä¸€æ­¥éƒ½æœ‰è¯¦ç»†çš„è€—æ—¶ç»Ÿè®¡ã€‚"""
    print("ğŸš€ å¼€å§‹ Whisper è¯­éŸ³è½¬å½•ä¸æ™ºèƒ½åå¤„ç†æµç¨‹ (v4.0 - åœé¡¿æ„ŸçŸ¥ç‰ˆ)")
    print("=" * 70)
    
    total_start_time = datetime.datetime.now()
    script_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in locals() else '.'
    output_dir = script_dir
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # --- æ­¥éª¤ 1: åŠ è½½æ¨¡å‹ (ä»£ç ä¸å˜) ---
    # ... (ä¸æ‚¨æä¾›çš„ä»£ç å®Œå…¨ç›¸åŒ)
    step1_start = datetime.datetime.now()
    print(f"ğŸ”§ æ­¥éª¤ 1: æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ '{model_name}' åˆ° {device}...")
    if os.path.exists(model_name) or '/' in model_name or model_name.endswith('.pt'):
        model = whisper.load_model(model_name, device=device)
        print(f"   ğŸ“‚ ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶: {model_name}")
    else:
        model = whisper.load_model(model_name, device=device)
        print(f"   ğŸŒ ä½¿ç”¨åœ¨çº¿æ¨¡å‹: {model_name}")
    step1_end = datetime.datetime.now()
    step1_duration = step1_end - step1_start
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆã€‚è€—æ—¶: {step1_duration}\n")

    # --- æ­¥éª¤ 2: è½¬å½•éŸ³é¢‘ (ä»£ç ä¸å˜) ---
    step2_start = datetime.datetime.now()
    print(f"ğŸ™ï¸ æ­¥éª¤ 2: æ­£åœ¨è½¬å½•éŸ³é¢‘æ–‡ä»¶...")
    print(f"   ğŸ“„ æ–‡ä»¶è·¯å¾„: {media_path}")
    print(f"   ğŸŒ è¯­è¨€è®¾ç½®: {language}")
    
    result = model.transcribe(media_path, language=language, verbose=False)
    # <--- ä¿®æ”¹ï¼šç°åœ¨æˆ‘ä»¬ä¿ç•™ segmentsï¼ŒåŸå§‹æ–‡æœ¬ä»…ç”¨äºå±•ç¤º ---
    original_segments = result['segments']
    original_text_display = result['text'].strip()
    
    step2_end = datetime.datetime.now()
    step2_duration = step2_end - step2_start
    print(f"âœ… éŸ³é¢‘è½¬å½•å®Œæˆã€‚è€—æ—¶: {step2_duration}")
    print(f"ğŸ“Š åŸå§‹æ–‡æœ¬é•¿åº¦: {len(original_text_display)} å­—ç¬¦, åˆ†æ®µæ•°: {len(original_segments)}")
    
    print("\nğŸ“ åŸå§‹è½¬å½•æ–‡æœ¬ (æ— æ ‡ç‚¹æ‹¼æ¥):")
    print("-" * 50)
    print(original_text_display)
    print("-" * 50 + "\n")
    
    # <--- ä¿®æ”¹ï¼šåç»­å¤„ç†ç°åœ¨åŸºäº segments ---
    # --- æ­¥éª¤ 3 & 4: é€æ®µè¿›è¡Œçƒ­è¯æ›¿æ¢å’Œç©ºæ ¼å¤„ç† ---
    step3_4_start = datetime.datetime.now()
    print("ğŸ”„ æ­¥éª¤ 3 & 4: æ­£åœ¨è¿›è¡Œçƒ­è¯æ›¿æ¢ä¸ä¸­è‹±æ–‡ç©ºæ ¼å¤„ç† (é€æ®µè¿›è¡Œ)...")
    
    processed_segments = []
    for segment in original_segments:
        # å¤åˆ¶ segment ä»¥å…ä¿®æ”¹åŸå§‹æ•°æ®
        new_segment = segment.copy()
        
        # æ­¥éª¤ 3: çƒ­è¯æ›¿æ¢
        text = apply_replacements(new_segment['text'], replacement_map)
        
        # æ­¥éª¤ 4: ä¸­è‹±æ–‡ç©ºæ ¼
        text = add_spaces_around_english(text)
        
        new_segment['text'] = text
        processed_segments.append(new_segment)
    
    step3_4_end = datetime.datetime.now()
    step3_4_duration = step3_4_end - step3_4_start
    print(f"âœ… çƒ­è¯ä¸ç©ºæ ¼å¤„ç†å®Œæˆã€‚è€—æ—¶: {step3_4_duration}\n")

    # --- æ­¥éª¤ 5: LLM æ™ºèƒ½æ ‡ç‚¹ (åˆ©ç”¨åœé¡¿ä¿¡å·) ---
    step5_start = datetime.datetime.now()
    print(f"ğŸ¤– æ­¥éª¤ 5: æ­£åœ¨è°ƒç”¨ LLM '{llm_model_name}' è¿›è¡Œåœé¡¿æ„ŸçŸ¥æ™ºèƒ½æ ‡ç‚¹...")
    
    # <--- ä¿®æ”¹ï¼šå°†å¤„ç†è¿‡çš„ segments ä¼ é€’ç»™ LLM å‡½æ•° ---
    final_text = enhance_punctuation_with_llm(processed_segments, llm_model_name)
    
    step5_end = datetime.datetime.now()
    step5_duration = step5_end - step5_start
    print(f"âœ… LLM æ ‡ç‚¹å¤„ç†å®Œæˆã€‚è€—æ—¶: {step5_duration}")
    print(f"ğŸ“Š æœ€ç»ˆæ–‡æœ¬é•¿åº¦: {len(final_text)} å­—ç¬¦\n")
    
    print("âœ¨ LLM å¤„ç†åæœ€ç»ˆæ–‡æœ¬:")
    print("=" * 50)
    print(final_text)
    print("=" * 50 + "\n")
    
    # --- æ­¥éª¤ 6: ä¿å­˜æ–‡ä»¶ (é€»è¾‘ç®€åŒ–) ---
    step6_start = datetime.datetime.now()
    print("ğŸ’¾ æ­¥éª¤ 6: æ­£åœ¨ä¿å­˜æœ€ç»ˆæ–‡æœ¬...")
    
    base_name = os.path.splitext(os.path.basename(media_path))[0]
    txt_path = os.path.join(output_dir, f"{base_name}_whisper_final.txt")
    save_text_file(final_text, txt_path)
    
    original_txt_path = os.path.join(output_dir, f"{base_name}_whisper_original.txt")
    save_text_file(original_text_display, original_txt_path)
    print(f"ğŸ“ åŸå§‹æ–‡æœ¬å·²ä¿å­˜: {os.path.abspath(original_txt_path)}")
    
    step6_end = datetime.datetime.now()
    step6_duration = step6_end - step6_start
    print(f"âœ… æ–‡ä»¶ä¿å­˜å®Œæˆã€‚è€—æ—¶: {step6_duration}\n")
    
    # --- æ€»ç»“ç»Ÿè®¡ ---
    total_end_time = datetime.datetime.now()
    total_duration = total_end_time - total_start_time
    
    print("ğŸ‰ å…¨éƒ¨æµç¨‹å®Œæˆ!")
    print("=" * 70)
    print("â±ï¸ å„æ­¥éª¤è€—æ—¶ç»Ÿè®¡:")
    print(f"   æ­¥éª¤1 (æ¨¡å‹åŠ è½½): {step1_duration}")
    print(f"   æ­¥éª¤2 (éŸ³é¢‘è½¬å½•): {step2_duration}")
    print(f"   æ­¥éª¤3&4 (é¢„å¤„ç†): {step3_4_duration}")
    print(f"   æ­¥éª¤5 (LLMæ ‡ç‚¹):   {step5_duration}")
    print(f"   æ­¥éª¤6 (æ–‡ä»¶ä¿å­˜): {step6_duration}")
    print(f"   â° æ€»è®¡è€—æ—¶:      {total_duration}")
    print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   ğŸ“„ æœ€ç»ˆæ–‡æœ¬: {txt_path}")
    print(f"   ğŸ“„ åŸå§‹æ–‡æœ¬: {original_txt_path}")
    print("=" * 70)

# --- 3. é…ç½®ä¸æ‰§è¡Œ (ä»£ç ä¸å˜) ---
if __name__ == "__main__":
    # ... (æ‚¨çš„é…ç½®éƒ¨åˆ†å®Œå…¨ä¸å˜)
    REPLACEMENT_MAP = {
        "ä¹Œç­å›¾": "Ubuntu", "å‰ç‰¹å“ˆå¸ƒ": "GitHub", "Moddy Talk": "MultiTalk",
        "é©¬å…‹é“": "Markdown", "VS æ‰£å¾·": "VS Code", "æ´¾æ£®": "Python",
        "ç”²ç“¦": "Java", "JavaScript": "JavaScript",
    }
    
    WHISPER_MODEL_NAME = "large-v3"
    MEDIA_FILE = "../audio/139.wav"
    LANGUAGE = "zh"
    
    LLM_MODEL_NAME = "qwen2.5:72b"
    
    script_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in locals() else '.'
    media_path_full = os.path.join(script_dir, MEDIA_FILE)
    
    if not os.path.exists(media_path_full):
        print(f"âŒ é”™è¯¯: éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ -> {media_path_full}")
        print("è¯·æ£€æŸ¥ MEDIA_FILE è·¯å¾„è®¾ç½®ã€‚")
    else:
        run_transcription_pipeline(
            model_name=WHISPER_MODEL_NAME,
            media_path=media_path_full,
            language=LANGUAGE,
            replacement_map=REPLACEMENT_MAP,
            llm_model_name=LLM_MODEL_NAME
        )