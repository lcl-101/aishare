"""
M6-2: Whisper æ¨¡å‹å¾®è°ƒè®­ç»ƒ

ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†å¯¹ Whisper æ¨¡å‹è¿›è¡Œå¾®è°ƒè®­ç»ƒã€‚

æ•°æ®é›†ç»“æ„:
- dataset/train/audio/ - è®­ç»ƒéŸ³é¢‘æ–‡ä»¶ (wavæ ¼å¼)  
- dataset/train/text/  - è®­ç»ƒæ–‡æœ¬æ–‡ä»¶ (txtæ ¼å¼)
- dataset/test/audio/  - æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ (wavæ ¼å¼)
- dataset/test/text/   - æµ‹è¯•æ–‡æœ¬æ–‡ä»¶ (txtæ ¼å¼)

ä¾èµ–å®‰è£…:
pip install transformers datasets evaluate accelerate jiwer
"""
import torch
import os
import numpy as np
import json
import datetime
import librosa
import soundfile as sf
import subprocess
from dataclasses import dataclass
from typing import Any, Dict, List, Union

try:
    from transformers import (
        WhisperTokenizer, WhisperFeatureExtractor, WhisperProcessor,
        WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer
    )
    from datasets import load_dataset, Audio
    from huggingface_hub import login
    import evaluate
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
    print("è¯·å®‰è£…ä¾èµ–: pip install torch transformers datasets evaluate huggingface_hub accelerate librosa soundfile")
    exit(1)

# --- é…ç½®å‚æ•° ---
DATASET_ROOT = "dataset"
TRAIN_FOLDER = "train"
TEST_FOLDER = "test"

# æ¨¡å‹è·¯å¾„ï¼ˆéœ€æå‰ä¸‹è½½åˆ°æœ¬åœ°ï¼‰
MODEL_NAME = "../models/whisper-large-v3"  # æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œæˆ–æ”¹ä¸º "openai/whisper-large-v3" ä½¿ç”¨åœ¨çº¿æ¨¡å‹

LANGUAGE = "zh"
TASK = "transcribe"
OUTPUT_DIR = "whisper-large-v3-finetuned"

def validate_audio_file(audio_file_path):
    """éªŒè¯éŸ³é¢‘æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
    try:
        # ä½¿ç”¨librosaåŠ è½½éŸ³é¢‘æ–‡ä»¶è¿›è¡ŒéªŒè¯
        audio, sr = librosa.load(audio_file_path, sr=16000, mono=True)
        
        # æ£€æŸ¥éŸ³é¢‘æ˜¯å¦ä¸ºç©ºæˆ–è¿‡çŸ­
        if len(audio) == 0:
            return False, "éŸ³é¢‘æ–‡ä»¶ä¸ºç©º"
        
        if len(audio) < 0.1 * sr:  # å°‘äº0.1ç§’
            return False, "éŸ³é¢‘æ–‡ä»¶è¿‡çŸ­"
        
        # æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if np.all(audio == 0):
            return False, "éŸ³é¢‘æ–‡ä»¶åŒ…å«é™éŸ³"
        
        return True, "éŸ³é¢‘æ–‡ä»¶æœ‰æ•ˆ"
        
    except Exception as e:
        return False, f"éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}"

def create_dataset_json(folder_path, json_file_path):
    """åˆ›å»ºæ•°æ®é›†JSONæ–‡ä»¶ï¼Œå¢åŠ éŸ³é¢‘æ–‡ä»¶éªŒè¯"""
    print(f"ğŸ“ æ­£åœ¨åˆ›å»ºæ•°æ®é›†æ–‡ä»¶: {json_file_path}")
    
    # ç§»é™¤æ—§æ–‡ä»¶
    if os.path.exists(json_file_path):
        os.remove(json_file_path)
    
    audio_path = os.path.join(folder_path, "audio")
    text_path = os.path.join(folder_path, "text")
    
    if not os.path.exists(audio_path) or not os.path.exists(text_path):
        raise FileNotFoundError(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {folder_path}")
    
    count = 0
    invalid_count = 0
    invalid_files = []
    
    with open(json_file_path, 'w', encoding='utf-8') as json_file:
        for audio_file in sorted(os.listdir(audio_path)):  # æ’åºç¡®ä¿ä¸€è‡´æ€§
            if not audio_file.endswith('.wav'):
                continue
                
            audio_file_path = os.path.join(audio_path, audio_file)
            text_file_path = os.path.join(text_path, audio_file.replace('.wav', '.txt'))
            
            if not os.path.exists(text_file_path):
                print(f"âš ï¸ ç¼ºå°‘å¯¹åº”æ–‡æœ¬æ–‡ä»¶: {text_file_path}")
                invalid_count += 1
                continue
            
            # éªŒè¯éŸ³é¢‘æ–‡ä»¶
            is_valid, error_msg = validate_audio_file(audio_file_path)
            if not is_valid:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆéŸ³é¢‘æ–‡ä»¶ {audio_file}: {error_msg}")
                invalid_files.append((audio_file, error_msg))
                invalid_count += 1
                continue
            
            try:
                with open(text_file_path, 'r', encoding='utf-8') as txt_file:
                    txt_sentence = txt_file.read().strip()
                
                # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºç©º
                if not txt_sentence:
                    print(f"âš ï¸ è·³è¿‡ç©ºæ–‡æœ¬æ–‡ä»¶: {text_file_path}")
                    invalid_count += 1
                    continue
                
                name = audio_file.replace('.wav', '')
                data = {
                    "name": name,
                    "audio_file_path": audio_file_path,
                    "txt_sentence": txt_sentence
                }
                
                json_file.write(json.dumps(data, ensure_ascii=False) + '\n')
                count += 1
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {audio_file} æ—¶å‡ºé”™: {e}")
                invalid_count += 1
    
    print(f"âœ… å®Œæˆï¼Œå…±å¤„ç† {count} ä¸ªæœ‰æ•ˆæ ·æœ¬ï¼Œè·³è¿‡ {invalid_count} ä¸ªæ— æ•ˆæ ·æœ¬")
    
    return count

def prepare_dataset(batch, feature_extractor, tokenizer):
    """æ•°æ®é¢„å¤„ç†å‡½æ•°ï¼ˆæ”¯æŒæ‰¹å¤„ç†ï¼‰ä½¿ç”¨librosaç›´æ¥åŠ è½½éŸ³é¢‘"""
    if isinstance(batch['audio_file_path'], list):
        # æ‰¹å¤„ç†æ¨¡å¼
        input_features = []
        labels = []
        valid_indices = []
        
        for i, audio_file_path in enumerate(batch['audio_file_path']):
            try:
                # ä½¿ç”¨librosaç›´æ¥åŠ è½½éŸ³é¢‘æ–‡ä»¶
                audio_array, sr = librosa.load(audio_file_path, sr=16000, mono=True)
                
                # æ£€æŸ¥éŸ³é¢‘æ•°ç»„æ˜¯å¦æœ‰æ•ˆ
                if audio_array is None or len(audio_array) == 0:
                    print(f"âš ï¸ è·³è¿‡ç©ºéŸ³é¢‘æ•°ç»„: ç´¢å¼• {i}")
                    continue
                
                # æ£€æŸ¥éŸ³é¢‘é•¿åº¦
                if len(audio_array) < 160:  # 0.01ç§’ at 16kHz
                    print(f"âš ï¸ è·³è¿‡è¿‡çŸ­éŸ³é¢‘: ç´¢å¼• {i}, é•¿åº¦ {len(audio_array)}")
                    continue
                
                features = feature_extractor(
                    audio_array, 
                    sampling_rate=sr
                ).input_features[0]
                input_features.append(features)
                valid_indices.append(i)
                
            except Exception as e:
                print(f"âš ï¸ å¤„ç†éŸ³é¢‘æ–‡ä»¶ {audio_file_path} æ—¶å‡ºé”™: {e}")
                continue
        
        # åªå¤„ç†æœ‰æ•ˆçš„æ–‡æœ¬
        for i in valid_indices:
            try:
                text = batch['txt_sentence'][i]
                if text and text.strip():
                    label = tokenizer(text.strip()).input_ids
                    labels.append(label)
                else:
                    # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œä»æœ‰æ•ˆåˆ—è¡¨ä¸­ç§»é™¤å¯¹åº”çš„éŸ³é¢‘ç‰¹å¾
                    if len(input_features) > len(labels):
                        input_features.pop()
                    print(f"âš ï¸ è·³è¿‡ç©ºæ–‡æœ¬: ç´¢å¼• {i}")
            except Exception as e:
                print(f"âš ï¸ å¤„ç†æ–‡æœ¬ {i} æ—¶å‡ºé”™: {e}")
                # ç§»é™¤å¯¹åº”çš„éŸ³é¢‘ç‰¹å¾
                if len(input_features) > len(labels):
                    input_features.pop()
                continue
            
        batch['input_features'] = input_features
        batch['labels'] = labels
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ï¼Œè¿”å›ç©ºæ‰¹æ¬¡
        if len(input_features) == 0:
            print("âš ï¸ å½“å‰æ‰¹æ¬¡æ— æœ‰æ•ˆæ ·æœ¬")
            batch['input_features'] = []
            batch['labels'] = []
    else:
        # å•ä¸ªæ ·æœ¬æ¨¡å¼
        try:
            audio_file_path = batch['audio_file_path']
            
            # ä½¿ç”¨librosaç›´æ¥åŠ è½½éŸ³é¢‘æ–‡ä»¶
            audio_array, sr = librosa.load(audio_file_path, sr=16000, mono=True)
            
            # æ£€æŸ¥éŸ³é¢‘æ•°ç»„
            if audio_array is None or len(audio_array) == 0:
                raise ValueError("éŸ³é¢‘æ•°ç»„ä¸ºç©º")
            
            # æ£€æŸ¥éŸ³é¢‘é•¿åº¦
            if len(audio_array) < 160:  # 0.01ç§’ at 16kHz
                raise ValueError(f"éŸ³é¢‘è¿‡çŸ­: {len(audio_array)}")
            
            batch['input_features'] = feature_extractor(
                audio_array, 
                sampling_rate=sr
            ).input_features[0]
            
            # å¤„ç†æ–‡æœ¬
            text = batch['txt_sentence']
            if not text or not text.strip():
                raise ValueError("æ–‡æœ¬ä¸ºç©º")
            
            batch['labels'] = tokenizer(text.strip()).input_ids
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†å•ä¸ªæ ·æœ¬ {batch.get('audio_file_path', 'unknown')} æ—¶å‡ºé”™: {e}")
            # è¿”å›ç©ºæ•°æ®ï¼Œè®©æ•°æ®åŠ è½½å™¨è·³è¿‡è¿™ä¸ªæ ·æœ¬
            batch['input_features'] = []
            batch['labels'] = []
    
    return batch

@dataclass
class DataCollatorSpeechSeq2SeqWithPadding:
    """è¯­éŸ³åºåˆ—åˆ°åºåˆ—æ•°æ®æ•´ç†å™¨"""
    processor: Any

    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
        # åˆ†ç¦»è¾“å…¥å’Œæ ‡ç­¾ï¼Œå› ä¸ºå®ƒä»¬é•¿åº¦ä¸åŒéœ€è¦ä¸åŒçš„å¡«å……æ–¹æ³•
        input_features = [{"input_features": feature["input_features"]} for feature in features]
        batch = self.processor.feature_extractor.pad(input_features, return_tensors="pt")

        # è·å–æ ‡è®°åŒ–çš„æ ‡ç­¾åºåˆ—
        label_features = [{"input_ids": feature["labels"]} for feature in features]
        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors="pt")

        # ç”¨ -100 æ›¿æ¢å¡«å……ä»¥æ­£ç¡®å¿½ç•¥æŸå¤±
        labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)

        # å¦‚æœåœ¨ä¹‹å‰çš„æ ‡è®°åŒ–æ­¥éª¤ä¸­æ·»åŠ äº† bos tokenï¼Œåœ¨è¿™é‡Œåˆ é™¤å®ƒ
        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():
            labels = labels[:, 1:]

        batch["labels"] = labels
        return batch

def compute_metrics(pred, tokenizer):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    pred_ids = pred.predictions
    label_ids = pred.label_ids

    # ç”¨ pad_token_id æ›¿æ¢ -100
    label_ids[label_ids == -100] = tokenizer.pad_token_id

    # è§£ç é¢„æµ‹å’Œæ ‡ç­¾
    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)
    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)

    # è®¡ç®— WER
    metric = evaluate.load("wer")
    wer = 100 * metric.compute(predictions=pred_str, references=label_str)
    return {"wer": wer}

def monitor_gpu_utilization():
    """ç›‘æ§GPUåˆ©ç”¨ç‡"""
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            utilization = int(result.stdout.strip())
            return utilization
    except:
        pass
    return None

def check_gpu_memory():
    """æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            total_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3  # GB
            allocated = torch.cuda.memory_allocated(i) / 1024**3  # GB
            cached = torch.cuda.memory_reserved(i) / 1024**3  # GB
            utilization = monitor_gpu_utilization()
            
            print(f"ğŸ® GPU {i} ({gpu_name}):")
            print(f"   ğŸ’¾ æ€»å†…å­˜: {total_memory:.1f} GB")
            print(f"   ğŸ”¥ å·²åˆ†é…: {allocated:.1f} GB")
            print(f"   ğŸ“¦ å·²ç¼“å­˜: {cached:.1f} GB")
            print(f"   ğŸ†“ å¯ç”¨: {total_memory - cached:.1f} GB")
            if utilization is not None:
                print(f"   âš¡ GPUåˆ©ç”¨ç‡: {utilization}%")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡")

def check_datasets_cache():
    """æ£€æŸ¥æ•°æ®é›†ç¼“å­˜ä½¿ç”¨æƒ…å†µ"""
    import shutil
    
    cache_dir = os.path.expanduser("~/.cache/huggingface/datasets")
    if os.path.exists(cache_dir):
        # è®¡ç®—ç¼“å­˜å¤§å°
        total_size = shutil.disk_usage(cache_dir).used
        total_size_gb = total_size / (1024**3)
        
        print(f"ğŸ“¦ æ•°æ®é›†ç¼“å­˜ä¿¡æ¯: {total_size_gb:.1f} GB")
        
        return total_size_gb
    else:
        print("ğŸ“¦ æ•°æ®é›†ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
        return 0

def clear_datasets_cache():
    """æ¸…ç†æ•°æ®é›†ç¼“å­˜"""
    import shutil
    
    cache_dir = os.path.expanduser("~/.cache/huggingface/datasets")
    if not os.path.exists(cache_dir):
        print("ğŸ“¦ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")
        return 0
    
    # è®¡ç®—æ¸…ç†å‰å¤§å°
    try:
        before_size = shutil.disk_usage(cache_dir).used / (1024**3)
    except:
        before_size = 0
    
    cleaned_count = 0
    cleaned_size = 0
    
    # æ¸…ç†jsonç¼“å­˜ç›®å½•
    json_cache_dir = os.path.join(cache_dir, "json")
    if os.path.exists(json_cache_dir):
        for item in os.listdir(json_cache_dir):
            if item.startswith("default-"):
                item_path = os.path.join(json_cache_dir, item)
                try:
                    if os.path.isdir(item_path):
                        # è®¡ç®—ç›®å½•å¤§å°
                        for root, dirs, files in os.walk(item_path):
                            for file in files:
                                try:
                                    cleaned_size += os.path.getsize(os.path.join(root, file))
                                except:
                                    pass
                        shutil.rmtree(item_path)
                        cleaned_count += 1
                    else:
                        cleaned_size += os.path.getsize(item_path)
                        os.remove(item_path)
                        cleaned_count += 1
                except Exception as e:
                    print(f"   âš ï¸ æ¸…ç† {item} æ—¶å‡ºé”™: {e}")
    
    # æ¸…ç†é”æ–‡ä»¶
    for item in os.listdir(cache_dir):
        if item.endswith(".lock") and "json_default-" in item:
            lock_path = os.path.join(cache_dir, item)
            try:
                os.remove(lock_path)
                cleaned_count += 1
            except Exception as e:
                print(f"   âš ï¸ æ¸…ç†é”æ–‡ä»¶ {item} æ—¶å‡ºé”™: {e}")
    
    cleaned_size_gb = cleaned_size / (1024**3)
    
    if cleaned_count > 0:
        print(f"ğŸ§¹ ç¼“å­˜æ¸…ç†å®Œæˆï¼Œé‡Šæ”¾ç©ºé—´: {cleaned_size_gb:.1f} GB")
    else:
        print("ğŸ“¦ æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„ç¼“å­˜æ–‡ä»¶")
    
    return cleaned_size_gb

def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    print("ğŸš€ å¼€å§‹ Whisper æ¨¡å‹å¾®è°ƒè®­ç»ƒ")
    print("=" * 60)
    
    # æ£€æŸ¥GPUå†…å­˜
    check_gpu_memory()
    print()
    
    # æ¸…ç†æ•°æ®é›†ç¼“å­˜
    print("ğŸ§¹ æ¸…ç†æ•°æ®é›†ç¼“å­˜...")
    cleared_size = clear_datasets_cache()
    print()
    
    # å‡†å¤‡æ•°æ®é›†è·¯å¾„
    train_dataset_path = os.path.join(DATASET_ROOT, TRAIN_FOLDER)
    test_dataset_path = os.path.join(DATASET_ROOT, TEST_FOLDER)
    train_json_file = os.path.join(DATASET_ROOT, "train_dataset.json")
    test_json_file = os.path.join(DATASET_ROOT, "test_dataset.json")
    
    try:
        # åˆ›å»ºæ•°æ®é›†JSONæ–‡ä»¶
        print("ğŸ“‚ æ­¥éª¤ 1: å‡†å¤‡æ•°æ®é›†...")
        train_count = create_dataset_json(train_dataset_path, train_json_file)
        test_count = create_dataset_json(test_dataset_path, test_json_file)
        
        if train_count == 0 or test_count == 0:
            raise ValueError("æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        
        # åŠ è½½æ•°æ®é›†
        print("\nğŸ“¥ æ­¥éª¤ 2: åŠ è½½æ•°æ®é›†...")
        dataset = load_dataset('json', data_files={
            'train': train_json_file, 
            'test': test_json_file
        })
        print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ - è®­ç»ƒ: {train_count}, æµ‹è¯•: {test_count}")
        
        # åˆå§‹åŒ–æ¨¡å‹ç»„ä»¶
        print("\nğŸ”§ æ­¥éª¤ 3: åˆå§‹åŒ–æ¨¡å‹ç»„ä»¶...")
        tokenizer = WhisperTokenizer.from_pretrained(MODEL_NAME, language=LANGUAGE, task=TASK)
        feature_extractor = WhisperFeatureExtractor.from_pretrained(MODEL_NAME)
        processor = WhisperProcessor.from_pretrained(MODEL_NAME)
        print("âœ… æ¨¡å‹ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        
        # æ•°æ®é¢„å¤„ç†
        print("\nâš™ï¸ æ­¥éª¤ 4: æ•°æ®é¢„å¤„ç†...")
        
        def prepare_batch(batch):
            return prepare_dataset(batch, feature_extractor, tokenizer)
        
        dataset = dataset.map(
            prepare_batch, 
            remove_columns=dataset.column_names["train"], 
            num_proc=1,
            batched=True,
            batch_size=300,
            desc="ğŸ”„ å¤„ç†éŸ³é¢‘ç‰¹å¾å’Œæ–‡æœ¬æ ‡ç­¾",
            load_from_cache_file=True,
            writer_batch_size=2000,
        )
        print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
        
        # è®¾ç½®æ•°æ®æ•´ç†å™¨å’Œè¯„ä¼°å‡½æ•°
        data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)
        
        def compute_metrics_wrapped(pred):
            return compute_metrics(pred, tokenizer)
        
        # åŠ è½½æ¨¡å‹
        print("\nğŸ¤– æ­¥éª¤ 5: åŠ è½½æ¨¡å‹...")
        model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)
        model.generation_config.language = LANGUAGE
        model.generation_config.task = TASK
        model.generation_config.forced_decoder_ids = None
        model.config.suppress_tokens = []
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        
        # è®­ç»ƒå‚æ•°é…ç½®
        print("\nâš™ï¸ æ­¥éª¤ 6: é…ç½®è®­ç»ƒå‚æ•°...")
        
        training_args = Seq2SeqTrainingArguments(
            output_dir=OUTPUT_DIR,
            
            # æ‰¹å¤„ç†å¤§å°é…ç½®
            per_device_train_batch_size=20,
            per_device_eval_batch_size=10,
            gradient_accumulation_steps=2,
            
            # å­¦ä¹ ç‡ç­–ç•¥
            learning_rate=1e-4,
            warmup_steps=1000,
            max_steps=20000,
            
            # å†…å­˜å’Œè®¡ç®—ä¼˜åŒ–
            gradient_checkpointing=False,
            fp16=False,
            bf16=True,
            dataloader_pin_memory=True,
            dataloader_num_workers=4,
            dataloader_prefetch_factor=2,
            
            # è¯„ä¼°ç­–ç•¥
            eval_strategy="steps",
            eval_steps=3000,
            save_steps=3000,
            save_total_limit=2,
            load_best_model_at_end=True,
            
            # ç”Ÿæˆå‚æ•°
            predict_with_generate=True,
            generation_max_length=256,
            
            # ä¼˜åŒ–å™¨é…ç½®
            optim="adamw_torch_fused",
            weight_decay=0.01,
            lr_scheduler_type="polynomial",
            
            # æ—¥å¿—å’Œç›‘æ§
            logging_steps=50,
            report_to=None,
            
            # è®­ç»ƒæ•ˆç‡è®¾ç½®
            metric_for_best_model="wer",
            greater_is_better=False,
            push_to_hub=False,
            remove_unused_columns=False,
            
            # æ•°å€¼ç¨³å®šæ€§è®¾ç½®
            max_grad_norm=0.5,
            warmup_ratio=0.067,
        )
        
        processor.save_pretrained(training_args.output_dir)
        print("âœ… è®­ç»ƒå‚æ•°é…ç½®å®Œæˆ")
        
        # æ˜¾ç¤ºè®­ç»ƒé…ç½®ä¿¡æ¯
        print(f"\nğŸ“Š è®­ç»ƒé…ç½®:")
        print(f"   ğŸ¯ æ¨¡å‹: {MODEL_NAME}")
        print(f"   ğŸ’¾ æ‰¹å¤§å°: {training_args.per_device_train_batch_size} (è®­ç»ƒ) / {training_args.per_device_eval_batch_size} (è¯„ä¼°)")
        print(f"   ğŸ“ˆ æœ‰æ•ˆæ‰¹å¤§å°: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}")
        print(f"   ğŸ”¥ å­¦ä¹ ç‡: {training_args.learning_rate}")
        print(f"   ğŸƒ è®­ç»ƒæ­¥æ•°: {training_args.max_steps}")
        print(f"   ğŸ² é¢„çƒ­æ­¥æ•°: {training_args.warmup_steps}")
        print(f"   ğŸ’¾ ç²¾åº¦æ¨¡å¼: {'BF16' if training_args.bf16 else 'FP16' if training_args.fp16 else 'FP32'}")
        print(f"   ğŸ”§ ä¼˜åŒ–å™¨: {training_args.optim}")
        print(f"   ğŸ“Š æ•°æ®è¿›ç¨‹: {training_args.dataloader_num_workers} workers")
        print(f"   ğŸ’¿ è¾“å‡ºç›®å½•: {training_args.output_dir}")
        print()
        
        # åˆ›å»ºè®­ç»ƒå™¨
        print("\nğŸ‹ï¸ æ­¥éª¤ 7: å¼€å§‹è®­ç»ƒ...")
        trainer = Seq2SeqTrainer(
            args=training_args,
            model=model,
            train_dataset=dataset["train"],
            eval_dataset=dataset["test"],
            data_collator=data_collator,
            compute_metrics=compute_metrics_wrapped,
            processing_class=processor,
        )
        
        # å¼€å§‹è®­ç»ƒ
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        trainer.train()
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        print("\nğŸ’¾ æ­¥éª¤ 8: ä¿å­˜æœ€ç»ˆæ¨¡å‹...")
        final_model_dir = f"{OUTPUT_DIR}/final"
        trainer.save_model(final_model_dir)
        processor.save_pretrained(final_model_dir)
        print(f"âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜è‡³: {final_model_dir}")
        
        # è¿è¡Œæœ€ç»ˆè¯„ä¼°
        print("\nğŸ“Š æ­¥éª¤ 9: æœ€ç»ˆè¯„ä¼°...")
        eval_results = trainer.evaluate()
        print("ğŸ“‹ æœ€ç»ˆè¯„ä¼°ç»“æœ:")
        for key, value in eval_results.items():
            print(f"   {key}: {value:.4f}")
        
        print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ¯ æœ€ä½³æ¨¡å‹WER: {eval_results.get('eval_wer', 'N/A'):.4f}")
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜ä½ç½®: {final_model_dir}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        raise
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        print("\nğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        for file_path in [train_json_file, test_json_file]:
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤: {file_path}")

if __name__ == "__main__":
    main()

