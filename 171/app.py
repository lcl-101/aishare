import gradio as gr
import numpy as np
import random
import os
import time
import torch
from PIL import Image
from diffusers import DiffusionPipeline

# é…ç½®å‚æ•°
MAX_SEED = np.iinfo(np.int32).max
MAX_IMAGE_SIZE = 1440

# å…¨å±€å˜é‡å­˜å‚¨ç®¡é“
pipe = None

def load_model():
    """åŠ è½½Qwen-Imageæ¨¡å‹"""
    global pipe
    if pipe is None:
        model_name = "checkpoints/Qwen-Image"
        
        if torch.cuda.is_available():
            torch_dtype = torch.bfloat16
            device = "cuda"
        else:
            torch_dtype = torch.float32
            device = "cpu"
        
        pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype)
        pipe = pipe.to(device)
        print(f"æ¨¡å‹å·²åŠ è½½åˆ° {device}")
    return pipe

# é¢„è®¾çš„æç¤ºè¯ç¤ºä¾‹
TEXT_GENERATION_EXAMPLES = [
    ["å®«å´éªçš„åŠ¨æ¼«é£æ ¼ã€‚å¹³è§†è§’æ‹æ‘„ï¼Œé˜³å…‰ä¸‹çš„å¤è¡—çƒ­é—¹éå‡¡ã€‚ä¸€ä¸ªç©¿ç€é’è¡«ã€æ‰‹é‡Œæ‹¿ç€å†™ç€'é˜¿é‡Œäº‘'å¡ç‰‡çš„é€é¥æ´¾å¼Ÿå­ç«™åœ¨ä¸­é—´ã€‚æ—è¾¹ä¸¤ä¸ªå°å­©æƒŠè®¶çš„çœ‹ç€ä»–ã€‚å·¦è¾¹æœ‰ä¸€å®¶åº—é“ºæŒ‚ç€'äº‘å­˜å‚¨'çš„ç‰Œå­ï¼Œé‡Œé¢æ‘†æ”¾ç€å‘å…‰çš„æœåŠ¡å™¨æœºç®±ï¼Œé—¨å£ä¸¤ä¸ªä¾å«å®ˆæŠ¤è€…ã€‚å³è¾¹æœ‰ä¸¤å®¶åº—é“ºï¼Œå…¶ä¸­ä¸€å®¶æŒ‚ç€'äº‘è®¡ç®—'çš„ç‰Œå­ï¼Œä¸€ä¸ªç©¿ç€æ——è¢çš„ç¾ä¸½å¥³å­æ­£çœ‹ç€é‡Œé¢é—ªé—ªå‘å…‰çš„ç”µè„‘å±å¹•ï¼›å¦ä¸€å®¶åº—é“ºæŒ‚ç€'äº‘æ¨¡å‹'çš„ç‰Œå­ï¼Œé—¨å£æ”¾ç€ä¸€ä¸ªå¤§é…’ç¼¸ï¼Œä¸Šé¢å†™ç€'åƒé—®'ï¼Œä¸€ä½è€æ¿å¨˜æ­£åœ¨å¾€é‡Œé¢å€’å‘å…‰çš„ä»£ç æº¶æ¶²ã€‚", "", 42, 1408, 928, 4.0, 50],
    ["ä¸€å‰¯å…¸é›…åº„é‡çš„å¯¹è”æ‚¬æŒ‚äºå…å ‚ä¹‹ä¸­ï¼Œæˆ¿é—´æ˜¯ä¸ªå®‰é™å¤å…¸çš„ä¸­å¼å¸ƒç½®ï¼Œæ¡Œå­ä¸Šæ”¾ç€ä¸€äº›é’èŠ±ç“·ï¼Œå¯¹è”ä¸Šå·¦ä¹¦'ä¹‰æœ¬ç”ŸçŸ¥äººæœºåŒé“å–„æ€æ–°'ï¼Œå³ä¹¦'é€šäº‘èµ‹æ™ºä¹¾å¤å¯æ•°é«˜å¿—è¿œ'ï¼Œ æ¨ªæ‰¹'æ™ºå¯é€šä¹‰'ï¼Œå­—ä½“é£˜é€¸ï¼Œä¸­é—´æŒ‚åœ¨ä¸€ç€ä¸€å‰¯ä¸­å›½é£çš„ç”»ä½œï¼Œå†…å®¹æ˜¯å²³é˜³æ¥¼ã€‚", "", 123, 1328, 1328, 4.0, 50],
    ["Bookstore window display. A sign displays 'New Arrivals This Week'. Below, a shelf tag with the text 'Best-Selling Novels Here'. To the side, a colorful poster advertises 'Author Meet And Greet on Saturday' with a central portrait of the author. There are four books on the bookshelf, namely 'The light between worlds' 'When stars are scattered' 'The slient patient' 'The night circus'", "", 456, 928, 1408, 4.0, 50],
    ["A man in a suit is standing in front of the window, looking at the bright moon outside the window. The man is holding a yellowed paper with handwritten words on it: 'A lantern moon climbs through the silver night, Unfurling quiet dreams across the sky, Each star a whispered promise wrapped in light, That dawn will bloom, though darkness wanders by.' There is a cute cat on the windowsill.", "", 789, 1408, 928, 4.0, 50],
    ["ä¸€ä¸ªç©¿ç€'QWEN'æ ‡å¿—çš„Tæ¤çš„ä¸­å›½ç¾å¥³æ­£æ‹¿ç€é»‘è‰²çš„é©¬å…‹ç¬”é¢ç›¸é•œå¤´å¾®ç¬‘ã€‚å¥¹èº«åçš„ç»ç’ƒæ¿ä¸Šæ‰‹å†™ä½“å†™ç€ 'ä¸€ã€Qwen-Imageçš„æŠ€æœ¯è·¯çº¿ï¼š æ¢ç´¢è§†è§‰ç”ŸæˆåŸºç¡€æ¨¡å‹çš„æé™ï¼Œå¼€åˆ›ç†è§£ä¸ç”Ÿæˆä¸€ä½“åŒ–çš„æœªæ¥ã€‚äºŒã€Qwen-Imageçš„æ¨¡å‹ç‰¹è‰²ï¼š1ã€å¤æ‚æ–‡å­—æ¸²æŸ“ã€‚æ”¯æŒä¸­è‹±æ¸²æŸ“ã€è‡ªåŠ¨å¸ƒå±€ï¼› 2ã€ç²¾å‡†å›¾åƒç¼–è¾‘ã€‚æ”¯æŒæ–‡å­—ç¼–è¾‘ã€ç‰©ä½“å¢å‡ã€é£æ ¼å˜æ¢ã€‚ä¸‰ã€Qwen-Imageçš„æœªæ¥æ„¿æ™¯ï¼šèµ‹èƒ½ä¸“ä¸šå†…å®¹åˆ›ä½œã€åŠ©åŠ›ç”Ÿæˆå¼AIå‘å±•ã€‚'", "", 999, 1328, 1328, 4.0, 50],
    ["A movie poster. The first row is the movie title, which reads 'Imagination Unleashed'. The second row is the movie subtitle, which reads 'Enter a world beyond your imagination'. The third row reads 'Cast: Qwen-Image'. The fourth row reads 'Director: The Collective Imagination of Humanity'. The central visual features a sleek, futuristic computer from which radiant colors, whimsical creatures, and dynamic, swirling patterns explosively emerge, filling the composition with energy, motion, and surreal creativity. The background transitions from dark, cosmic tones into a luminous, dreamlike expanse, evoking a digital fantasy realm. At the bottom edge, the text 'Launching in the Cloud, August 2025' appears in bold, modern sans-serif font with a glowing, slightly transparent effect, evoking a high-tech, cinematic aesthetic. The overall style blends sci-fi surrealism with graphic design flairâ€”sharp contrasts, vivid color grading, and layered visual depthâ€”reminiscent of visionary concept art and digital matte painting, 32K resolution, ultra-detailed.", "", 111, 1408, 928, 4.0, 50],
    ["ä¸€å¼ ä¼ä¸šçº§é«˜è´¨é‡PPTé¡µé¢å›¾åƒï¼Œæ•´ä½“é‡‡ç”¨ç§‘æŠ€æ„Ÿåè¶³çš„æ˜Ÿç©ºè“ä¸ºä¸»è‰²è°ƒï¼ŒèƒŒæ™¯èåˆæµåŠ¨çš„å‘å…‰ç§‘æŠ€çº¿æ¡ä¸å¾®å…‰ç²’å­ç‰¹æ•ˆï¼Œè¥é€ å‡ºä¸“ä¸šã€ç°ä»£ä¸”å¯Œæœ‰ä¿¡ä»»æ„Ÿçš„å“ç‰Œæ°›å›´ï¼›é¡µé¢é¡¶éƒ¨å·¦ä¾§æ¸…æ™°å±•ç¤ºæ©˜çº¢è‰²Alibabaæ ‡å¿—ï¼Œè‰²å½©é²œæ˜ã€è¾¨è¯†åº¦é«˜ã€‚ä¸»æ ‡é¢˜ä½äºç”»é¢ä¸­å¤®åä¸Šä½ç½®ï¼Œä½¿ç”¨å¤§å·åŠ ç²—ç™½è‰²æˆ–æµ…è“è‰²å­—ä½“å†™ç€'é€šä¹‰åƒé—®è§†è§‰åŸºç¡€æ¨¡å‹'ï¼Œå­—ä½“ç°ä»£ç®€æ´ï¼Œçªå‡ºæŠ€æœ¯æ„Ÿï¼›ä¸»æ ‡é¢˜ä¸‹æ–¹ç´§æ¥ä¸€è¡Œæ¥·ä½“ä¸­æ–‡æ–‡å­—ï¼š'åŸç”Ÿä¸­æ–‡Â·å¤æ‚åœºæ™¯Â·è‡ªåŠ¨å¸ƒå±€'ï¼Œå­—ä½“æŸ”å’Œä¼˜é›…ï¼Œå½¢æˆç§‘æŠ€ä¸äººæ–‡çš„èåˆã€‚ä¸‹æ–¹å±…ä¸­æ’å¸ƒå±•ç¤ºäº†å››å¼ ä¸å›¾ç‰‡ï¼Œåˆ†åˆ«æ˜¯ï¼šä¸€å¹…å†™å®ä¸æ°´å¢¨é£æ ¼ç»“åˆçš„æ¢…èŠ±ç‰¹å†™ï¼Œæå¹²è‹åŠ²ã€èŠ±ç“£æ¸…é›…ï¼ŒèƒŒæ™¯èå…¥æ·¡å¢¨æ™•æŸ“ä¸é£˜é›ªæ•ˆæœï¼Œä½“ç°åšéŸ§ä¸æ‹”çš„ç²¾ç¥æ°”è´¨ï¼›ä¸Šæ–¹å†™ç€é»‘è‰²çš„æ¥·ä½“'æ¢…å‚²'ã€‚ä¸€æ ªç”Ÿé•¿äºå±±æ¶§çŸ³ç¼ä¸­çš„å…°èŠ±ï¼Œå¶ç‰‡ä¿®é•¿ã€èŠ±æœµç´ å‡€ï¼Œæ­é…æ™¨é›¾ç¼­ç»•çš„è‡ªç„¶ç¯å¢ƒï¼Œå±•ç°æ¸…é€¸è„±ä¿—çš„æ–‡äººé£éª¨ï¼›ä¸Šæ–¹å†™ç€é»‘è‰²çš„æ¥·ä½“'å…°å¹½'ã€‚ä¸€ç»„è¿é£è€Œç«‹çš„ç¿ ç«¹ï¼Œç«¹å¶éšé£æ‘‡æ›³ï¼Œå…‰å½±äº¤é”™ï¼ŒèƒŒæ™¯ä¸ºé’ç°è‰²å±±å²©ä¸æµæ°´ï¼Œå‘ˆç°åˆšæŸ”å¹¶æµã€è™šæ€€è‹¥è°·çš„æ–‡åŒ–æ„è±¡ï¼›ä¸Šæ–¹å†™ç€é»‘è‰²çš„æ¥·ä½“'ç«¹æ¸…'ã€‚ä¸€ç‰‡ç››å¼€äºç§‹æ—¥åº­é™¢çš„èŠèŠ±ä¸›ï¼ŒèŠ±è‰²ä¸°å¯Œã€å±‚æ¬¡åˆ†æ˜ï¼Œé…ä»¥è½å¶ä¸å¤äº­å‰ªå½±ï¼Œä¼ é€’æ¬ç„¶è‡ªé€‚çš„ç”Ÿæ´»å“²å­¦ï¼›ä¸Šæ–¹å†™ç€é»‘è‰²çš„æ¥·ä½“'èŠæ·¡'ã€‚æ‰€æœ‰å›¾ç‰‡é‡‡ç”¨ç»Ÿä¸€å°ºå¯¸ä¸è¾¹æ¡†æ ·å¼ï¼Œå‘ˆæ¨ªå‘æ’åˆ—ã€‚é¡µé¢åº•éƒ¨ä¸­å¤®ç”¨æ¥·ä½“å°å­—å†™æ˜'2025å¹´8æœˆï¼Œæ•¬è¯·æœŸå¾…'ï¼Œæ’ç‰ˆå·¥æ•´ã€ç»“æ„æ¸…æ™°ï¼Œæ•´ä½“é£æ ¼ç»Ÿä¸€ä¸”ç»†èŠ‚ä¸°å¯Œï¼Œæå…·è§†è§‰å†²å‡»åŠ›ä¸å“ç‰Œè°ƒæ€§ã€‚", "", 222, 1328, 1328, 4.0, 50]
]



def generate_image(prompt, negative_prompt, seed, width, height, guidance_scale, num_inference_steps, progress=gr.Progress()):
    """å›¾ç‰‡ç”Ÿæˆå‡½æ•°"""
    if not prompt:
        return None, "è¯·è¾“å…¥æç¤ºè¯"
    
    progress(0.1, desc="æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
    model = load_model()
    
    # æ£€æµ‹è¯­è¨€å¹¶æ·»åŠ ç›¸åº”çš„é­”æ³•è¯
    if any('\u4e00' <= char <= '\u9fff' for char in prompt):
        # åŒ…å«ä¸­æ–‡å­—ç¬¦
        positive_magic = "è¶…æ¸…ï¼Œ4Kï¼Œç”µå½±çº§æ„å›¾ã€‚"
    else:
        # è‹±æ–‡æç¤ºè¯
        positive_magic = "Ultra HD, 4K, cinematic composition. "
    
    full_prompt = positive_magic + prompt
    
    try:
        progress(0.3, desc="æ­£åœ¨ç”Ÿæˆå›¾ç‰‡...")
        
        if seed == -1:
            seed = random.randint(0, MAX_SEED)
        
        generator = torch.Generator(device=model.device).manual_seed(seed)
        
        image = model(
            prompt=full_prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=num_inference_steps,
            true_cfg_scale=guidance_scale,
            generator=generator
        ).images[0]
        
        progress(1.0, desc="å®Œæˆ!")
        
        # ä¿å­˜å›¾ç‰‡
        timestamp = int(time.time())
        filename = f"generated_{timestamp}.png"
        image.save(filename)
        
        return image, f"å›¾ç‰‡ç”ŸæˆæˆåŠŸ! ç§å­å€¼: {seed}"
        
    except Exception as e:
        return None, f"ç”Ÿæˆå¤±è´¥: {str(e)}"



def randomize_seed():
    """éšæœºç§å­ç”Ÿæˆ"""
    return random.randint(0, MAX_SEED)

def quick_preset(preset_type):
    """å¿«é€Ÿé¢„è®¾åŠŸèƒ½"""
    presets = {
        "portrait": {
            "width": 928,
            "height": 1408,
            "guidance": 4.0,
            "steps": 50
        },
        "landscape": {
            "width": 1408,
            "height": 928,
            "guidance": 4.0,
            "steps": 50
        },
        "square": {
            "width": 1328,
            "height": 1328,
            "guidance": 4.0,
            "steps": 50
        },
        "fast": {
            "width": 1328,
            "height": 1328,
            "guidance": 3.0,
            "steps": 25
        },
        "quality": {
            "width": 1328,
            "height": 1328,
            "guidance": 5.0,
            "steps": 75
        }
    }
    return presets.get(preset_type, presets["square"])

# åˆ›å»ºGradioç•Œé¢
def create_interface():
    with gr.Blocks(title="Qwen-Image WebUI", theme=gr.themes.Soft()) as demo:
        gr.HTML("""
        <div style="text-align: center; margin-bottom: 20px;">
            <h1 style="color: #2E86AB; font-size: 2.5em;">ğŸ¨ Qwen-Image WebUI</h1>
            <p style="font-size: 1.2em; color: #555;">æ™ºèƒ½è§†è§‰åˆ›ä½œçš„åŸºç¡€æ¨¡å‹</p>
            <p style="color: #777;">ğŸ–¼ï¸ æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡</p>
            <p style="color: #888; font-size: 0.9em;">é€‚ç”¨äºYouTubeæ¼”ç¤º - å±•ç¤ºAIå›¾åƒç”Ÿæˆçš„æ— é™å¯èƒ½</p>
            <p style="color: #ff6b6b; font-size: 0.85em;">âš ï¸ å›¾ç‰‡ç¼–è¾‘ã€å›¾ç‰‡ç†è§£ã€é£æ ¼è½¬æ¢åŠŸèƒ½å³å°†å‘å¸ƒï¼Œæ•¬è¯·æœŸå¾…ï¼</p>
        </div>
        """)
        
        # Tab 1: æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡
        with gr.Tab("ğŸ“ æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡", elem_id="text_to_image"):
            with gr.Row():
                with gr.Column(scale=1):
                    prompt_input = gr.Textbox(
                        label="æç¤ºè¯ (Prompt)",
                        placeholder="æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„å›¾ç‰‡...",
                        lines=3
                    )
                    negative_prompt_input = gr.Textbox(
                        label="è´Ÿé¢æç¤ºè¯ (Negative Prompt)",
                        placeholder="æè¿°ä½ ä¸æƒ³è¦çš„å…ƒç´ ...",
                        lines=2
                    )
                    
                    with gr.Row():
                        seed_input = gr.Number(
                            label="ç§å­å€¼ (Seed)",
                            value=42,
                            minimum=-1,
                            maximum=MAX_SEED
                        )
                        random_seed_btn = gr.Button("ğŸ² éšæœº", size="sm")
                    
                    with gr.Row():
                        width_input = gr.Slider(
                            label="å®½åº¦",
                            minimum=512,
                            maximum=MAX_IMAGE_SIZE,
                            value=1408,
                            step=64
                        )
                        height_input = gr.Slider(
                            label="é«˜åº¦",
                            minimum=512,
                            maximum=MAX_IMAGE_SIZE,
                            value=928,
                            step=64
                        )
                    
                    # å¿«é€Ÿé¢„è®¾æŒ‰é’®
                    with gr.Row():
                        gr.Markdown("**å¿«é€Ÿé¢„è®¾:**")
                    with gr.Row():
                        portrait_btn = gr.Button("ğŸ“± ç«–å±", size="sm")
                        landscape_btn = gr.Button("ğŸ–¼ï¸ æ¨ªå±", size="sm")
                        square_btn = gr.Button("â¬œ æ–¹å½¢", size="sm")
                        fast_btn = gr.Button("âš¡ å¿«é€Ÿ", size="sm")
                        quality_btn = gr.Button("ğŸ’ é«˜è´¨é‡", size="sm")
                    
                    with gr.Row():
                        guidance_scale_input = gr.Slider(
                            label="å¼•å¯¼å°ºåº¦",
                            minimum=1.0,
                            maximum=10.0,
                            value=4.0,
                            step=0.1
                        )
                        num_inference_steps_input = gr.Slider(
                            label="æ¨ç†æ­¥æ•°",
                            minimum=10,
                            maximum=100,
                            value=50,
                            step=5
                        )
                    
                    generate_btn = gr.Button("ğŸ¨ ç”Ÿæˆå›¾ç‰‡", variant="primary", size="lg")
                
                with gr.Column(scale=1):
                    output_image = gr.Image(label="ç”Ÿæˆç»“æœ", type="pil")
                    output_info = gr.Textbox(label="ç”Ÿæˆä¿¡æ¯", interactive=False)
            
            # ç¤ºä¾‹
            gr.Examples(
                examples=TEXT_GENERATION_EXAMPLES,
                inputs=[prompt_input, negative_prompt_input, seed_input, width_input, height_input, guidance_scale_input, num_inference_steps_input],
                outputs=[output_image, output_info],
                fn=generate_image,
                cache_examples=False
            )
        
        # äº‹ä»¶ç»‘å®š
        random_seed_btn.click(fn=randomize_seed, outputs=seed_input)
        
        # å¿«é€Ÿé¢„è®¾æŒ‰é’®äº‹ä»¶
        portrait_btn.click(
            fn=lambda: (928, 1408, 4.0, 50),
            outputs=[width_input, height_input, guidance_scale_input, num_inference_steps_input]
        )
        landscape_btn.click(
            fn=lambda: (1408, 928, 4.0, 50),
            outputs=[width_input, height_input, guidance_scale_input, num_inference_steps_input]
        )
        square_btn.click(
            fn=lambda: (1328, 1328, 4.0, 50),
            outputs=[width_input, height_input, guidance_scale_input, num_inference_steps_input]
        )
        fast_btn.click(
            fn=lambda: (1328, 1328, 3.0, 25),
            outputs=[width_input, height_input, guidance_scale_input, num_inference_steps_input]
        )
        quality_btn.click(
            fn=lambda: (1328, 1328, 5.0, 75),
            outputs=[width_input, height_input, guidance_scale_input, num_inference_steps_input]
        )
        
        generate_btn.click(
            fn=generate_image,
            inputs=[prompt_input, negative_prompt_input, seed_input, width_input, height_input, guidance_scale_input, num_inference_steps_input],
            outputs=[output_image, output_info]
        )
        
        # æ·»åŠ CSSæ ·å¼
        demo.css = """
        #text_to_image {
            min-height: 600px;
        }
        .gradio-container {
            max-width: 1400px !important;
        }
        .gr-button {
            transition: all 0.3s ease;
        }
        .gr-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }
        .gr-form {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            border-radius: 15px;
            padding: 20px;
            margin: 10px 0;
        }
        """
    
    return demo

if __name__ == "__main__":
    # é¢„åŠ è½½æ¨¡å‹
    print("æ­£åœ¨é¢„åŠ è½½Qwen-Imageæ¨¡å‹...")
    load_model()
    print("æ¨¡å‹åŠ è½½å®Œæˆ!")
    
    # å¯åŠ¨ç•Œé¢
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True
    )
