import os
import gradio as gr
import torch
import numpy as np
import glob
from omegaconf import OmegaConf
from torchvision.transforms import v2
from diffusers.utils import load_image
from einops import rearrange
from pipeline import CausalInferencePipeline
from wan.vae.wanx_vae import get_wanx_vae_wrapper
from demo_utils.vae_block3 import VAEDecoderWrapper
from utils.visualize import process_video
from utils.misc import set_seed
from utils.conditions import *
from utils.wan_wrapper import WanDiffusionWrapper
from safetensors.torch import load_file
import tempfile
import shutil

class InteractiveGameInference:
    def __init__(self, config_path, checkpoint_path, pretrained_model_path):
        self.config_path = config_path
        self.checkpoint_path = checkpoint_path
        self.pretrained_model_path = pretrained_model_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.weight_dtype = torch.bfloat16

        self._init_config()
        self._init_models()

        self.frame_process = v2.Compose([
            v2.Resize(size=(352, 640), antialias=True),
            v2.ToTensor(),
            v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
        ])

    def _init_config(self):
        self.config = OmegaConf.load(self.config_path)

    def _init_models(self):
        # Initialize pipeline
        generator = WanDiffusionWrapper(
            **getattr(self.config, "model_kwargs", {}), is_causal=True)
        current_vae_decoder = VAEDecoderWrapper()
        vae_state_dict = torch.load(os.path.join(self.pretrained_model_path, "Wan2.1_VAE.pth"), map_location="cpu")
        decoder_state_dict = {}
        for key, value in vae_state_dict.items():
            if 'decoder.' in key or 'conv2' in key:
                decoder_state_dict[key] = value
        current_vae_decoder.load_state_dict(decoder_state_dict)
        current_vae_decoder.to(self.device, torch.float16)
        current_vae_decoder.requires_grad_(False)
        current_vae_decoder.eval()
        current_vae_decoder.compile(mode="max-autotune-no-cudagraphs")
        pipeline = CausalInferencePipeline(self.config, generator=generator, vae_decoder=current_vae_decoder)
        if self.checkpoint_path:
            print("Loading Pretrained Model...")
            state_dict = load_file(self.checkpoint_path)
            pipeline.generator.load_state_dict(state_dict)

        self.pipeline = pipeline.to(device=self.device, dtype=self.weight_dtype)
        self.pipeline.vae_decoder.to(torch.float16)

        vae = get_wanx_vae_wrapper(self.pretrained_model_path, torch.float16)
        vae.requires_grad_(False)
        vae.eval()
        self.vae = vae.to(self.device, self.weight_dtype)

    def _resizecrop(self, image, th, tw):
        w, h = image.size
        if h / w > th / tw:
            new_w = int(w)
            new_h = int(new_w * th / tw)
        else:
            new_h = int(h)
            new_w = int(new_h * tw / th)
        left = (w - new_w) / 2
        top = (h - new_h) / 2
        right = (w + new_w) / 2
        bottom = (h + new_h) / 2
        image = image.crop((left, top, right, bottom))
        return image
    
    def generate_videos(self, img_path, num_output_frames, seed, output_folder):
        set_seed(seed)
        os.makedirs(output_folder, exist_ok=True)
        
        mode = self.config.get('mode', 'universal')
        
        image = load_image(img_path)
        image = self._resizecrop(image, 352, 640)
        image = self.frame_process(image)[None, :, None, :, :].to(dtype=self.weight_dtype, device=self.device)

        # Encode the input image as the first latent
        padding_video = torch.zeros_like(image).repeat(1, 1, 4 * (num_output_frames - 1), 1, 1)
        img_cond = torch.concat([image, padding_video], dim=2)
        tiler_kwargs={"tiled": True, "tile_size": [44, 80], "tile_stride": [23, 38]}
        img_cond = self.vae.encode(img_cond, device=self.device, **tiler_kwargs).to(self.device)
        mask_cond = torch.ones_like(img_cond)
        mask_cond[:, :, 1:] = 0
        cond_concat = torch.cat([mask_cond[:, :4], img_cond], dim=1) 
        visual_context = self.vae.clip.encode_video(image)
        sampled_noise = torch.randn(
            [1, 16, num_output_frames, 44, 80], device=self.device, dtype=self.weight_dtype
        )
        num_frames = (num_output_frames - 1) * 4 + 1
        
        conditional_dict = {
            "cond_concat": cond_concat.to(device=self.device, dtype=self.weight_dtype),
            "visual_context": visual_context.to(device=self.device, dtype=self.weight_dtype)
        }
        
        if mode == 'universal':
            cond_data = Bench_actions_universal(num_frames)
            mouse_condition = cond_data['mouse_condition'].unsqueeze(0).to(device=self.device, dtype=self.weight_dtype)
            conditional_dict['mouse_cond'] = mouse_condition
        elif mode == 'gta_drive':
            cond_data = Bench_actions_gta_drive(num_frames)
            mouse_condition = cond_data['mouse_condition'].unsqueeze(0).to(device=self.device, dtype=self.weight_dtype)
            conditional_dict['mouse_cond'] = mouse_condition
        else:
            cond_data = Bench_actions_templerun(num_frames)
        keyboard_condition = cond_data['keyboard_condition'].unsqueeze(0).to(device=self.device, dtype=self.weight_dtype)
        conditional_dict['keyboard_cond'] = keyboard_condition
        
        with torch.no_grad():
            videos = self.pipeline.inference(
                noise=sampled_noise,
                conditional_dict=conditional_dict,
                return_latents=False,
                mode=mode,
                profile=False
            )

        videos_tensor = torch.cat(videos, dim=1)
        videos = rearrange(videos_tensor, "B T C H W -> B T H W C")
        videos = ((videos.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)[0]
        video = np.ascontiguousarray(videos)
        mouse_icon = 'assets/images/mouse.png'
        
        # ç”Ÿæˆè¾“å‡ºè§†é¢‘æ–‡ä»¶å
        base_name = os.path.splitext(os.path.basename(img_path))[0]
        output_path = os.path.join(output_folder, f'{base_name}_demo.mp4')
        output_icon_path = os.path.join(output_folder, f'{base_name}_demo_icon.mp4')
        
        if mode != 'templerun':
            config = (
                keyboard_condition[0].float().cpu().numpy(),
                mouse_condition[0].float().cpu().numpy()
            )
        else:
            config = (
                keyboard_condition[0].float().cpu().numpy()
            )
        
        process_video(video.astype(np.uint8), output_path, config, mouse_icon, mouse_scale=0.1, process_icon=False, mode=mode)
        process_video(video.astype(np.uint8), output_icon_path, config, mouse_icon, mouse_scale=0.1, process_icon=True, mode=mode)
        
        return output_path, output_icon_path

def get_demo_images():
    """è·å–æ‰€æœ‰demoå›¾ç‰‡"""
    demo_images = []
    for folder in ['universal', 'gta_drive', 'temple_run']:
        folder_path = f'demo_images/{folder}'
        if os.path.exists(folder_path):
            images = glob.glob(os.path.join(folder_path, '*.png')) + glob.glob(os.path.join(folder_path, '*.jpg')) + glob.glob(os.path.join(folder_path, '*.webp'))
            demo_images.extend(sorted(images))
    return demo_images

def get_config_files():
    """è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶"""
    config_files = glob.glob('configs/inference_yaml/*.yaml')
    return sorted(config_files)

def get_checkpoint_paths():
    """è·å–æ‰€æœ‰checkpointè·¯å¾„"""
    checkpoints = []
    base_path = "Matrix-Game-2.0"
    if os.path.exists(base_path):
        for subfolder in ['gta_distilled_model', 'templerun_distilled_model', 'base_distilled_model']:
            subfolder_path = os.path.join(base_path, subfolder)
            if os.path.exists(subfolder_path):
                safetensors_files = glob.glob(os.path.join(subfolder_path, '*.safetensors'))
                checkpoints.extend(safetensors_files)
    return sorted(checkpoints)

def inference_fn(image, config_path, checkpoint_path, num_output_frames, seed, pretrained_model_path):
    """æ¨ç†å‡½æ•°"""
    if not image:
        return None, None, "âŒ è¯·å…ˆä¸Šä¼ å›¾ç‰‡"
    
    if not config_path:
        return None, None, "âŒ è¯·é€‰æ‹©é…ç½®æ–‡ä»¶"
    
    if not checkpoint_path:
        return None, None, "âŒ è¯·é€‰æ‹©æ¨¡å‹æƒé‡"
    
    if not os.path.exists(config_path):
        return None, None, f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}"
    
    if not os.path.exists(checkpoint_path):
        return None, None, f"âŒ æ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}"
    
    try:
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶å¤¹
        with tempfile.TemporaryDirectory() as temp_dir:
            # å¦‚æœimageæ˜¯ä¸Šä¼ çš„æ–‡ä»¶ï¼Œéœ€è¦å¤„ç†è·¯å¾„
            if hasattr(image, 'name'):
                img_path = image.name
            else:
                img_path = image
            
            if not os.path.exists(img_path):
                return None, None, f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}"
            
            print(f"ğŸ”„ å¼€å§‹æ¨ç†...")
            print(f"ğŸ“· è¾“å…¥å›¾ç‰‡: {img_path}")
            print(f"âš™ï¸ é…ç½®æ–‡ä»¶: {config_path}")
            print(f"ğŸ”§ æ¨¡å‹æƒé‡: {checkpoint_path}")
            
            # åˆå§‹åŒ–æ¨ç†å™¨
            inferencer = InteractiveGameInference(config_path, checkpoint_path, pretrained_model_path)
            
            # ç”Ÿæˆè§†é¢‘
            output_path, output_icon_path = inferencer.generate_videos(
                img_path=img_path,
                num_output_frames=num_output_frames,
                seed=seed,
                output_folder=temp_dir
            )
            
            # å¤åˆ¶åˆ°è¾“å‡ºæ–‡ä»¶å¤¹
            os.makedirs("outputs", exist_ok=True)
            final_output = os.path.join("outputs", os.path.basename(output_path))
            final_icon_output = os.path.join("outputs", os.path.basename(output_icon_path))
            shutil.copy2(output_path, final_output)
            shutil.copy2(output_icon_path, final_icon_output)
            
            print(f"âœ… æ¨ç†å®Œæˆ!")
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {final_output}")
            print(f"ğŸ“ å¸¦å›¾æ ‡ç‰ˆæœ¬: {final_icon_output}")
            
            return final_output, final_icon_output, "âœ… æ¨ç†å®Œæˆï¼è§†é¢‘å·²ä¿å­˜åˆ° outputs/ æ–‡ä»¶å¤¹"
            
    except Exception as e:
        error_msg = f"âŒ æ¨ç†å¤±è´¥: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return None, None, error_msg

def create_examples():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    demo_images = get_demo_images()
    config_files = get_config_files()
    checkpoint_paths = get_checkpoint_paths()
    
    examples = []
    
    # ä¸ºæ¯ç§æ¨¡å¼åˆ›å»ºç¤ºä¾‹
    modes = {
        'universal': ('configs/inference_yaml/inference_universal.yaml', 'Matrix-Game-2.0/base_distilled_model'),
        'gta_drive': ('configs/inference_yaml/inference_gta_drive.yaml', 'Matrix-Game-2.0/gta_distilled_model'),
        'templerun': ('configs/inference_yaml/inference_templerun.yaml', 'Matrix-Game-2.0/templerun_distilled_model')
    }
    
    for mode, (config, checkpoint_folder) in modes.items():
        # æ‰¾åˆ°å¯¹åº”æ¨¡å¼çš„å›¾ç‰‡
        mode_images = [img for img in demo_images if mode.replace('_', '') in img or mode in img]
        if not mode_images:
            continue
            
        # æ‰¾åˆ°å¯¹åº”çš„checkpoint
        checkpoint_files = glob.glob(os.path.join(checkpoint_folder, '*.safetensors'))
        if not checkpoint_files:
            continue
            
        # åˆ›å»ºç¤ºä¾‹
        example_image = mode_images[0] if mode_images else None
        example_checkpoint = checkpoint_files[0] if checkpoint_files else ""
        
        if example_image and os.path.exists(config):
            examples.append([
                example_image,
                config,
                example_checkpoint,
                150,  # num_output_frames
                42,   # seed
                "Matrix-Game-2.0"  # pretrained_model_path
            ])
    
    return examples

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    with gr.Blocks(title="Matrix Game Inference WebUI", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ® Matrix Game Inference WebUI
        
        å°†å•å¼ æ¸¸æˆæˆªå›¾è½¬æ¢ä¸ºè¿ç»­æ¸¸æˆè§†é¢‘çš„AIæ¨ç†å·¥å…·
        
        æ”¯æŒä¸‰ç§æ¸¸æˆæ¨¡å¼ï¼š
        - **Universalï¼ˆé€šç”¨ï¼‰**: é€‚ç”¨äºå„ç§æ¸¸æˆåœºæ™¯
        - **GTA Driveï¼ˆGTAé©¾é©¶ï¼‰**: ä¸“é—¨é’ˆå¯¹GTAç±»é©¾é©¶æ¸¸æˆä¼˜åŒ–  
        - **Temple Runï¼ˆç¥åº™é€ƒäº¡ï¼‰**: ä¸“é—¨é’ˆå¯¹è·‘é…·ç±»æ¸¸æˆä¼˜åŒ–
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“ è¾“å…¥è®¾ç½®")
                
                image_input = gr.Image(
                    label="è¾“å…¥å›¾ç‰‡ (æ”¯æŒ PNGã€JPGã€WEBP æ ¼å¼)",
                    type="filepath",
                    height=300
                )
                
                config_dropdown = gr.Dropdown(
                    choices=get_config_files(),
                    label="é…ç½®æ–‡ä»¶ (é€‰æ‹©å¯¹åº”çš„æ¸¸æˆæ¨¡å¼)",
                    value="configs/inference_yaml/inference_universal.yaml" if os.path.exists("configs/inference_yaml/inference_universal.yaml") else None
                )
                
                checkpoint_dropdown = gr.Dropdown(
                    choices=get_checkpoint_paths(),
                    label="æ¨¡å‹æƒé‡ (é€‰æ‹©å¯¹åº”æ¨¡å¼çš„æƒé‡æ–‡ä»¶)",
                    value=get_checkpoint_paths()[0] if get_checkpoint_paths() else ""
                )
                
            with gr.Column(scale=1):
                gr.Markdown("### âš™ï¸ å‚æ•°è®¾ç½®")
                
                num_frames_slider = gr.Slider(
                    minimum=10,
                    maximum=300,
                    value=150,
                    step=1,
                    label="è¾“å‡ºå¸§æ•° (æ›´å¤šå¸§æ•°=æ›´é•¿è§†é¢‘ï¼Œä½†éœ€è¦æ›´å¤šæ—¶é—´å’Œå†…å­˜)"
                )
                
                seed_number = gr.Number(
                    value=42,
                    label="éšæœºç§å­ (ç›¸åŒç§å­äº§ç”Ÿç›¸åŒç»“æœ)",
                    precision=0
                )
                
                pretrained_path = gr.Textbox(
                    value="Matrix-Game-2.0",
                    label="é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„",
                    info="åŒ…å« VAE å’Œå…¶ä»–åŸºç¡€æ¨¡å‹çš„æ–‡ä»¶å¤¹"
                )
                
                run_button = gr.Button("ğŸš€ å¼€å§‹æ¨ç†", variant="primary", size="lg")
        
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸ“º è¾“å‡ºç»“æœ")
                with gr.Row():
                    output_video = gr.Video(label="ç”Ÿæˆè§†é¢‘ï¼ˆæ™®é€šç‰ˆï¼‰", height=300)
                    output_icon_video = gr.Video(label="ç”Ÿæˆè§†é¢‘ï¼ˆå¸¦æ“ä½œå›¾æ ‡ç‰ˆï¼‰", height=300)
                status_output = gr.Textbox(label="çŠ¶æ€ä¿¡æ¯", interactive=False, lines=3)
        
        # ç¤ºä¾‹
        gr.Markdown("""
        ### ğŸ’¡ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
        ç‚¹å‡»ä¸‹é¢çš„ç¤ºä¾‹å¯ä»¥å¿«é€ŸåŠ è½½å¯¹åº”çš„é…ç½®å’Œå›¾ç‰‡
        """)
        examples = create_examples()
        if examples:
            gr.Examples(
                examples=examples,
                inputs=[
                    image_input,
                    config_dropdown,
                    checkpoint_dropdown,
                    num_frames_slider,
                    seed_number,
                    pretrained_path
                ],
                label="ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿå¼€å§‹"
            )
        else:
            gr.Markdown("âš ï¸ æœªæ‰¾åˆ°ç¤ºä¾‹æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ demo_images å’Œæ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ### ä½¿ç”¨æ­¥éª¤ï¼š
            1. **é€‰æ‹©å›¾ç‰‡**: ä¸Šä¼ ä¸€å¼ æ¸¸æˆæˆªå›¾ï¼Œå»ºè®®åˆ†è¾¨ç‡ä¸è¦å¤ªé«˜
            2. **é€‰æ‹©é…ç½®**: æ ¹æ®æ¸¸æˆç±»å‹é€‰æ‹©å¯¹åº”çš„ yaml é…ç½®æ–‡ä»¶
            3. **é€‰æ‹©æƒé‡**: é€‰æ‹©ä¸é…ç½®æ–‡ä»¶åŒ¹é…çš„æ¨¡å‹æƒé‡æ–‡ä»¶
            4. **è°ƒæ•´å‚æ•°**: è®¾ç½®è¾“å‡ºå¸§æ•°å’Œéšæœºç§å­
            5. **å¼€å§‹æ¨ç†**: ç‚¹å‡»æŒ‰é’®å¼€å§‹ç”Ÿæˆè§†é¢‘
            
            ### æ³¨æ„äº‹é¡¹ï¼š
            - æ¨ç†è¿‡ç¨‹éœ€è¦ä¸€å®šæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
            - æ›´å¤šå¸§æ•°ä¼šäº§ç”Ÿæ›´é•¿çš„è§†é¢‘ï¼Œä½†éœ€è¦æ›´å¤šGPUå†…å­˜
            - å¦‚æœé‡åˆ°å†…å­˜ä¸è¶³ï¼Œè¯·å‡å°‘è¾“å‡ºå¸§æ•°
            - ç”Ÿæˆçš„è§†é¢‘ä¼šä¿å­˜åœ¨ `outputs/` æ–‡ä»¶å¤¹ä¸­
            """)
        
        # ç»‘å®šæ¨ç†å‡½æ•°
        run_button.click(
            fn=inference_fn,
            inputs=[
                image_input,
                config_dropdown,
                checkpoint_dropdown,
                num_frames_slider,
                seed_number,
                pretrained_path
            ],
            outputs=[output_video, output_icon_video, status_output],
            show_progress=True
        )
    
    return demo

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print("ğŸ® Matrix Game WebUI")
    print("=" * 50)
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        print(f"âœ… CUDA å¯ç”¨: {torch.cuda.get_device_name()}")
        print(f"   GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âš ï¸  CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè¿è¡Œï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = [
        "Matrix-Game-2.0/Wan2.1_VAE.pth",
        "assets/images/mouse.png"
    ]
    
    missing_files = []
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
    
    if missing_files:
        print("âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶:")
        for file in missing_files:
            print(f"   - {file}")
        print("\nè¯·ç¡®ä¿å·²æ­£ç¡®ä¸‹è½½æ‰€æœ‰æ¨¡å‹æ–‡ä»¶")
        return False
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_files = get_config_files()
    if not config_files:
        print("âŒ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ configs/inference_yaml/ ç›®å½•")
        return False
    
    # æ£€æŸ¥checkpointæ–‡ä»¶
    checkpoint_files = get_checkpoint_paths()
    if not checkpoint_files:
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ Matrix-Game-2.0/ ç›®å½•")
        return False
    
    print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
    print(f"ğŸ“ æ‰¾åˆ° {len(config_files)} ä¸ªé…ç½®æ–‡ä»¶")
    print(f"ğŸ”§ æ‰¾åˆ° {len(checkpoint_files)} ä¸ªæ¨¡å‹æƒé‡")
    print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(get_demo_images())} ä¸ªç¤ºä¾‹å›¾ç‰‡")
    print("=" * 50)
    
    return True

if __name__ == "__main__":
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        print("ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        exit(1)
    
    # ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs("outputs", exist_ok=True)
    
    try:
        # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
        print("ğŸš€ å¯åŠ¨WebUI...")
        print("ç•Œé¢å°†åœ¨ http://localhost:7860 æ‰“å¼€")
        print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
        print("=" * 50)
        
        demo = create_interface()
        demo.launch(
            server_name="0.0.0.0",
            server_port=7860,
            share=False,
            debug=False,
            show_error=True
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ WebUI å·²åœæ­¢")
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {str(e)}")
        print("è¯·æ£€æŸ¥ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")
