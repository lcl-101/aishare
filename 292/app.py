"""
UltraShape Gradio Web Application
åŸºäº Gradio çš„ UltraShape 3D ç½‘æ ¼ç²¾ç‚¼ Web ç•Œé¢
"""

import os
import sys
import tempfile
import torch
import gradio as gr
from PIL import Image
from omegaconf import OmegaConf

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from ultrashape.rembg import BackgroundRemover
from ultrashape.utils.misc import instantiate_from_config
from ultrashape.surface_loaders import SharpEdgeSurfaceLoader
from ultrashape.utils import voxelize_from_point
from ultrashape.pipelines import UltraShapePipeline

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹
pipeline = None
loader = None
rembg = None
token_num = None
voxel_res = None
device = None


def load_models():
    """å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""
    global pipeline, loader, rembg, token_num, voxel_res, device
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    config_path = os.path.join(project_root, "configs/infer_dit_refine.yaml")
    ckpt_path = os.path.join(project_root, "checkpoints/UltraShape/ultrashape_v1.pt")
    
    print("=" * 60)
    print("æ­£åœ¨åŠ è½½ UltraShape æ¨¡å‹...")
    print("=" * 60)
    
    print(f"æ­£åœ¨ä» {config_path} åŠ è½½é…ç½®...")
    config = OmegaConf.load(config_path)
    
    # ä¿®æ”¹ dinov2 æ¨¡å‹è·¯å¾„ä¸ºæœ¬åœ°è·¯å¾„
    dinov2_local_path = os.path.join(project_root, "checkpoints/dinov2-large")
    if os.path.exists(dinov2_local_path):
        config.model.params.conditioner_config.params.main_image_encoder.kwargs.version = dinov2_local_path
        print(f"ä½¿ç”¨æœ¬åœ° DINOv2 æ¨¡å‹: {dinov2_local_path}")
    
    print("æ­£åœ¨åˆå§‹åŒ– VAE...")
    vae = instantiate_from_config(config.model.params.vae_config)
    
    print("æ­£åœ¨åˆå§‹åŒ– DiT...")
    dit = instantiate_from_config(config.model.params.dit_cfg)
    
    print("æ­£åœ¨åˆå§‹åŒ–å›¾åƒç¼–ç å™¨...")
    conditioner = instantiate_from_config(config.model.params.conditioner_config)
    
    print("æ­£åœ¨åˆå§‹åŒ–è°ƒåº¦å™¨å’Œå¤„ç†å™¨...")
    scheduler = instantiate_from_config(config.model.params.scheduler_cfg)
    image_processor = instantiate_from_config(config.model.params.image_processor_cfg)
    
    print(f"æ­£åœ¨ä» {ckpt_path} åŠ è½½æƒé‡...")
    weights = torch.load(ckpt_path, map_location='cpu')
    
    vae.load_state_dict(weights['vae'], strict=True)
    dit.load_state_dict(weights['dit'], strict=True)
    conditioner.load_state_dict(weights['conditioner'], strict=True)
    
    vae.eval().to(device)
    dit.eval().to(device)
    conditioner.eval().to(device)
    
    if hasattr(vae, 'enable_flashvdm_decoder'):
        vae.enable_flashvdm_decoder()
    
    pipeline = UltraShapePipeline(
        vae=vae,
        model=dit,
        scheduler=scheduler,
        conditioner=conditioner,
        image_processor=image_processor
    )
    
    token_num = config.model.params.vae_config.params.num_latents
    voxel_res = config.model.params.vae_config.params.voxel_query_res
    
    print(f"æ­£åœ¨åˆå§‹åŒ–è¡¨é¢åŠ è½½å™¨ (Token æ•°é‡: {token_num})...")
    loader = SharpEdgeSurfaceLoader(
        num_sharp_points=204800,
        num_uniform_points=204800,
    )
    
    print("æ­£åœ¨åˆå§‹åŒ–èƒŒæ™¯ç§»é™¤å™¨...")
    rembg = BackgroundRemover()
    
    print("=" * 60)
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")
    print("=" * 60)


def refine_mesh(
    image_input,
    mesh_input,
    steps: int = 50,
    scale: float = 0.99,
    octree_res: int = 1024,
    seed: int = 42,
    remove_bg: bool = True,
    progress=gr.Progress()
):
    """
    æ‰§è¡Œç½‘æ ¼ç²¾ç‚¼æ¨ç†
    """
    global pipeline, loader, rembg, token_num, voxel_res, device
    
    if pipeline is None:
        return None, "âŒ é”™è¯¯ï¼šæ¨¡å‹å°šæœªåŠ è½½ï¼Œè¯·ç¨åé‡è¯•"
    
    if image_input is None:
        return None, "âŒ é”™è¯¯ï¼šè¯·ä¸Šä¼ å‚è€ƒå›¾åƒ"
    
    if mesh_input is None:
        return None, "âŒ é”™è¯¯ï¼šè¯·ä¸Šä¼ ç²—ç³™ç½‘æ ¼æ–‡ä»¶"
    
    try:
        progress(0.1, desc="æ­£åœ¨å¤„ç†è¾“å…¥å›¾åƒ...")
        
        # å¤„ç†å›¾åƒ
        if isinstance(image_input, str):
            image = Image.open(image_input)
        else:
            image = Image.fromarray(image_input)
        
        if remove_bg or image.mode != 'RGBA':
            progress(0.2, desc="æ­£åœ¨ç§»é™¤èƒŒæ™¯...")
            image = rembg(image)
        
        progress(0.3, desc="æ­£åœ¨åŠ è½½ç½‘æ ¼...")
        
        # å¤„ç†ç½‘æ ¼æ–‡ä»¶è·¯å¾„
        mesh_path = mesh_input
        if hasattr(mesh_input, 'name'):
            mesh_path = mesh_input.name
        
        surface = loader(mesh_path, normalize_scale=scale).to(device, dtype=torch.float16)
        pc = surface[:, :, :3]  # [B, N, 3]
        
        progress(0.4, desc="æ­£åœ¨ä½“ç´ åŒ–...")
        _, voxel_idx = voxelize_from_point(pc, token_num, resolution=voxel_res)
        
        # å¦‚æœä½“ç´ æ•°é‡å°‘äºç›®æ ‡æ•°é‡ï¼Œé€šè¿‡é‡å¤å¡«å……åˆ°ç›®æ ‡å¤§å°
        if voxel_idx.shape[1] < token_num:
            B, actual_k, _ = voxel_idx.shape
            repeat_times = (token_num + actual_k - 1) // actual_k
            voxel_idx = voxel_idx.repeat(1, repeat_times, 1)[:, :token_num, :]
        
        progress(0.5, desc="æ­£åœ¨è¿è¡Œæ‰©æ•£è¿‡ç¨‹...")
        generator = torch.Generator(device).manual_seed(seed)
        
        with torch.autocast(device_type="cuda", dtype=torch.bfloat16):
            mesh, _ = pipeline(
                image=image,
                voxel_cond=voxel_idx,
                generator=generator,
                box_v=1.0,
                mc_level=0.0,
                octree_resolution=octree_res,
                num_inference_steps=steps,
            )
        
        progress(0.9, desc="æ­£åœ¨ä¿å­˜ç»“æœ...")
        
        # ä¿å­˜ç»“æœ
        output_dir = tempfile.mkdtemp()
        output_path = os.path.join(output_dir, "refined_mesh.glb")
        
        mesh = mesh[0]
        mesh.export(output_path)
        
        progress(1.0, desc="å®Œæˆï¼")
        
        return output_path, f"âœ… ç²¾ç‚¼å®Œæˆï¼æ¨ç†æ­¥æ•°: {steps}, éšæœºç§å­: {seed}"
    
    except Exception as e:
        import traceback
        error_msg = f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}\n{traceback.format_exc()}"
        print(error_msg)
        return None, error_msg


def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    # è‡ªå®šä¹‰ CSS
    custom_css = """
    .youtube-banner {
        background: linear-gradient(135deg, #FF0000 0%, #CC0000 100%);
        padding: 15px 20px;
        border-radius: 10px;
        margin-bottom: 20px;
        text-align: center;
    }
    .youtube-banner a {
        color: white !important;
        text-decoration: none;
        font-size: 18px;
        font-weight: bold;
    }
    .youtube-banner a:hover {
        text-decoration: underline;
    }
    .youtube-icon {
        margin-right: 8px;
    }
    """
    
    with gr.Blocks(
        title="UltraShape - 3D ç½‘æ ¼ç²¾ç‚¼",
        css=custom_css,
        theme=gr.themes.Soft()
    ) as demo:
        
        # YouTube é¢‘é“æ¨ªå¹…
        gr.HTML("""
        <div class="youtube-banner">
            <a href="https://www.youtube.com/@rongyikanshijie-ai" target="_blank">
                <span class="youtube-icon">â–¶ï¸</span>
                AI æŠ€æœ¯åˆ†äº«é¢‘é“ - æ¬¢è¿è®¢é˜…æˆ‘çš„ YouTube é¢‘é“ï¼
            </a>
        </div>
        """)
        
        gr.Markdown("""
        # ğŸ¨ UltraShape - 3D ç½‘æ ¼ç²¾ç‚¼å·¥å…·
        
        ä¸Šä¼ å‚è€ƒå›¾åƒå’Œç²—ç³™ç½‘æ ¼ï¼Œä½¿ç”¨ UltraShape æ¨¡å‹ç”Ÿæˆç²¾ç»†çš„ 3D ç½‘æ ¼ã€‚
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ è¾“å…¥")
                
                image_input = gr.Image(
                    label="å‚è€ƒå›¾åƒ",
                    type="numpy",
                    sources=["upload", "clipboard"],
                    height=300
                )
                
                mesh_input = gr.Model3D(
                    label="ç²—ç³™ç½‘æ ¼æ–‡ä»¶ (.glb / .obj)",
                    height=300,
                    clear_color=[0.8, 0.8, 0.8, 1.0]
                )
                
                gr.Markdown("### âš™ï¸ å‚æ•°è®¾ç½®")
                
                with gr.Row():
                    steps = gr.Slider(
                        label="æ¨ç†æ­¥æ•°",
                        minimum=10,
                        maximum=100,
                        value=50,
                        step=1,
                        info="æ›´å¤šæ­¥æ•°å¯èƒ½äº§ç”Ÿæ›´å¥½çš„ç»“æœï¼Œä½†éœ€è¦æ›´é•¿æ—¶é—´"
                    )
                    
                    seed = gr.Number(
                        label="éšæœºç§å­",
                        value=42,
                        precision=0,
                        info="è®¾ç½®éšæœºç§å­ä»¥è·å¾—å¯å¤ç°çš„ç»“æœ"
                    )
                
                with gr.Row():
                    scale = gr.Slider(
                        label="ç½‘æ ¼å½’ä¸€åŒ–æ¯”ä¾‹",
                        minimum=0.5,
                        maximum=1.0,
                        value=0.99,
                        step=0.01,
                        info="ç½‘æ ¼å½’ä¸€åŒ–çš„ç¼©æ”¾å› å­"
                    )
                    
                    octree_res = gr.Slider(
                        label="å…«å‰æ ‘åˆ†è¾¨ç‡",
                        minimum=256,
                        maximum=2048,
                        value=1024,
                        step=64,
                        info="Marching Cubes åˆ†è¾¨ç‡"
                    )
                
                remove_bg = gr.Checkbox(
                    label="ç§»é™¤èƒŒæ™¯",
                    value=True,
                    info="è‡ªåŠ¨ç§»é™¤å›¾åƒèƒŒæ™¯"
                )
                
                submit_btn = gr.Button(
                    "ğŸš€ å¼€å§‹ç²¾ç‚¼",
                    variant="primary",
                    size="lg"
                )
            
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¥ è¾“å‡º")
                
                output_model = gr.Model3D(
                    label="ç²¾ç‚¼åçš„ 3D æ¨¡å‹",
                    height=400,
                    clear_color=[0.8, 0.8, 0.8, 1.0]
                )
                
                output_file = gr.File(
                    label="ä¸‹è½½ç²¾ç‚¼åçš„ç½‘æ ¼æ–‡ä»¶"
                )
                
                status_text = gr.Textbox(
                    label="çŠ¶æ€",
                    interactive=False,
                    lines=2
                )
        
        # ä½¿ç”¨è¯´æ˜
        gr.Markdown("""
        ---
        ### ğŸ“– ä½¿ç”¨è¯´æ˜
        
        1. **ä¸Šä¼ å‚è€ƒå›¾åƒ**ï¼šä¸Šä¼ æ‚¨æƒ³è¦ä½œä¸ºå‚è€ƒçš„å›¾åƒï¼ˆæ”¯æŒ PNGã€JPG ç­‰æ ¼å¼ï¼‰
        2. **ä¸Šä¼ ç²—ç³™ç½‘æ ¼**ï¼šä¸Šä¼ éœ€è¦ç²¾ç‚¼çš„ç²—ç³™ 3D ç½‘æ ¼æ–‡ä»¶ï¼ˆæ”¯æŒ .glbã€.objã€.ply æ ¼å¼ï¼‰
        3. **è°ƒæ•´å‚æ•°**ï¼ˆå¯é€‰ï¼‰ï¼š
           - **æ¨ç†æ­¥æ•°**ï¼šæ›´å¤šæ­¥æ•°é€šå¸¸äº§ç”Ÿæ›´å¥½çš„ç»“æœ
           - **éšæœºç§å­**ï¼šç”¨äºå¯å¤ç°çš„ç»“æœ
           - **ç½‘æ ¼å½’ä¸€åŒ–æ¯”ä¾‹**ï¼šè°ƒæ•´ç½‘æ ¼çš„ç¼©æ”¾
           - **å…«å‰æ ‘åˆ†è¾¨ç‡**ï¼šæ§åˆ¶è¾“å‡ºç½‘æ ¼çš„ç²¾åº¦
        4. **ç‚¹å‡»"å¼€å§‹ç²¾ç‚¼"**ï¼šç­‰å¾…å¤„ç†å®Œæˆ
        5. **æŸ¥çœ‹å’Œä¸‹è½½ç»“æœ**ï¼šåœ¨å³ä¾§é¢„è§ˆ 3D æ¨¡å‹å¹¶ä¸‹è½½
        
        ---
        ### âš ï¸ æ³¨æ„äº‹é¡¹
        
        - æ¨ç†è¿‡ç¨‹éœ€è¦ GPUï¼Œè¯·ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ˜¾å­˜
        - å¤„ç†æ—¶é—´å–å†³äºæ¨ç†æ­¥æ•°å’Œå…«å‰æ ‘åˆ†è¾¨ç‡
        - å»ºè®®ä½¿ç”¨å…·æœ‰æ¸…æ™°èƒŒæ™¯çš„å‚è€ƒå›¾åƒä»¥è·å¾—æœ€ä½³æ•ˆæœ
        """)
        
        # ç»‘å®šäº‹ä»¶
        def process_and_return(image, mesh, steps, scale, octree_res, seed, remove_bg, progress=gr.Progress()):
            output_path, status = refine_mesh(
                image, mesh, int(steps), scale, int(octree_res), int(seed), remove_bg, progress
            )
            return output_path, output_path, status
        
        submit_btn.click(
            fn=process_and_return,
            inputs=[image_input, mesh_input, steps, scale, octree_res, seed, remove_bg],
            outputs=[output_model, output_file, status_text]
        )
    
    return demo


if __name__ == "__main__":
    # å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
    load_models()
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
