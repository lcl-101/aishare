"""
Qwen3-VL Multimodal RAG Web Application

åŸºäº Gradio çš„å¤šæ¨¡æ€ RAG æ¼”ç¤ºç¨‹åºï¼Œæ”¯æŒï¼š
- PDF æ–‡æ¡£ä¸Šä¼ å’Œå¤„ç†
- å›¾ç‰‡æ–‡æ¡£ä¸Šä¼ 
- æ–‡æœ¬æŸ¥è¯¢æ£€ç´¢
- ä½¿ç”¨ Qwen3-VL-Embedding è¿›è¡ŒåµŒå…¥
- ä½¿ç”¨ Qwen3-VL-Reranker è¿›è¡Œé‡æ’åº
- ä½¿ç”¨ Qwen3-VL ç”Ÿæˆç­”æ¡ˆ
"""

import os
import sys
import torch
import numpy as np
import gradio as gr
import requests
import logging
from pathlib import Path
from PIL import Image
from typing import List, Dict, Optional, Tuple

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from models.qwen3_vl_embedding import Qwen3VLEmbedder
from models.qwen3_vl_reranker import Qwen3VLReranker
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==================== å…¨å±€é…ç½® ====================
EXAMPLE_PDF_URL = "https://climate.ec.europa.eu/system/files/2018-06/youth_magazine_en.pdf"
EXAMPLE_PDF_PATH = "data/examples/climate_document.pdf"
EXAMPLE_IMAGES_DIR = "data/examples/document_pages"
TEMP_DIR = "temp"

# æ¨¡å‹è·¯å¾„é…ç½® (ä¼˜å…ˆä½¿ç”¨æœ¬åœ°è·¯å¾„)
EMBEDDING_MODEL_PATH = os.environ.get(
    "EMBEDDING_MODEL_PATH", 
    "checkpoints/Qwen3-VL-Embedding-2B"
)
RERANKER_MODEL_PATH = os.environ.get(
    "RERANKER_MODEL_PATH", 
    "checkpoints/Qwen3-VL-Reranker-2B"
)
VLM_MODEL_PATH = os.environ.get(
    "VLM_MODEL_PATH", 
    "checkpoints/Qwen3-VL-2B-Instruct"
)

# å¦‚æœæœ¬åœ°è·¯å¾„ä¸å­˜åœ¨ï¼Œä½¿ç”¨ HuggingFace æ¨¡å‹
def get_model_path(local_path: str, hf_path: str) -> str:
    if os.path.exists(local_path):
        logger.info(f"ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {local_path}")
        return local_path
    logger.info(f"æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨ HuggingFace: {hf_path}")
    return hf_path

# ==================== å·¥å…·å‡½æ•° ====================
def ensure_dir(path: str):
    """ç¡®ä¿ç›®å½•å­˜åœ¨"""
    Path(path).mkdir(parents=True, exist_ok=True)


def download_pdf(url: str, save_path: str) -> str:
    """ä¸‹è½½ PDF æ–‡ä»¶"""
    ensure_dir(os.path.dirname(save_path))
    if os.path.exists(save_path):
        logger.info(f"PDF å·²å­˜åœ¨: {save_path}")
        return save_path
    
    logger.info(f"ä¸‹è½½ PDF: {url}")
    response = requests.get(url, timeout=60)
    response.raise_for_status()
    with open(save_path, 'wb') as f:
        f.write(response.content)
    logger.info(f"PDF ä¿å­˜è‡³: {save_path}")
    return save_path


def pdf_to_images(pdf_path: str, output_dir: str = None) -> List[str]:
    """å°† PDF è½¬æ¢ä¸ºå›¾ç‰‡"""
    try:
        from pdf2image import convert_from_path
    except ImportError:
        raise ImportError("è¯·å®‰è£… pdf2image: pip install pdf2image")
    
    if output_dir is None:
        output_dir = EXAMPLE_IMAGES_DIR
    ensure_dir(output_dir)
    
    logger.info(f"è½¬æ¢ PDF ä¸ºå›¾ç‰‡: {pdf_path}")
    images = convert_from_path(pdf_path)
    
    image_paths = []
    for idx, img in enumerate(images):
        img_path = os.path.join(output_dir, f"page_{idx:03d}.png")
        img.save(img_path)
        image_paths.append(img_path)
    
    logger.info(f"å…±è½¬æ¢ {len(image_paths)} é¡µ")
    return image_paths


def download_example_data():
    """ä¸‹è½½ç¤ºä¾‹æ•°æ®"""
    logger.info("æ­£åœ¨å‡†å¤‡ç¤ºä¾‹æ•°æ®...")
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¤ºä¾‹å›¾ç‰‡
    if os.path.exists(EXAMPLE_IMAGES_DIR):
        existing_images = list(Path(EXAMPLE_IMAGES_DIR).glob("*.png"))
        if len(existing_images) > 0:
            logger.info(f"ç¤ºä¾‹æ•°æ®å·²å­˜åœ¨ï¼Œå…± {len(existing_images)} é¡µ")
            return sorted([str(p) for p in existing_images])
    
    # ä¸‹è½½å¹¶è½¬æ¢ PDF
    try:
        pdf_path = download_pdf(EXAMPLE_PDF_URL, EXAMPLE_PDF_PATH)
        image_paths = pdf_to_images(pdf_path, EXAMPLE_IMAGES_DIR)
        return image_paths
    except Exception as e:
        logger.error(f"ä¸‹è½½ç¤ºä¾‹æ•°æ®å¤±è´¥: {e}")
        return []


# ==================== RAG ç³»ç»Ÿç±» ====================
class MultimodalRAG:
    def __init__(self):
        self.embedder = None
        self.reranker = None
        self.vlm_model = None
        self.vlm_processor = None
        
        self.document_images: List[str] = []
        self.document_embeddings = None
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def load_embedder(self):
        """åŠ è½½ Embedding æ¨¡å‹"""
        if self.embedder is not None:
            return
        
        model_path = get_model_path(
            EMBEDDING_MODEL_PATH, 
            "Qwen/Qwen3-VL-Embedding-2B"
        )
        logger.info(f"åŠ è½½ Embedding æ¨¡å‹: {model_path}")
        self.embedder = Qwen3VLEmbedder(
            model_path,
            torch_dtype=torch.bfloat16,
        )
        logger.info("Embedding æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def unload_embedder(self):
        """å¸è½½ Embedding æ¨¡å‹ä»¥èŠ‚çœæ˜¾å­˜"""
        if self.embedder is not None:
            del self.embedder
            self.embedder = None
            torch.cuda.empty_cache()
            logger.info("Embedding æ¨¡å‹å·²å¸è½½")
    
    def load_reranker(self):
        """åŠ è½½ Reranker æ¨¡å‹"""
        if self.reranker is not None:
            return
        
        model_path = get_model_path(
            RERANKER_MODEL_PATH,
            "Qwen/Qwen3-VL-Reranker-2B"
        )
        logger.info(f"åŠ è½½ Reranker æ¨¡å‹: {model_path}")
        self.reranker = Qwen3VLReranker(
            model_path,
            torch_dtype=torch.bfloat16,
        )
        logger.info("Reranker æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def unload_reranker(self):
        """å¸è½½ Reranker æ¨¡å‹"""
        if self.reranker is not None:
            del self.reranker
            self.reranker = None
            torch.cuda.empty_cache()
            logger.info("Reranker æ¨¡å‹å·²å¸è½½")
    
    def load_vlm(self):
        """åŠ è½½ VLM ç”Ÿæˆæ¨¡å‹"""
        if self.vlm_model is not None:
            return
        
        model_path = get_model_path(
            VLM_MODEL_PATH,
            "Qwen/Qwen3-VL-2B-Instruct"
        )
        logger.info(f"åŠ è½½ VLM æ¨¡å‹: {model_path}")
        self.vlm_model = Qwen3VLForConditionalGeneration.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
        )
        self.vlm_processor = AutoProcessor.from_pretrained(model_path)
        logger.info("VLM æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def unload_vlm(self):
        """å¸è½½ VLM æ¨¡å‹"""
        if self.vlm_model is not None:
            del self.vlm_model
            del self.vlm_processor
            self.vlm_model = None
            self.vlm_processor = None
            torch.cuda.empty_cache()
            logger.info("VLM æ¨¡å‹å·²å¸è½½")
    
    def index_documents(self, image_paths: List[str]) -> str:
        """ç´¢å¼•æ–‡æ¡£å›¾ç‰‡"""
        if not image_paths:
            return "âŒ æ²¡æœ‰æ–‡æ¡£å›¾ç‰‡å¯ç´¢å¼•"
        
        self.document_images = image_paths
        
        # åŠ è½½ embedder
        self.load_embedder()
        
        # æ„å»ºè¾“å…¥
        document_inputs = [{"image": img_path} for img_path in image_paths]
        
        logger.info(f"æ­£åœ¨ä¸º {len(image_paths)} ä¸ªæ–‡æ¡£ç”ŸæˆåµŒå…¥...")
        self.document_embeddings = self.embedder.process(document_inputs)
        
        # å¸è½½ä»¥èŠ‚çœæ˜¾å­˜
        self.unload_embedder()
        
        return f"âœ… æˆåŠŸç´¢å¼• {len(image_paths)} ä¸ªæ–‡æ¡£é¡µé¢"
    
    def retrieve_top_k(
        self, 
        query_embedding: np.ndarray, 
        k: int = 3
    ) -> Tuple[List[int], List[float]]:
        """æ£€ç´¢ Top-K ç›¸å…³æ–‡æ¡£"""
        if self.document_embeddings is None:
            return [], []
        
        doc_emb = self.document_embeddings
        if torch.is_tensor(doc_emb):
            doc_emb = doc_emb.cpu().numpy()
        if torch.is_tensor(query_embedding):
            query_embedding = query_embedding.cpu().numpy()
        
        similarity_scores = query_embedding @ doc_emb.T
        top_k_indices = np.argsort(similarity_scores)[-k:][::-1]
        top_k_scores = similarity_scores[top_k_indices]
        
        return top_k_indices.tolist(), top_k_scores.tolist()
    
    def search(
        self, 
        query: str, 
        top_k: int = 3, 
        use_reranker: bool = True
    ) -> Tuple[List[Tuple[str, float]], str]:
        """æœç´¢ç›¸å…³æ–‡æ¡£"""
        if not self.document_images or self.document_embeddings is None:
            return [], "âŒ è¯·å…ˆç´¢å¼•æ–‡æ¡£"
        
        # åŠ è½½ embedder å¹¶ç”ŸæˆæŸ¥è¯¢åµŒå…¥
        self.load_embedder()
        query_inputs = [{"text": query}]
        query_embedding = self.embedder.process(query_inputs)
        self.unload_embedder()
        
        # æ£€ç´¢
        top_indices, top_scores = self.retrieve_top_k(
            query_embedding[0], k=top_k
        )
        
        results = []
        if use_reranker and len(top_indices) > 0:
            # ä½¿ç”¨ Reranker é‡æ’åº
            self.load_reranker()
            
            reranker_inputs = {
                "instruction": "Retrieve pages relevant to the user's query.",
                "query": {"text": query},
                "documents": [{"image": self.document_images[idx]} for idx in top_indices],
            }
            reranker_scores = self.reranker.process(reranker_inputs)
            
            self.unload_reranker()
            
            # æŒ‰é‡æ’åºåˆ†æ•°æ’åº
            sorted_results = sorted(
                zip(top_indices, reranker_scores), 
                key=lambda x: x[1], 
                reverse=True
            )
            for idx, score in sorted_results:
                results.append((self.document_images[idx], score))
            
            status = f"âœ… æ£€ç´¢å®Œæˆï¼ˆä½¿ç”¨ Reranker é‡æ’åºï¼‰"
        else:
            for idx, score in zip(top_indices, top_scores):
                results.append((self.document_images[idx], score))
            status = f"âœ… æ£€ç´¢å®Œæˆ"
        
        return results, status
    
    def generate_answer(
        self, 
        query: str, 
        image_path: str, 
        max_tokens: int = 512
    ) -> str:
        """ä½¿ç”¨ VLM ç”Ÿæˆç­”æ¡ˆ"""
        self.load_vlm()
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": f"file://{image_path}"},
                    {
                        "type": "text",
                        "text": f"Based on this document page, please answer the following question:\n\n{query}"
                    },
                ],
            }
        ]
        
        inputs = self.vlm_processor.apply_chat_template(
            messages,
            tokenize=True,
            add_generation_prompt=True,
            return_dict=True,
            return_tensors="pt"
        )
        inputs = inputs.to(self.vlm_model.device)
        
        generated_ids = self.vlm_model.generate(
            **inputs, 
            max_new_tokens=max_tokens,
            do_sample=True,
            temperature=0.7,
        )
        generated_ids_trimmed = [
            out_ids[len(in_ids):] 
            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
        ]
        output_text = self.vlm_processor.batch_decode(
            generated_ids_trimmed,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )
        
        return output_text[0]


# ==================== Gradio ç•Œé¢ ====================
# å…¨å±€ RAG å®ä¾‹
rag = MultimodalRAG()


def load_example_documents():
    """åŠ è½½ç¤ºä¾‹æ–‡æ¡£"""
    image_paths = download_example_data()
    if not image_paths:
        return None, "âŒ åŠ è½½ç¤ºä¾‹æ•°æ®å¤±è´¥"
    
    # åªä½¿ç”¨éƒ¨åˆ†é¡µé¢ä½œä¸ºç¤ºä¾‹
    image_paths = image_paths[4:10]  # ç¬¬5-10é¡µ
    
    status = rag.index_documents(image_paths)
    
    # è¿”å›å›¾ç‰‡ç”¨äºæ˜¾ç¤º
    gallery_images = [(path, f"Page {i+1}") for i, path in enumerate(image_paths)]
    return gallery_images, status


def upload_documents(files):
    """ä¸Šä¼ å¹¶ç´¢å¼•æ–‡æ¡£"""
    if not files:
        return None, "âŒ è¯·ä¸Šä¼ æ–‡æ¡£"
    
    image_paths = []
    ensure_dir(TEMP_DIR)
    
    for file in files:
        file_path = file.name
        ext = os.path.splitext(file_path)[1].lower()
        
        if ext == '.pdf':
            # è½¬æ¢ PDF
            pdf_images = pdf_to_images(file_path, TEMP_DIR)
            image_paths.extend(pdf_images)
        elif ext in ['.png', '.jpg', '.jpeg', '.webp']:
            image_paths.append(file_path)
        else:
            logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
    
    if not image_paths:
        return None, "âŒ æ²¡æœ‰å¯å¤„ç†çš„æ–‡æ¡£"
    
    status = rag.index_documents(image_paths)
    gallery_images = [(path, f"Page {i+1}") for i, path in enumerate(image_paths)]
    return gallery_images, status


def search_documents(query: str, top_k: int, use_reranker: bool):
    """æœç´¢æ–‡æ¡£"""
    if not query.strip():
        return None, "âŒ è¯·è¾“å…¥æŸ¥è¯¢"
    
    results, status = rag.search(query, top_k=top_k, use_reranker=use_reranker)
    
    if not results:
        return None, status
    
    gallery_images = [
        (path, f"Score: {score:.4f}") 
        for path, score in results
    ]
    return gallery_images, status


def generate_answer(query: str, selected_image: str):
    """ç”Ÿæˆç­”æ¡ˆ"""
    if not query.strip():
        return "âŒ è¯·è¾“å…¥æŸ¥è¯¢"
    
    if not selected_image:
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæœç´¢ç»“æœ
        if rag.document_images:
            selected_image = rag.document_images[0]
        else:
            return "âŒ è¯·å…ˆç´¢å¼•æ–‡æ¡£å¹¶é€‰æ‹©ä¸€ä¸ªé¡µé¢"
    
    try:
        answer = rag.generate_answer(query, selected_image)
        return answer
    except Exception as e:
        logger.error(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
        return f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"


def select_image_for_generation(evt: gr.SelectData, gallery):
    """ä»æœç´¢ç»“æœä¸­é€‰æ‹©å›¾ç‰‡ç”¨äºç”Ÿæˆ"""
    if gallery and evt.index < len(gallery):
        return gallery[evt.index][0]
    return None


# åˆ›å»º Gradio ç•Œé¢
def create_ui():
    with gr.Blocks(
        title="Qwen3-VL Multimodal RAG",
        theme=gr.themes.Soft(),
    ) as demo:
        gr.Markdown("""
        # ğŸ” Qwen3-VL Multimodal RAG Demo
        
        ä½¿ç”¨ Qwen3-VL æ¨¡å‹ç³»åˆ—å®ç°å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)ï¼š
        - **Qwen3-VL-Embedding**: æ–‡æ¡£å’ŒæŸ¥è¯¢åµŒå…¥
        - **Qwen3-VL-Reranker**: æœç´¢ç»“æœé‡æ’åº  
        - **Qwen3-VL-Instruct**: åŸºäºæ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ
        """)
        
        selected_image_path = gr.State(None)
        
        with gr.Tabs():
            # ========== æ–‡æ¡£ç´¢å¼• Tab ==========
            with gr.TabItem("ğŸ“š æ–‡æ¡£ç´¢å¼•"):
                gr.Markdown("### ä¸Šä¼ æ–‡æ¡£æˆ–åŠ è½½ç¤ºä¾‹æ•°æ®")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        example_btn = gr.Button(
                            "ğŸŒ åŠ è½½ç¤ºä¾‹æ•°æ® (æ°”å€™å˜åŒ–æ–‡æ¡£)", 
                            variant="primary"
                        )
                        
                        gr.Markdown("---")
                        
                        upload_files = gr.File(
                            label="ä¸Šä¼  PDF æˆ–å›¾ç‰‡",
                            file_count="multiple",
                            file_types=[".pdf", ".png", ".jpg", ".jpeg", ".webp"],
                        )
                        upload_btn = gr.Button("ğŸ“¤ ä¸Šä¼ å¹¶ç´¢å¼•")
                    
                    with gr.Column(scale=2):
                        doc_gallery = gr.Gallery(
                            label="å·²ç´¢å¼•æ–‡æ¡£",
                            columns=3,
                            height=400,
                            object_fit="contain",
                        )
                        index_status = gr.Textbox(
                            label="çŠ¶æ€", 
                            interactive=False
                        )
            
            # ========== æœç´¢ Tab ==========
            with gr.TabItem("ğŸ” æœç´¢"):
                gr.Markdown("### è¾“å…¥æŸ¥è¯¢è¿›è¡Œå¤šæ¨¡æ€æ£€ç´¢")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        query_input = gr.Textbox(
                            label="æŸ¥è¯¢",
                            placeholder="ä¾‹å¦‚ï¼šHow much did the world temperature change?",
                            lines=2,
                        )
                        top_k_slider = gr.Slider(
                            minimum=1, 
                            maximum=10, 
                            value=3, 
                            step=1,
                            label="è¿”å›ç»“æœæ•°é‡ (Top-K)"
                        )
                        use_reranker_checkbox = gr.Checkbox(
                            label="ä½¿ç”¨ Reranker é‡æ’åº",
                            value=True
                        )
                        search_btn = gr.Button("ğŸ” æœç´¢", variant="primary")
                    
                    with gr.Column(scale=2):
                        search_gallery = gr.Gallery(
                            label="æœç´¢ç»“æœ (ç‚¹å‡»é€‰æ‹©ç”¨äºç”Ÿæˆç­”æ¡ˆ)",
                            columns=3,
                            height=400,
                            object_fit="contain",
                            allow_preview=True,
                        )
                        search_status = gr.Textbox(
                            label="çŠ¶æ€",
                            interactive=False
                        )
            
            # ========== ç”Ÿæˆç­”æ¡ˆ Tab ==========
            with gr.TabItem("ğŸ’¬ ç”Ÿæˆç­”æ¡ˆ"):
                gr.Markdown("### åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        gen_query_input = gr.Textbox(
                            label="é—®é¢˜",
                            placeholder="è¾“å…¥ä½ æƒ³é—®çš„é—®é¢˜...",
                            lines=3,
                        )
                        selected_image_display = gr.Image(
                            label="é€‰ä¸­çš„æ–‡æ¡£é¡µé¢",
                            height=300,
                        )
                        generate_btn = gr.Button("âœ¨ ç”Ÿæˆç­”æ¡ˆ", variant="primary")
                    
                    with gr.Column(scale=1):
                        answer_output = gr.Textbox(
                            label="ç”Ÿæˆçš„ç­”æ¡ˆ",
                            lines=15,
                            interactive=False,
                        )
        
        # ========== äº‹ä»¶ç»‘å®š ==========
        example_btn.click(
            fn=load_example_documents,
            outputs=[doc_gallery, index_status],
        )
        
        upload_btn.click(
            fn=upload_documents,
            inputs=[upload_files],
            outputs=[doc_gallery, index_status],
        )
        
        search_btn.click(
            fn=search_documents,
            inputs=[query_input, top_k_slider, use_reranker_checkbox],
            outputs=[search_gallery, search_status],
        )
        
        # ç‚¹å‡»æœç´¢ç»“æœé€‰æ‹©å›¾ç‰‡
        search_gallery.select(
            fn=lambda evt, gallery: (gallery[evt.index][0] if gallery else None, gallery[evt.index][0] if gallery else None),
            inputs=[search_gallery],
            outputs=[selected_image_path, selected_image_display],
        )
        
        # åŒæ­¥æŸ¥è¯¢åˆ°ç”Ÿæˆé¡µé¢
        query_input.change(
            fn=lambda x: x,
            inputs=[query_input],
            outputs=[gen_query_input],
        )
        
        generate_btn.click(
            fn=generate_answer,
            inputs=[gen_query_input, selected_image_path],
            outputs=[answer_output],
        )
        
        gr.Markdown("""
        ---
        ### ä½¿ç”¨è¯´æ˜
        1. **æ–‡æ¡£ç´¢å¼•**: ä¸Šä¼  PDF/å›¾ç‰‡æ–‡æ¡£ï¼Œæˆ–åŠ è½½ç¤ºä¾‹æ•°æ®
        2. **æœç´¢**: è¾“å…¥æŸ¥è¯¢ï¼Œç³»ç»Ÿä¼šæ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£é¡µé¢
        3. **ç”Ÿæˆç­”æ¡ˆ**: ç‚¹å‡»æœç´¢ç»“æœé€‰æ‹©é¡µé¢ï¼Œç„¶åç”Ÿæˆç­”æ¡ˆ
        
        ### æ¨¡å‹é…ç½®
        - é»˜è®¤ä½¿ç”¨ `checkpoints/` ç›®å½•ä¸‹çš„æœ¬åœ°æ¨¡å‹
        - å¯é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®æ¨¡å‹è·¯å¾„:
          - `EMBEDDING_MODEL_PATH`
          - `RERANKER_MODEL_PATH`  
          - `VLM_MODEL_PATH`
        """)
    
    return demo


# ==================== ä¸»ç¨‹åº ====================
if __name__ == "__main__":
    # å¯åŠ¨æ—¶ä¸‹è½½ç¤ºä¾‹æ•°æ®
    logger.info("æ­£åœ¨åˆå§‹åŒ–...")
    download_example_data()
    
    # åˆ›å»ºå¹¶å¯åŠ¨ Gradio
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
    )
